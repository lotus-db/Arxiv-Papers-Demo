title,authors,abstract,arxiv_id,link,date_published,date_updated,primary_category,categories,max_author_hindex
A Survey on Retrieval-Augmented Text Generation for Large Language Models,"['Yizheng Huang', 'Jimmy Huang']","Retrieval-Augmented Generation (RAG) merges retrieval methods with deep learning advancements to address the static limitations of large language models (LLMs) by enabling the dynamic integration of up-to-date external information. This methodology, focusing primarily on the text domain, provides a cost-effective solution to the generation of plausible but incorrect responses by LLMs, thereby enhancing the accuracy and reliability of their outputs through the use of real-world data. As RAG grows in complexity and incorporates multiple concepts that can influence its performance, this paper organizes the RAG paradigm into four categories: pre-retrieval, retrieval, post-retrieval, and generation, offering a detailed perspective from the retrieval viewpoint. It outlines RAG's evolution and discusses the field's progression through the analysis of significant studies. Additionally, the paper introduces evaluation methods for RAG, addressing the challenges faced and proposing future research directions. By offering an organized framework and categorization, the study aims to consolidate existing research on RAG, clarify its technological underpinnings, and highlight its potential to broaden the adaptability and applications of LLMs.",2404.10981,http://arxiv.org/abs/2404.10981v1,2024-04-17 01:27:42+00:00,2024-04-17 01:27:42+00:00,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL']",0
Behavior Alignment: A New Perspective of Evaluating LLM-based Conversational Recommendation Systems,"['Dayu Yang', 'Fumian Chen', 'Hui Fang']","Large Language Models (LLMs) have demonstrated great potential in Conversational Recommender Systems (CRS). However, the application of LLMs to CRS has exposed a notable discrepancy in behavior between LLM-based CRS and human recommenders: LLMs often appear inflexible and passive, frequently rushing to complete the recommendation task without sufficient inquiry.This behavior discrepancy can lead to decreased accuracy in recommendations and lower user satisfaction. Despite its importance, existing studies in CRS lack a study about how to measure such behavior discrepancy. To fill this gap, we propose Behavior Alignment, a new evaluation metric to measure how well the recommendation strategies made by a LLM-based CRS are consistent with human recommenders'. Our experiment results show that the new metric is better aligned with human preferences and can better differentiate how systems perform than existing evaluation metrics. As Behavior Alignment requires explicit and costly human annotations on the recommendation strategies, we also propose a classification-based method to implicitly measure the Behavior Alignment based on the responses. The evaluation results confirm the robustness of the method.",2404.11773,http://arxiv.org/abs/2404.11773v1,2024-04-17 21:56:27+00:00,2024-04-17 21:56:27+00:00,cs.IR,"['cs.IR', 'cs.AI']",0
Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers,"['Fang Guo', 'Wenyu Li', 'Honglei Zhuang', 'Yun Luo', 'Yafu Li', 'Le Yan', 'Yue Zhang']","The most recent pointwise Large Language Model (LLM) rankers have achieved remarkable ranking results. However, these rankers are hindered by two major drawbacks: (1) they fail to follow a standardized comparison guidance during the ranking process, and (2) they struggle with comprehensive considerations when dealing with complicated passages. To address these shortcomings, we propose to build a ranker that generates ranking scores based on a set of criteria from various perspectives. These criteria are intended to direct each perspective in providing a distinct yet synergistic evaluation. Our research, which examines eight datasets from the BEIR benchmark demonstrates that incorporating this multi-perspective criteria ensemble approach markedly enhanced the performance of pointwise LLM rankers.",2404.1196,http://arxiv.org/abs/2404.11960v1,2024-04-18 07:42:46+00:00,2024-04-18 07:42:46+00:00,cs.IR,"['cs.IR', 'cs.AI']",0
How Do Recommendation Models Amplify Popularity Bias? An Analysis from the Spectral Perspective,"['Siyi Lin', 'Chongming Gao', 'Jiawei Chen', 'Sheng Zhou', 'Binbin Hu', 'Can Wang']","Recommendation Systems (RS) are often plagued by popularity bias. Specifically,when recommendation models are trained on long-tailed datasets, they not only inherit this bias but often exacerbate it. This effect undermines both the precision and fairness of RS and catalyzes the so-called Matthew Effect. Despite the widely recognition of this issue, the fundamental causes remain largely elusive. In our research, we delve deeply into popularity bias amplification. Our comprehensive theoretical and empirical investigations lead to two core insights: 1) Item popularity is memorized in the principal singular vector of the score matrix predicted by the recommendation model; 2) The dimension collapse phenomenon amplifies the impact of principal singular vector on model predictions, intensifying the popularity bias. Based on these insights, we propose a novel method to mitigate this bias by imposing penalties on the magnitude of the principal singular value. Considering the heavy computational burden in directly evaluating the gradient of the principal singular value, we develop an efficient algorithm that harnesses the inherent properties of the singular vector. Extensive experiments across seven real-world datasets and three testing scenarios have been conducted to validate the superiority of our method.",2404.12008,http://arxiv.org/abs/2404.12008v1,2024-04-18 08:59:32+00:00,2024-04-18 08:59:32+00:00,cs.IR,"['cs.IR', 'cs.AI']",0
De-DSI: Decentralised Differentiable Search Index,"['Petru Neague', 'Marcel Gregoriadis', 'Johan Pouwelse']","This study introduces De-DSI, a novel framework that fuses large language models (LLMs) with genuine decentralization for information retrieval, particularly employing the differentiable search index (DSI) concept in a decentralized setting. Focused on efficiently connecting novel user queries with document identifiers without direct document access, De-DSI operates solely on query-docid pairs. To enhance scalability, an ensemble of DSI models is introduced, where the dataset is partitioned into smaller shards for individual model training. This approach not only maintains accuracy by reducing the number of data each model needs to handle but also facilitates scalability by aggregating outcomes from multiple models. This aggregation uses a beam search to identify top docids and applies a softmax function for score normalization, selecting documents with the highest scores for retrieval. The decentralized implementation demonstrates that retrieval success is comparable to centralized methods, with the added benefit of the possibility of distributing computational complexity across the network. This setup also allows for the retrieval of multimedia items through magnet links, eliminating the need for platforms or intermediaries.",2404.12237,http://arxiv.org/abs/2404.12237v1,2024-04-18 14:51:55+00:00,2024-04-18 14:51:55+00:00,cs.IR,"['cs.IR', 'cs.AI', 'cs.DC', 'I.2.7; I.2.11; H.3.3; C.2.4']",31
LLMTune: Accelerate Database Knob Tuning with Large Language Models,"['Xinmei Huang', 'Haoyang Li', 'Jing Zhang', 'Xinxin Zhao', 'Zhiming Yao', 'Yiyan Li', 'Zhuohao Yu', 'Tieying Zhang', 'Hong Chen', 'Cuiping Li']","Database knob tuning is a critical challenge in the database community, aiming to optimize knob values to enhance database performance for specific workloads. DBMS often feature hundreds of tunable knobs, posing a significant challenge for DBAs to recommend optimal configurations. Consequently, many machine learning-based tuning methods have been developed to automate this process. Despite the introduction of various optimizers, practical applications have unveiled a new problem: they typically require numerous workload runs to achieve satisfactory performance, a process that is both time-consuming and resource-intensive. This inefficiency largely stems from the optimal configuration often being substantially different from the default setting, necessitating multiple iterations during tuning. Recognizing this, we argue that an effective starting point could significantly reduce redundant exploration in less efficient areas, thereby potentially speeding up the tuning process for the optimizers. Based on this assumption, we introduce LLMTune, a large language model-based configuration generator designed to produce an initial, high-quality configuration for new workloads. These generated configurations can then serve as starting points for various base optimizers, accelerating their tuning processes. To obtain training data for LLMTune's supervised fine-tuning, we have devised a new automatic data generation framework capable of efficiently creating a large number of <workload, configuration> pairs. We have conducted thorough experiments to evaluate LLMTune's effectiveness with different workloads, such as TPC-H and JOB. In comparison to leading methods, LLMTune demonstrates a quicker ability to identify superior configurations. For instance, with the challenging TPC-H workload, our LLMTune achieves a significant 15.6x speed-up ratio in finding the best-performing configurations.",2404.11581,http://arxiv.org/abs/2404.11581v1,2024-04-17 17:28:05+00:00,2024-04-17 17:28:05+00:00,cs.AI,"['cs.AI', 'cs.DB']",0
Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System,"['Sein Kim', 'Hongseok Kang', 'Seungyoon Choi', 'Donghyun Kim', 'Minchul Yang', 'Chanyoung Park']","Collaborative filtering recommender systems (CF-RecSys) have shown successive results in enhancing the user experience on social media and e-commerce platforms. However, as CF-RecSys struggles under cold scenarios with sparse user-item interactions, recent strategies have focused on leveraging modality information of user/items (e.g., text or images) based on pre-trained modality encoders and Large Language Models (LLMs). Despite their effectiveness under cold scenarios, we observe that they underperform simple traditional collaborative filtering models under warm scenarios due to the lack of collaborative knowledge. In this work, we propose an efficient All-round LLM-based Recommender system, called A-LLMRec, that excels not only in the cold scenario but also in the warm scenario. Our main idea is to enable an LLM to directly leverage the collaborative knowledge contained in a pre-trained state-of-the-art CF-RecSys so that the emergent ability of the LLM as well as the high-quality user/item embeddings that are already trained by the state-of-the-art CF-RecSys can be jointly exploited. This approach yields two advantages: (1) model-agnostic, allowing for integration with various existing CF-RecSys, and (2) efficiency, eliminating the extensive fine-tuning typically required for LLM-based recommenders. Our extensive experiments on various real-world datasets demonstrate the superiority of A-LLMRec in various scenarios, including cold/warm, few-shot, cold user, and cross-domain scenarios. Beyond the recommendation task, we also show the potential of A-LLMRec in generating natural language outputs based on the understanding of the collaborative knowledge by performing a favorite genre prediction task. Our code is available at https://github.com/ghdtjr/A-LLMRec .",2404.11343,http://arxiv.org/abs/2404.11343v1,2024-04-17 13:03:07+00:00,2024-04-17 13:03:07+00:00,cs.IR,"['cs.IR', 'cs.AI']",1
Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models,"['Sunhao Dai', 'Chen Xu', 'Shicheng Xu', 'Liang Pang', 'Zhenhua Dong', 'Jun Xu']","With the rapid advancement of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift. This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem. In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs. We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment. Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation. In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues. Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era. We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.",2404.11457,http://arxiv.org/abs/2404.11457v1,2024-04-17 15:05:03+00:00,2024-04-17 15:05:03+00:00,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL']",25
When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes,"['Asaf Yehudai', 'Elron Bendel']","We present FastFit, a method, and a Python package design to provide fast and accurate few-shot classification, especially for scenarios with many semantically similar classes. FastFit utilizes a novel approach integrating batch contrastive learning and token-level similarity score. Compared to existing few-shot learning packages, such as SetFit, Transformers, or few-shot prompting of large language models via API calls, FastFit significantly improves multiclass classification performance in speed and accuracy across FewMany, our newly curated English benchmark, and Multilingual datasets. FastFit demonstrates a 3-20x improvement in training speed, completing training in just a few seconds. The FastFit package is now available on GitHub and PyPi, presenting a user-friendly solution for NLP practitioners.",2404.12365,http://arxiv.org/abs/2404.12365v1,2024-04-18 17:48:05+00:00,2024-04-18 17:48:05+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG']",3
Optimizing Intensive Database Tasks Through Caching Proxy Mechanisms,"['Ionut-Alex Moise', 'Alexandra Băicoianu']","Web caching is essential for the World Wide Web, saving processing power, bandwidth, and reducing latency. Many proxy caching solutions focus on buffering data from the main server, neglecting cacheable information meant for server writes. Existing systems addressing this issue are often intrusive, requiring modifications to the main application for integration. We identify opportunities for enhancement in conventional caching proxies. This paper explores, designs, and implements a potential prototype for such an application. Our focus is on harnessing a faster bulk-data-write approach compared to single-data-write within the context of relational databases. If a (upload) request matches a specified cacheable URL, then the data will be extracted and buffered on the local disk for later bulk-write. In contrast with already existing caching proxies, Squid, for example, in a similar uploading scenario, the request would simply get redirected, leaving out potential gains such as minimized processing power, lower server load, and bandwidth. After prototyping and testing the suggested application against Squid, concerning data uploads with 1, 100, 1.000, ..., and 100.000 requests, we consistently observed query execution improvements ranging from 5 to 9 times. This enhancement was achieved through buffering and bulk-writing the data, the extent of which depended on the specific test conditions.",2404.12128,http://arxiv.org/abs/2404.12128v1,2024-04-18 12:29:03+00:00,2024-04-18 12:29:03+00:00,cs.DB,['cs.DB'],0
XMiner: Efficient Directed Subgraph Matching with Pattern Reduction,"['Pingpeng Yuan', 'Yujiang Wang', 'Tianyu Ma', 'Siyuan He', 'Ling Liu']","Graph pattern matching, one of the fundamental graph mining problems, aims to extract structural patterns of interest from an input graph. The state-of-the-art graph matching algorithms and systems are mainly designed for undirected graphs. Directed graph matching is more complex than undirected graph matching because the edge direction must be taken into account before the exploration of each directed edge. Thus, the technologies (e.g. storage, exploiting symmetry for graph matching) for undirected graph matching may not be fully applicable to directed graphs. For example, the redundancy implied in directed graph pattern can not be detected using the symmetry breaking for undirected pattern graph. Here, we present XMiner for efficient directed graph pattern matching whose core idea is 'pattern reduction'. It first analyzes the relationship between constraints implied in a pattern digraph. Then it reduces the pattern graph into a simplified form by finding a minimum constraint cover. Finally, XMiner generates an execution plan and follows it to extract matchings of the pattern graph. So, XMiner works on simplified pattern graph and avoids much data access and redundant computation throughout the matching process. Our experimental results show that XMiner outperforms state-of the-art stand-alone graph matching systems, and scales to complex graph pattern matching tasks on larger graph.",2404.11105,http://arxiv.org/abs/2404.11105v1,2024-04-17 06:42:26+00:00,2024-04-17 06:42:26+00:00,cs.DB,"['cs.DB', 'cs.DC']",0
Real-Time Trajectory Synthesis with Local Differential Privacy,"['Yujia Hu', 'Yuntao Du', 'Zhikun Zhang', 'Ziquan Fang', 'Lu Chen', 'Kai Zheng', 'Yunjun Gao']","Trajectory streams are being generated from location-aware devices, such as smartphones and in-vehicle navigation systems. Due to the sensitive nature of the location data, directly sharing user trajectories suffers from privacy leakage issues. Local differential privacy (LDP), which perturbs sensitive data on the user side before it is shared or analyzed, emerges as a promising solution for private trajectory stream collection and analysis. Unfortunately, existing stream release approaches often neglect the rich spatial-temporal context information within trajectory streams, resulting in suboptimal utility and limited types of downstream applications. To this end, we propose RetraSyn, a novel real-time trajectory synthesis framework, which is able to perform on-the-fly trajectory synthesis based on the mobility patterns privately extracted from users' trajectory streams. Thus, the downstream trajectory analysis can be performed on the high-utility synthesized data with privacy protection. We also take the genuine behaviors of real-world mobile travelers into consideration, ensuring authenticity and practicality. The key components of RetraSyn include the global mobility model, dynamic mobility update mechanism, real-time synthesis, and adaptive allocation strategy. We conduct extensive experiments on multiple real-world and synthetic trajectory datasets under various location-based utility metrics, encompassing both streaming and historical scenarios. The empirical results demonstrate the superiority and versatility of our proposed framework.",2404.1145,http://arxiv.org/abs/2404.11450v1,2024-04-17 14:55:49+00:00,2024-04-17 14:55:49+00:00,cs.DB,"['cs.DB', 'cs.CR']",0
Effective Individual Fairest Community Search over Heterogeneous Information Networks,"['Taige Zhao', 'Jianxin Li', 'Ningning Cui', 'Wei Luo']","Community search over heterogeneous information networks has been applied to wide domains, such as activity organization and team formation. From these scenarios, the members of a group with the same treatment often have different levels of activity and workloads, which causes unfairness in the treatment between active members and inactive members (called individual unfairness). However, existing works do not pay attention to individual fairness and do not sufficiently consider the rich semantics of HINs (e.g., high-order structure), which disables complex queries. To fill the gap, we formally define the issue of individual fairest community search over HINs (denoted as IFCS), which aims to find a set of vertices from the HIN that own the same type, close relationships, and small difference of activity level and has been demonstrated to be NP-hard. To do this, we first develop an exploration-based filter that reduces the search space of the community effectively. Further, to avoid repeating computation and prune unfair communities in advance, we propose a message-based scheme and a lower bound-based scheme. At last, we conduct extensive experiments on four real-world datasets to demonstrate the effectiveness and efficiency of our proposed algorithms, which achieve at least X3 times faster than the baseline solution.",2404.12107,http://arxiv.org/abs/2404.12107v1,2024-04-18 11:47:46+00:00,2024-04-18 11:47:46+00:00,cs.DB,"['cs.DB', 'cs.DS', 'cs.SI']",0
Causal Deconfounding via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation,"['Jiajie Zhu', 'Yan Wang', 'Feng Zhu', 'Zhu Sun']","In recent years, dual-target Cross-Domain Recommendation (CDR) has been proposed to capture comprehensive user preferences in order to ultimately enhance the recommendation accuracy in both data-richer and data-sparser domains simultaneously. However, in addition to users' true preferences, the user-item interactions might also be affected by confounders (e.g., free shipping, sales promotion). As a result, dual-target CDR has to meet two challenges: (1) how to effectively decouple observed confounders, including single-domain confounders and cross-domain confounders, and (2) how to preserve the positive effects of observed confounders on predicted interactions, while eliminating their negative effects on capturing comprehensive user preferences. To address the above two challenges, we propose a Causal Deconfounding framework via Confounder Disentanglement for dual-target Cross-Domain Recommendation, called CD2CDR. In CD2CDR, we first propose a confounder disentanglement module to effectively decouple observed single-domain and cross-domain confounders. We then propose a causal deconfounding module to preserve the positive effects of such observed confounders and eliminate their negative effects via backdoor adjustment, thereby enhancing the recommendation accuracy in each domain. Extensive experiments conducted on five real-world datasets demonstrate that CD2CDR significantly outperforms the state-of-the-art methods.",2404.1118,http://arxiv.org/abs/2404.11180v1,2024-04-17 08:50:29+00:00,2024-04-17 08:50:29+00:00,cs.IR,['cs.IR'],0
A Learning-to-Rank Formulation of Clustering-Based Approximate Nearest Neighbor Search,"['Thomas Vecchiato', 'Claudio Lucchese', 'Franco Maria Nardini', 'Sebastian Bruch']","A critical piece of the modern information retrieval puzzle is approximate nearest neighbor search. Its objective is to return a set of $k$ data points that are closest to a query point, with its accuracy measured by the proportion of exact nearest neighbors captured in the returned set. One popular approach to this question is clustering: The indexing algorithm partitions data points into non-overlapping subsets and represents each partition by a point such as its centroid. The query processing algorithm first identifies the nearest clusters -- a process known as routing -- then performs a nearest neighbor search over those clusters only. In this work, we make a simple observation: The routing function solves a ranking problem. Its quality can therefore be assessed with a ranking metric, making the function amenable to learning-to-rank. Interestingly, ground-truth is often freely available: Given a query distribution in a top-$k$ configuration, the ground-truth is the set of clusters that contain the exact top-$k$ vectors. We develop this insight and apply it to Maximum Inner Product Search (MIPS). As we demonstrate empirically on various datasets, learning a simple linear function consistently improves the accuracy of clustering-based MIPS.",2404.11731,http://arxiv.org/abs/2404.11731v1,2024-04-17 20:34:41+00:00,2024-04-17 20:34:41+00:00,cs.IR,['cs.IR'],0
Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing,"['Le Yan', 'Zhen Qin', 'Honglei Zhuang', 'Rolf Jagerman', 'Xuanhui Wang', 'Michael Bendersky', 'Harrie Oosterhuis']","The powerful generative abilities of large language models (LLMs) show potential in generating relevance labels for search applications. Previous work has found that directly asking about relevancy, such as ``How relevant is document A to query Q?"", results in sub-optimal ranking. Instead, the pairwise ranking prompting (PRP) approach produces promising ranking performance through asking about pairwise comparisons, e.g., ``Is document A more relevant than document B to query Q?"". Thus, while LLMs are effective at their ranking ability, this is not reflected in their relevance label generation. In this work, we propose a post-processing method to consolidate the relevance labels generated by an LLM with its powerful ranking abilities. Our method takes both LLM generated relevance labels and pairwise preferences. The labels are then altered to satisfy the pairwise preferences of the LLM, while staying as close to the original values as possible. Our experimental results indicate that our approach effectively balances label accuracy and ranking performance. Thereby, our work shows it is possible to combine both the ranking and labeling abilities of LLMs through post-processing.",2404.11791,http://arxiv.org/abs/2404.11791v1,2024-04-17 22:57:30+00:00,2024-04-17 22:57:30+00:00,cs.IR,['cs.IR'],0
SIGformer: Sign-aware Graph Transformer for Recommendation,"['Sirui Chen', 'Jiawei Chen', 'Sheng Zhou', 'Bohao Wang', 'Shen Han', 'Chanfei Su', 'Yuqing Yuan', 'Can Wang']","In recommender systems, most graph-based methods focus on positive user feedback, while overlooking the valuable negative feedback. Integrating both positive and negative feedback to form a signed graph can lead to a more comprehensive understanding of user preferences. However, the existing efforts to incorporate both types of feedback are sparse and face two main limitations: 1) They process positive and negative feedback separately, which fails to holistically leverage the collaborative information within the signed graph; 2) They rely on MLPs or GNNs for information extraction from negative feedback, which may not be effective.   To overcome these limitations, we introduce SIGformer, a new method that employs the transformer architecture to sign-aware graph-based recommendation. SIGformer incorporates two innovative positional encodings that capture the spectral properties and path patterns of the signed graph, enabling the full exploitation of the entire graph. Our extensive experiments across five real-world datasets demonstrate the superiority of SIGformer over state-of-the-art methods. The code is available at https://github.com/StupidThree/SIGformer.",2404.11982,http://arxiv.org/abs/2404.11982v1,2024-04-18 08:26:04+00:00,2024-04-18 08:26:04+00:00,cs.IR,['cs.IR'],0
Knowledge-Aware Multi-Intent Contrastive Learning for Multi-Behavior Recommendation,"['Shunpan Liang', 'Junjie Zhao', 'Chen Li', 'Yu Lei']","Multi-behavioral recommendation optimizes user experiences by providing users with more accurate choices based on their diverse behaviors, such as view, add to cart, and purchase. Current studies on multi-behavioral recommendation mainly explore the connections and differences between multi-behaviors from an implicit perspective. Specifically, they directly model those relations using black-box neural networks. In fact, users' interactions with items under different behaviors are driven by distinct intents. For instance, when users view products, they tend to pay greater attention to information such as ratings and brands. However, when it comes to the purchasing phase, users become more price-conscious. To tackle this challenge and data sparsity problem in the multi-behavioral recommendation, we propose a novel model: Knowledge-Aware Multi-Intent Contrastive Learning (KAMCL) model. This model uses relationships in the knowledge graph to construct intents, aiming to mine the connections between users' multi-behaviors from the perspective of intents to achieve more accurate recommendations. KAMCL is equipped with two contrastive learning schemes to alleviate the data scarcity problem and further enhance user representations. Extensive experiments on three real datasets demonstrate the superiority of our model.",2404.11993,http://arxiv.org/abs/2404.11993v1,2024-04-18 08:39:52+00:00,2024-04-18 08:39:52+00:00,cs.IR,"['cs.IR', 'cs.LG']",4
DRepMRec: A Dual Representation Learning Framework for Multimodal Recommendation,"['Kangning Zhang', 'Yingjie Qin', 'Ruilong Su', 'Yifan Liu', 'Jiarui Jin', 'Weinan Zhang', 'Yong Yu']","Multimodal Recommendation focuses mainly on how to effectively integrate behavior and multimodal information in the recommendation task. Previous works suffer from two major issues. Firstly, the training process tightly couples the behavior module and multimodal module by jointly optimizing them using the sharing model parameters, which leads to suboptimal performance since behavior signals and modality signals often provide opposite guidance for the parameters updates. Secondly, previous approaches fail to take into account the significant distribution differences between behavior and modality when they attempt to fuse behavior and modality information. This resulted in a misalignment between the representations of behavior and modality. To address these challenges, in this paper, we propose a novel Dual Representation learning framework for Multimodal Recommendation called DRepMRec, which introduce separate dual lines for coupling problem and Behavior-Modal Alignment (BMA) for misalignment problem. Specifically, DRepMRec leverages two independent lines of representation learning to calculate behavior and modal representations. After obtaining separate behavior and modal representations, we design a Behavior-Modal Alignment Module (BMA) to align and fuse the dual representations to solve the misalignment problem. Furthermore, we integrate the BMA into other recommendation models, resulting in consistent performance improvements. To ensure dual representations maintain their semantic independence during alignment, we introduce Similarity-Supervised Signal (SSS) for representation learning. We conduct extensive experiments on three public datasets and our method achieves state-of-the-art (SOTA) results. The source code will be available upon acceptance.",2404.11119,http://arxiv.org/abs/2404.11119v1,2024-04-17 07:07:41+00:00,2024-04-17 07:07:41+00:00,cs.IR,"['cs.IR', 'cs.MM']",8
Deep Pattern Network for Click-Through Rate Prediction,"['Hengyu Zhang', 'Junwei Pan', 'Dapeng Liu', 'Jie Jiang', 'Xiu Li']","Click-through rate (CTR) prediction tasks play a pivotal role in real-world applications, particularly in recommendation systems and online advertising. A significant research branch in this domain focuses on user behavior modeling. Current research predominantly centers on modeling co-occurrence relationships between the target item and items previously interacted with by users in their historical data. However, this focus neglects the intricate modeling of user behavior patterns. In reality, the abundance of user interaction records encompasses diverse behavior patterns, indicative of a spectrum of habitual paradigms. These patterns harbor substantial potential to significantly enhance CTR prediction performance. To harness the informational potential within user behavior patterns, we extend Target Attention (TA) to Target Pattern Attention (TPA) to model pattern-level dependencies. Furthermore, three critical challenges demand attention: the inclusion of unrelated items within behavior patterns, data sparsity in behavior patterns, and computational complexity arising from numerous patterns. To address these challenges, we introduce the Deep Pattern Network (DPN), designed to comprehensively leverage information from user behavior patterns. DPN efficiently retrieves target-related user behavior patterns using a target-aware attention mechanism. Additionally, it contributes to refining user behavior patterns through a pre-training paradigm based on self-supervised learning while promoting dependency learning within sparse patterns. Our comprehensive experiments, conducted across three public datasets, substantiate the superior performance and broad compatibility of DPN.",2404.11456,http://arxiv.org/abs/2404.11456v1,2024-04-17 15:05:00+00:00,2024-04-17 15:05:00+00:00,cs.IR,['cs.IR'],33
Disentangled Cascaded Graph Convolution Networks for Multi-Behavior Recommendation,"['Zhiyong Cheng', 'Jianhua Dong', 'Fan Liu', 'Lei Zhu', 'Xun Yang', 'Meng Wang']","Multi-behavioral recommender systems have emerged as a solution to address data sparsity and cold-start issues by incorporating auxiliary behaviors alongside target behaviors. However, existing models struggle to accurately capture varying user preferences across different behaviors and fail to account for diverse item preferences within behaviors. Various user preference factors (such as price or quality) entangled in the behavior may lead to sub-optimization problems. Furthermore, these models overlook the personalized nature of user behavioral preferences by employing uniform transformation networks for all users and items. To tackle these challenges, we propose the Disentangled Cascaded Graph Convolutional Network (Disen-CGCN), a novel multi-behavior recommendation model. Disen-CGCN employs disentangled representation techniques to effectively separate factors within user and item representations, ensuring their independence. In addition, it incorporates a multi-behavioral meta-network, enabling personalized feature transformation across user and item behaviors. Furthermore, an attention mechanism captures user preferences for different item factors within each behavior. By leveraging attention weights, we aggregate user and item embeddings separately for each behavior, computing preference scores that predict overall user preferences for items. Our evaluation on benchmark datasets demonstrates the superiority of Disen-CGCN over state-of-the-art models, showcasing an average performance improvement of 7.07% and 9.00% on respective datasets. These results highlight Disen-CGCN's ability to effectively leverage multi-behavioral data, leading to more accurate recommendations.",2404.11519,http://arxiv.org/abs/2404.11519v1,2024-04-17 16:10:55+00:00,2024-04-17 16:10:55+00:00,cs.IR,['cs.IR'],0
Automated Similarity Metric Generation for Recommendation,"['Liang Qu', 'Yun Lin', 'Wei Yuan', 'Xiaojun Wan', 'Yuhui Shi', 'Hongzhi Yin']","The embedding-based architecture has become the dominant approach in modern recommender systems, mapping users and items into a compact vector space. It then employs predefined similarity metrics, such as the inner product, to calculate similarity scores between user and item embeddings, thereby guiding the recommendation of items that align closely with a user's preferences. Given the critical role of similarity metrics in recommender systems, existing methods mainly employ handcrafted similarity metrics to capture the complex characteristics of user-item interactions. Yet, handcrafted metrics may not fully capture the diverse range of similarity patterns that can significantly vary across different domains.   To address this issue, we propose an Automated Similarity Metric Generation method for recommendations, named AutoSMG, which can generate tailored similarity metrics for various domains and datasets. Specifically, we first construct a similarity metric space by sampling from a set of basic embedding operators, which are then integrated into computational graphs to represent metrics. We employ an evolutionary algorithm to search for the optimal metrics within this metric space iteratively. To improve search efficiency, we utilize an early stopping strategy and a surrogate model to approximate the performance of candidate metrics instead of fully training models. Notably, our proposed method is model-agnostic, which can seamlessly plugin into different recommendation model architectures. The proposed method is validated on three public recommendation datasets across various domains in the Top-K recommendation task, and experimental results demonstrate that AutoSMG outperforms both commonly used handcrafted metrics and those generated by other search strategies.",2404.11818,http://arxiv.org/abs/2404.11818v1,2024-04-18 00:35:40+00:00,2024-04-18 00:35:40+00:00,cs.IR,['cs.IR'],0
Planning with Language Models Through The Lens of Efficiency,"['Michael Katz', 'Harsha Kokel', 'Kavitha Srinivas', 'Shirin Sohrabi']",We analyse the cost of using LLMs for planning and highlight that recent trends are profoundly uneconomical. We propose a significantly more efficient approach and argue for a responsible use of compute resources; urging research community to investigate LLM-based approaches that upholds efficiency.,2404.11833,http://arxiv.org/abs/2404.11833v1,2024-04-18 01:27:29+00:00,2024-04-18 01:27:29+00:00,cs.AI,['cs.AI'],0
Accounting for AI and Users Shaping One Another: The Role of Mathematical Models,"['Sarah Dean', 'Evan Dong', 'Meena Jagadeesan', 'Liu Leqi']","As AI systems enter into a growing number of societal domains, these systems increasingly shape and are shaped by user preferences, opinions, and behaviors. However, the design of AI systems rarely accounts for how AI and users shape one another. In this position paper, we argue for the development of formal interaction models which mathematically specify how AI and users shape one another. Formal interaction models can be leveraged to (1) specify interactions for implementation, (2) monitor interactions through empirical analysis, (3) anticipate societal impacts via counterfactual analysis, and (4) control societal impacts via interventions. The design space of formal interaction models is vast, and model design requires careful consideration of factors such as style, granularity, mathematical complexity, and measurability. Using content recommender systems as a case study, we critically examine the nascent literature of formal interaction models with respect to these use-cases and design axes. More broadly, we call for the community to leverage formal interaction models when designing, evaluating, or auditing any AI system which interacts with users.",2404.12366,http://arxiv.org/abs/2404.12366v1,2024-04-18 17:49:02+00:00,2024-04-18 17:49:02+00:00,cs.LG,"['cs.LG', 'cs.CY', 'cs.GT', 'cs.IR']",0
Explainable Artificial Intelligence Techniques for Accurate Fault Detection and Diagnosis: A Review,"['Ahmed Maged', 'Salah Haridy', 'Herman Shen']","As the manufacturing industry advances with sensor integration and automation, the opaque nature of deep learning models in machine learning poses a significant challenge for fault detection and diagnosis. And despite the related predictive insights Artificial Intelligence (AI) can deliver, advanced machine learning engines often remain a black box. This paper reviews the eXplainable AI (XAI) tools and techniques in this context. We explore various XAI methodologies, focusing on their role in making AI decision-making transparent, particularly in critical scenarios where humans are involved. We also discuss current limitations and potential future research that aims to balance explainability with model performance while improving trustworthiness in the context of AI applications for critical industrial use cases.",2404.11597,http://arxiv.org/abs/2404.11597v1,2024-04-17 17:49:38+00:00,2024-04-17 17:49:38+00:00,cs.AI,"['cs.AI', 'cs.LG']",0
Implementation and Evaluation of a Gradient Descent-Trained Defensible Blackboard Architecture System,"['Jordan Milbrath', 'Jonathan Rivard', 'Jeremy Straub']","A variety of forms of artificial intelligence systems have been developed. Two well-known techniques are neural networks and rule-fact expert systems. The former can be trained from presented data while the latter is typically developed by human domain experts. A combined implementation that uses gradient descent to train a rule-fact expert system has been previously proposed. A related system type, the Blackboard Architecture, adds an actualization capability to expert systems. This paper proposes and evaluates the incorporation of a defensible-style gradient descent training capability into the Blackboard Architecture. It also introduces the use of activation functions for defensible artificial intelligence systems and implements and evaluates a new best path-based training algorithm.",2404.11714,http://arxiv.org/abs/2404.11714v1,2024-04-17 19:55:58+00:00,2024-04-17 19:55:58+00:00,cs.AI,['cs.AI'],24
RAM: Towards an Ever-Improving Memory System by Learning from Communications,"['Jiaqi Li', 'Xiaobo Wang', 'Zihao Wang', 'Zilong Zheng']","We introduce RAM, an innovative RAG-based framework with an ever-improving memory. Inspired by humans' pedagogical process, RAM utilizes recursively reasoning-based retrieval and experience reflections to continually update the memory and learn from users' communicative feedback, namely communicative learning. Extensive experiments with both simulated and real users demonstrate significant improvements over traditional RAG and self-knowledge methods, particularly excelling in handling false premise and multi-hop questions. Furthermore, RAM exhibits promising adaptability to various feedback and retrieval method chain types, showcasing its potential for advancing AI capabilities in dynamic knowledge acquisition and lifelong learning.",2404.12045,http://arxiv.org/abs/2404.12045v1,2024-04-18 09:58:51+00:00,2024-04-18 09:58:51+00:00,cs.AI,['cs.AI'],0
Evaluating AI for Law: Bridging the Gap with Open-Source Solutions,"['Rohan Bhambhoria', 'Samuel Dahan', 'Jonathan Li', 'Xiaodan Zhu']","This study evaluates the performance of general-purpose AI, like ChatGPT, in legal question-answering tasks, highlighting significant risks to legal professionals and clients. It suggests leveraging foundational models enhanced by domain-specific knowledge to overcome these issues. The paper advocates for creating open-source legal AI systems to improve accuracy, transparency, and narrative diversity, addressing general AI's shortcomings in legal contexts.",2404.12349,http://arxiv.org/abs/2404.12349v1,2024-04-18 17:26:01+00:00,2024-04-18 17:26:01+00:00,cs.AI,"['cs.AI', 'cs.HC']",4
A Fast Maximum Clique Algorithm Based on Network Decomposition for Large Sparse Networks,"['Tianlong Fan', 'Wenjun Jiang', 'Yi-Cheng Zhang', 'Linyuan Lü']","Finding maximum cliques in large networks is a challenging combinatorial problem with many real-world applications. We present a fast algorithm to achieve the exact solution for the maximum clique problem in large sparse networks based on efficient graph decomposition. A bunch of effective techniques is being used to greatly prune the graph and a novel concept called Complete-Upper-Bound-Induced Subgraph (CUBIS) is proposed to ensure that the structures with the potential to form the maximum clique are retained in the process of graph decomposition. Our algorithm first pre-prunes peripheral nodes, subsequently, one or two small-scale CUBISs are constructed guided by the core number and current maximum clique size. Bron-Kerbosch search is performed on each CUBIS to find the maximum clique. Experiments on 50 empirical networks with a scale of up to 20 million show the CUBIS scales are largely independent of the original network scale. This enables an approximately linear runtime, making our algorithm amenable for large networks. Our work provides a new framework for effectively solving maximum clique problems on massive sparse graphs, which not only makes the graph scale no longer the bottleneck but also shows some light on solving other clique-related problems.",2404.11862,http://arxiv.org/abs/2404.11862v1,2024-04-18 02:35:29+00:00,2024-04-18 02:35:29+00:00,cs.SI,"['cs.SI', 'cs.DS', 'cs.IR', 'physics.data-an', '05C82(Primary), 05C80, 91D30, 68P20(Secondary)', 'H.3.3; F.2.2; J.2']",28
Estimating the Hessian Matrix of Ranking Objectives for Stochastic Learning to Rank with Gradient Boosted Trees,"['Jingwei Kang', 'Maarten de Rijke', 'Harrie Oosterhuis']","Stochastic learning to rank (LTR) is a recent branch in the LTR field that concerns the optimization of probabilistic ranking models. Their probabilistic behavior enables certain ranking qualities that are impossible with deterministic models. For example, they can increase the diversity of displayed documents, increase fairness of exposure over documents, and better balance exploitation and exploration through randomization. A core difficulty in LTR is gradient estimation, for this reason, existing stochastic LTR methods have been limited to differentiable ranking models (e.g., neural networks). This is in stark contrast with the general field of LTR where Gradient Boosted Decision Trees (GBDTs) have long been considered the state-of-the-art.   In this work, we address this gap by introducing the first stochastic LTR method for GBDTs. Our main contribution is a novel estimator for the second-order derivatives, i.e., the Hessian matrix, which is a requirement for effective GBDTs. To efficiently compute both the first and second-order derivatives simultaneously, we incorporate our estimator into the existing PL-Rank framework, which was originally designed for first-order derivatives only. Our experimental results indicate that stochastic LTR without the Hessian has extremely poor performance, whilst the performance is competitive with the current state-of-the-art with our estimated Hessian. Thus, through the contribution of our novel Hessian estimation method, we have successfully introduced GBDTs to stochastic LTR.",2404.1219,http://arxiv.org/abs/2404.12190v1,2024-04-18 13:53:32+00:00,2024-04-18 13:53:32+00:00,cs.LG,"['cs.LG', 'cs.IR']",76
Shotit: compute-efficient image-to-video search engine for the cloud,['Leslie Wong'],"With the rapid growth of information technology, users are exposed to a massive amount of data online, including image, music, and video. This has led to strong needs to provide effective corresponsive search services such as image, music, and video search services. Most of them are operated based on keywords, namely using keywords to find related image, music, and video. Additionally, there are image-to-image search services that enable users to find similar images using one input image. Given that videos are essentially composed of image frames, then similar videos can be searched by one input image or screenshot. We want to target this scenario and provide an efficient method and implementation in this paper.   We present Shotit, a cloud-native image-to-video search engine that tailors this search scenario in a compute-efficient approach. One main limitation faced in this scenario is the scale of its dataset. A typical image-to-image search engine only handles one-to-one relationships, colloquially, one image corresponds to another single image. But image-to-video proliferates. Take a 24-min length video as an example, it will generate roughly 20,000 image frames. As the number of videos grows, the scale of the dataset explodes exponentially. In this case, a compute-efficient approach ought to be considered, and the system design should cater to the cloud-native trend. Choosing an emerging technology - vector database as its backbone, Shotit fits these two metrics performantly. Experiments for two different datasets, a 50 thousand-scale Blender Open Movie dataset, and a 50 million-scale proprietary TV genre dataset at a 4 Core 32GB RAM Intel Xeon Gold 6271C cloud machine with object storage reveal the effectiveness of Shotit. A demo regarding the Blender Open Movie dataset is illustrated within this paper.",2404.12169,http://arxiv.org/abs/2404.12169v1,2024-04-18 13:23:05+00:00,2024-04-18 13:23:05+00:00,cs.MM,"['cs.MM', 'cs.IR']",0
iRAG: An Incremental Retrieval Augmented Generation System for Videos,"['Md Adnan Arefeen', 'Biplob Debnath', 'Md Yusuf Sarwar Uddin', 'Srimat Chakradhar']","Retrieval augmented generation (RAG) systems combine the strengths of language generation and information retrieval to power many real-world applications like chatbots. Use of RAG for combined understanding of multimodal data such as text, images and videos is appealing but two critical limitations exist: one-time, upfront capture of all content in large multimodal data as text descriptions entails high processing times, and not all information in the rich multimodal data is typically in the text descriptions. Since the user queries are not known apriori, developing a system for multimodal to text conversion and interactive querying of multimodal data is challenging.   To address these limitations, we propose iRAG, which augments RAG with a novel incremental workflow to enable interactive querying of large corpus of multimodal data. Unlike traditional RAG, iRAG quickly indexes large repositories of multimodal data, and in the incremental workflow, it uses the index to opportunistically extract more details from select portions of the multimodal data to retrieve context relevant to an interactive user query. Such an incremental workflow avoids long multimodal to text conversion times, overcomes information loss issues by doing on-demand query-specific extraction of details in multimodal data, and ensures high quality of responses to interactive user queries that are often not known apriori. To the best of our knowledge, iRAG is the first system to augment RAG with an incremental workflow to support efficient interactive querying of large, real-world multimodal data. Experimental results on real-world long videos demonstrate 23x to 25x faster video to text ingestion, while ensuring that quality of responses to interactive user queries is comparable to responses from a traditional RAG where all video data is converted to text upfront before any querying.",2404.12309,http://arxiv.org/abs/2404.12309v1,2024-04-18 16:38:02+00:00,2024-04-18 16:38:02+00:00,cs.CV,"['cs.CV', 'cs.IR', 'cs.LG']",0
On the Empirical Complexity of Reasoning and Planning in LLMs,"['Liwei Kang', 'Zirui Zhao', 'David Hsu', 'Wee Sun Lee']","Large Language Models (LLMs) work surprisingly well for some complex reasoning problems via chain-of-thought (CoT) or tree-of-thought (ToT), but the underlying reasons remain unclear. We seek to understand the performance of these methods by conducting experimental case studies and linking the outcomes to sample and computational complexity in machine learning. We found that if problems can be decomposed into a sequence of reasoning steps and learning to predict the next step has a low sample and computational complexity, explicitly outlining the reasoning chain with all necessary information for predicting the next step may improve performance. Conversely, for problems where predicting the next step is computationally hard, adopting ToT may yield better reasoning outcomes than attempting to formulate a short reasoning chain.",2404.11041,http://arxiv.org/abs/2404.11041v1,2024-04-17 03:34:27+00:00,2024-04-17 03:34:27+00:00,cs.AI,"['cs.AI', 'cs.LG']",53
Small Language Models are Good Too: An Empirical Study of Zero-Shot Classification,"['Pierre Lepagnol', 'Thomas Gerald', 'Sahar Ghannay', 'Christophe Servan', 'Sophie Rosset']","This study is part of the debate on the efficiency of large versus small language models for text classification by prompting.We assess the performance of small language models in zero-shot text classification, challenging the prevailing dominance of large models.Across 15 datasets, our investigation benchmarks language models from 77M to 40B parameters using different architectures and scoring functions. Our findings reveal that small models can effectively classify texts, getting on par with or surpassing their larger counterparts.We developed and shared a comprehensive open-source repository that encapsulates our methodologies. This research underscores the notion that bigger isn't always better, suggesting that resource-efficient small models may offer viable solutions for specific data classification challenges.",2404.11122,http://arxiv.org/abs/2404.11122v1,2024-04-17 07:10:28+00:00,2024-04-17 07:10:28+00:00,cs.AI,['cs.AI'],14
Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation,"['Jessica López Espejel', 'Mahaman Sanoussi Yahaya Alassan', 'Merieme Bouhandi', 'Walid Dahhane', 'El Hassane Ettifouri']","Large Language Models (LLMs) have become the go-to solution for many Natural Language Processing (NLP) tasks due to their ability to tackle various problems and produce high-quality results. Specifically, they are increasingly used to automatically generate code, easing the burden on developers by handling repetitive tasks. However, this improvement in quality has led to high computational and memory demands, making LLMs inaccessible to users with limited resources. In this paper, we focus on Central Processing Unit (CPU)-compatible models and conduct a thorough semi-manual evaluation of their strengths and weaknesses in generating Python code. We enhance their performance by introducing a Chain-of-Thought prompt that guides the model in problem-solving. Additionally, we propose a dataset of 60 programming problems with varying difficulty levels for evaluation purposes. Our assessment also includes testing these models on two state-of-the-art datasets: HumanEval and EvalPlus. We commit to sharing our dataset and experimental results publicly to ensure transparency.",2404.1116,http://arxiv.org/abs/2404.11160v1,2024-04-17 08:16:48+00:00,2024-04-17 08:16:48+00:00,cs.AI,['cs.AI'],0
Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM,"['Hongzhao Li', 'Hongyu Wang', 'Xia Sun', 'Hua He', 'Jun Feng']","Medical report generation automates radiology descriptions from images, easing the burden on physicians and minimizing errors. However, current methods lack structured outputs and physician interactivity for clear, clinically relevant reports. Our method introduces a prompt-guided approach to generate structured chest X-ray reports using a pre-trained large language model (LLM). First, we identify anatomical regions in chest X-rays to generate focused sentences that center on key visual elements, thereby establishing a structured report foundation with anatomy-based sentences. We also convert the detected anatomy into textual prompts conveying anatomical comprehension to the LLM. Additionally, the clinical context prompts guide the LLM to emphasize interactivity and clinical requirements. By integrating anatomy-focused sentences and anatomy/clinical prompts, the pre-trained LLM can generate structured chest X-ray reports tailored to prompted anatomical regions and clinical contexts. We evaluate using language generation and clinical effectiveness metrics, demonstrating strong performance.",2404.11209,http://arxiv.org/abs/2404.11209v1,2024-04-17 09:45:43+00:00,2024-04-17 09:45:43+00:00,cs.AI,"['cs.AI', 'cs.CV', 'cs.MM']",14
How to Exhibit More Predictable Behaviors,"['Salomé Lepers', 'Sophie Lemonnier', 'Vincent Thomas', 'Olivier Buffet']","This paper looks at predictability problems, i.e., wherein an agent must choose its strategy in order to optimize the predictions that an external observer could make. We address these problems while taking into account uncertainties on the environment dynamics and on the observed agent's policy. To that end, we assume that the observer 1. seeks to predict the agent's future action or state at each time step, and 2. models the agent using a stochastic policy computed from a known underlying problem, and we leverage on the framework of observer-aware Markov decision processes (OAMDPs). We propose action and state predictability performance criteria through reward functions built on the observer's belief about the agent policy; show that these induced predictable OAMDPs can be represented by goal-oriented or discounted MDPs; and analyze the properties of the proposed reward functions both theoretically and empirically on two types of grid-world problems.",2404.11296,http://arxiv.org/abs/2404.11296v1,2024-04-17 12:06:17+00:00,2024-04-17 12:06:17+00:00,cs.AI,['cs.AI'],0
DUPE: Detection Undermining via Prompt Engineering for Deepfake Text,"['James Weichert', 'Chinecherem Dimobi']","As large language models (LLMs) become increasingly commonplace, concern about distinguishing between human and AI text increases as well. The growing power of these models is of particular concern to teachers, who may worry that students will use LLMs to write school assignments. Facing a technology with which they are unfamiliar, teachers may turn to publicly-available AI text detectors. Yet the accuracy of many of these detectors has not been thoroughly verified, posing potential harm to students who are falsely accused of academic dishonesty. In this paper, we evaluate three different AI text detectors-Kirchenbauer et al. watermarks, ZeroGPT, and GPTZero-against human and AI-generated essays. We find that watermarking results in a high false positive rate, and that ZeroGPT has both high false positive and false negative rates. Further, we are able to significantly increase the false negative rate of all detectors by using ChatGPT 3.5 to paraphrase the original AI-generated texts, thereby effectively bypassing the detectors.",2404.11408,http://arxiv.org/abs/2404.11408v1,2024-04-17 14:10:27+00:00,2024-04-17 14:10:27+00:00,cs.AI,['cs.AI'],1
Instantiations and Computational Aspects of Non-Flat Assumption-based Argumentation,"['Tuomo Lehtonen', 'Anna Rapberger', 'Francesca Toni', 'Markus Ulbricht', 'Johannes P. Wallner']","Most existing computational tools for assumption-based argumentation (ABA) focus on so-called flat frameworks, disregarding the more general case. In this paper, we study an instantiation-based approach for reasoning in possibly non-flat ABA. We make use of a semantics-preserving translation between ABA and bipolar argumentation frameworks (BAFs). By utilizing compilability theory, we establish that the constructed BAFs will in general be of exponential size. In order to keep the number of arguments and computational cost low, we present three ways of identifying redundant arguments. Moreover, we identify fragments of ABA which admit a poly-sized instantiation. We propose two algorithmic approaches for reasoning in possibly non-flat ABA. The first approach utilizes the BAF instantiation while the second works directly without constructing arguments. An empirical evaluation shows that the former outperforms the latter on many instances, reflecting the lower complexity of BAF reasoning. This result is in contrast to flat ABA, where direct approaches dominate instantiation-based approaches.",2404.11431,http://arxiv.org/abs/2404.11431v1,2024-04-17 14:36:47+00:00,2024-04-17 14:36:47+00:00,cs.AI,['cs.AI'],0
Prediction of Unmanned Surface Vessel Motion Attitude Based on CEEMDAN-PSO-SVM,"['Zhuoya Geng', 'Jianmei Chen', 'Wanqiang Zhu']","Unmanned boats, while navigating at sea, utilize active compensation systems to mitigate wave disturbances experienced by onboard instruments and equipment. However, there exists a lag in the measurement of unmanned boat attitudes, thus introducing unmanned boat motion attitude prediction to compensate for the lag in the signal acquisition process. This paper, based on the basic principles of waves, derives the disturbance patterns of waves on unmanned boats from the wave energy spectrum. Through simulation analysis of unmanned boat motion attitudes, motion attitude data is obtained, providing experimental data for subsequent work. A combined prediction model based on Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN), Particle Swarm Optimization (PSO), and Support Vector Machine (SVM) is designed to predict the motion attitude of unmanned boats. Simulation results validate its superior prediction accuracy compared to traditional prediction models. For example, in terms of mean absolute error, it improves by 17% compared to the EMD-PSO-SVM model.",2404.11443,http://arxiv.org/abs/2404.11443v1,2024-04-17 14:53:03+00:00,2024-04-17 14:53:03+00:00,cs.AI,['cs.AI'],17
Research on emotionally intelligent dialogue generation based on automatic dialogue system,"['Jin Wang', 'JinFei Wang', 'Shuying Dai', 'Jiqiang Yu', 'Keqin Li']","Automated dialogue systems are important applications of artificial intelligence, and traditional systems struggle to understand user emotions and provide empathetic feedback. This study integrates emotional intelligence technology into automated dialogue systems and creates a dialogue generation model with emotional intelligence through deep learning and natural language processing techniques. The model can detect and understand a wide range of emotions and specific pain signals in real time, enabling the system to provide empathetic interaction. By integrating the results of the study ""Can artificial intelligence detect pain and express pain empathy?"", the model's ability to understand the subtle elements of pain empathy has been enhanced, setting higher standards for emotional intelligence dialogue systems. The project aims to provide theoretical understanding and practical suggestions to integrate advanced emotional intelligence capabilities into dialogue systems, thereby improving user experience and interaction quality.",2404.11447,http://arxiv.org/abs/2404.11447v1,2024-04-17 14:55:03+00:00,2024-04-17 14:55:03+00:00,cs.AI,"['cs.AI', 'cs.CL']",6
Taxonomy to Regulation: A (Geo)Political Taxonomy for AI Risks and Regulatory Measures in the EU AI Act,['Sinan Arda'],"Technological innovations have shown remarkable capabilities to benefit and harm society alike. AI constitutes a democratized sophisticated technology accessible to large parts of society, including malicious actors. This work proposes a taxonomy focusing on on (geo)political risks associated with AI. It identifies 12 risks in total divided into four categories: (1) Geopolitical Pressures, (2) Malicious Usage, (3) Environmental, Social, and Ethical Risks, and (4) Privacy and Trust Violations. Incorporating a regulatory side, this paper conducts a policy assessment of the EU AI Act. Adopted in March 2023, the landmark regulation has the potential to have a positive top-down impact concerning AI risk reduction but needs regulatory adjustments to mitigate risks more comprehensively. Regulatory exceptions for open-source models, excessively high parameters for the classification of GPAI models as a systemic risk, and the exclusion of systems designed exclusively for military purposes from the regulation's obligations leave room for future action.",2404.11476,http://arxiv.org/abs/2404.11476v1,2024-04-17 15:32:56+00:00,2024-04-17 15:32:56+00:00,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG', '68T01', 'I.2.0']",0
"The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey","['Tula Masterman', 'Sandi Besen', 'Mason Sawtell', 'Alex Chao']","This survey paper examines the recent advancements in AI agent implementations, with a focus on their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution capabilities. The primary objectives of this work are to a) communicate the current capabilities and limitations of existing AI agent implementations, b) share insights gained from our observations of these systems in action, and c) suggest important considerations for future developments in AI agent design. We achieve this by providing overviews of single-agent and multi-agent architectures, identifying key patterns and divergences in design choices, and evaluating their overall impact on accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic architecture, the impact of leadership on agent systems, agent communication styles, and key phases for planning, execution, and reflection that enable robust AI agent systems.",2404.11584,http://arxiv.org/abs/2404.11584v1,2024-04-17 17:32:41+00:00,2024-04-17 17:32:41+00:00,cs.AI,"['cs.AI', 'cs.CL']",0
Spatial Context-based Self-Supervised Learning for Handwritten Text Recognition,"['Carlos Penarrubia', 'Carlos Garrido-Munoz', 'Jose J. Valero-Mas', 'Jorge Calvo-Zaragoza']","Handwritten Text Recognition (HTR) is a relevant problem in computer vision, and implies unique challenges owing to its inherent variability and the rich contextualization required for its interpretation. Despite the success of Self-Supervised Learning (SSL) in computer vision, its application to HTR has been rather scattered, leaving key SSL methodologies unexplored. This work focuses on one of them, namely Spatial Context-based SSL. We investigate how this family of approaches can be adapted and optimized for HTR and propose new workflows that leverage the unique features of handwritten text. Our experiments demonstrate that the methods considered lead to advancements in the state-of-the-art of SSL for HTR in a number of benchmark cases.",2404.11585,http://arxiv.org/abs/2404.11585v1,2024-04-17 17:33:32+00:00,2024-04-17 17:33:32+00:00,cs.AI,['cs.AI'],0
Cross-Problem Learning for Solving Vehicle Routing Problems,"['Zhuoyi Lin', 'Yaoxin Wu', 'Bangjian Zhou', 'Zhiguang Cao', 'Wen Song', 'Yingqian Zhang', 'Senthilnath Jayavelu']","Existing neural heuristics often train a deep architecture from scratch for each specific vehicle routing problem (VRP), ignoring the transferable knowledge across different VRP variants. This paper proposes the cross-problem learning to assist heuristics training for different downstream VRP variants. Particularly, we modularize neural architectures for complex VRPs into 1) the backbone Transformer for tackling the travelling salesman problem (TSP), and 2) the additional lightweight modules for processing problem-specific features in complex VRPs. Accordingly, we propose to pre-train the backbone Transformer for TSP, and then apply it in the process of fine-tuning the Transformer models for each target VRP variant. On the one hand, we fully fine-tune the trained backbone Transformer and problem-specific modules simultaneously. On the other hand, we only fine-tune small adapter networks along with the modules, keeping the backbone Transformer still. Extensive experiments on typical VRPs substantiate that 1) the full fine-tuning achieves significantly better performance than the one trained from scratch, and 2) the adapter-based fine-tuning also delivers comparable performance while being notably parameter-efficient. Furthermore, we empirically demonstrate the favorable effect of our method in terms of cross-distribution application and versatility.",2404.11677,http://arxiv.org/abs/2404.11677v1,2024-04-17 18:17:50+00:00,2024-04-17 18:17:50+00:00,cs.AI,['cs.AI'],25
A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications,"['Antonio Boiano', 'Marco Di Gennaro', 'Luca Barbieri', 'Michele Carminati', 'Monica Nicoli', 'Alessandro Redondi', 'Stefano Savazzi', 'Albert Sund Aillet', 'Diogo Reis Santos', 'Luigi Serio']","Federated Learning (FL) has emerged as a promising approach for privacy-preserving machine learning, particularly in sensitive domains such as healthcare. In this context, the TRUSTroke project aims to leverage FL to assist clinicians in ischemic stroke prediction. This paper provides an overview of the TRUSTroke FL network infrastructure. The proposed architecture adopts a client-server model with a central Parameter Server (PS). We introduce a Docker-based design for the client nodes, offering a flexible solution for implementing FL processes in clinical settings. The impact of different communication protocols (HTTP or MQTT) on FL network operation is analyzed, with MQTT selected for its suitability in FL scenarios. A control plane to support the main operations required by FL processes is also proposed. The paper concludes with an analysis of security aspects of the FL architecture, addressing potential threats and proposing mitigation strategies to increase the trustworthiness level.",2404.11698,http://arxiv.org/abs/2404.11698v1,2024-04-17 18:55:41+00:00,2024-04-17 18:55:41+00:00,cs.AI,"['cs.AI', 'cs.DC']",0
A Survey on Semantic Modeling for Building Energy Management,"['Miracle Aniakor', 'Vinicius V. Cogo', 'Pedro M. Ferreira']","Buildings account for a substantial portion of global energy consumption. Reducing buildings' energy usage primarily involves obtaining data from building systems and environment, which are instrumental in assessing and optimizing the building's performance. However, as devices from various manufacturers represent their data in unique ways, this disparity introduces challenges for semantic interoperability and creates obstacles in developing scalable building applications. This survey explores the leading semantic modeling techniques deployed for energy management in buildings. Furthermore, it aims to offer tangible use cases for applying semantic models, shedding light on the pivotal concepts and limitations intrinsic to each model. Our findings will assist researchers in discerning the appropriate circumstances and methodologies for employing these models in various use cases.",2404.11716,http://arxiv.org/abs/2404.11716v1,2024-04-17 20:10:43+00:00,2024-04-17 20:10:43+00:00,cs.AI,"['cs.AI', 'I.2.4; C.m; H.m']",0
Enhancing Q&A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study,"['Zooey Nguyen', 'Anthony Annunziata', 'Vinh Luong', 'Sang Dinh', 'Quynh Le', 'Anh Hai Ha', 'Chanh Le', 'Hong An Phan', 'Shruti Raghavan', 'Christopher Nguyen']","This paper investigates the impact of domain-specific model fine-tuning and of reasoning mechanisms on the performance of question-answering (Q&A) systems powered by large language models (LLMs) and Retrieval-Augmented Generation (RAG). Using the FinanceBench SEC financial filings dataset, we observe that, for RAG, combining a fine-tuned embedding model with a fine-tuned LLM achieves better accuracy than generic models, with relatively greater gains attributable to fine-tuned embedding models. Additionally, employing reasoning iterations on top of RAG delivers an even bigger jump in performance, enabling the Q&A systems to get closer to human-expert quality. We discuss the implications of such findings, propose a structured technical design space capturing major technical components of Q&A AI, and provide recommendations for making high-impact technical choices for such components. We plan to follow up on this work with actionable guides for AI teams and further investigations into the impact of domain-specific augmentation in RAG and into agentic AI capabilities such as advanced planning and reasoning.",2404.11792,http://arxiv.org/abs/2404.11792v1,2024-04-17 23:00:03+00:00,2024-04-17 23:00:03+00:00,cs.AI,['cs.AI'],0
CAUS: A Dataset for Question Generation based on Human Cognition Leveraging Large Language Models,"['Minjung Shin', 'Donghyun Kim', 'Jeh-Kwang Ryu']","We introduce the CAUS (Curious About Uncertain Scene) dataset, designed to enable Large Language Models, specifically GPT-4, to emulate human cognitive processes for resolving uncertainties. Leveraging this dataset, we investigate the potential of LLMs to engage in questioning effectively. Our approach involves providing scene descriptions embedded with uncertainties to stimulate the generation of reasoning and queries. The queries are then classified according to multi-dimensional criteria. All procedures are facilitated by a collaborative system involving both LLMs and human researchers. Our results demonstrate that GPT-4 can effectively generate pertinent questions and grasp their nuances, particularly when given appropriate context and instructions. The study suggests that incorporating human-like questioning into AI models improves their ability to manage uncertainties, paving the way for future advancements in Artificial Intelligence (AI).",2404.11835,http://arxiv.org/abs/2404.11835v1,2024-04-18 01:31:19+00:00,2024-04-18 01:31:19+00:00,cs.AI,['cs.AI'],0
SGRU: A High-Performance Structured Gated Recurrent Unit for Traffic Flow Prediction,"['Wenfeng Zhang', 'Xin Li', 'Anqi Li', 'Xiaoting Huang', 'Ti Wang', 'Honglei Gao']","Traffic flow prediction is an essential task in constructing smart cities and is a typical Multivariate Time Series (MTS) Problem. Recent research has abandoned Gated Recurrent Units (GRU) and utilized dilated convolutions or temporal slicing for feature extraction, and they have the following drawbacks: (1) Dilated convolutions fail to capture the features of adjacent time steps, resulting in the loss of crucial transitional data. (2) The connections within the same temporal slice are strong, while the connections between different temporal slices are too loose. In light of these limitations, we emphasize the importance of analyzing a complete time series repeatedly and the crucial role of GRU in MTS. Therefore, we propose SGRU: Structured Gated Recurrent Units, which involve structured GRU layers and non-linear units, along with multiple layers of time embedding to enhance the model's fitting performance. We evaluate our approach on four publicly available California traffic datasets: PeMS03, PeMS04, PeMS07, and PeMS08 for regression prediction. Experimental results demonstrate that our model outperforms baseline models with average improvements of 11.7%, 18.6%, 18.5%, and 12.0% respectively.",2404.11854,http://arxiv.org/abs/2404.11854v1,2024-04-18 02:15:40+00:00,2024-04-18 02:15:40+00:00,cs.AI,['cs.AI'],6
Concept Induction using LLMs: a user experiment for assessment,"['Adrita Barua', 'Cara Widmer', 'Pascal Hitzler']","Explainable Artificial Intelligence (XAI) poses a significant challenge in providing transparent and understandable insights into complex AI models. Traditional post-hoc algorithms, while useful, often struggle to deliver interpretable explanations. Concept-based models offer a promising avenue by incorporating explicit representations of concepts to enhance interpretability. However, existing research on automatic concept discovery methods is often limited by lower-level concepts, costly human annotation requirements, and a restricted domain of background knowledge. In this study, we explore the potential of a Large Language Model (LLM), specifically GPT-4, by leveraging its domain knowledge and common-sense capability to generate high-level concepts that are meaningful as explanations for humans, for a specific setting of image classification. We use minimal textual object information available in the data via prompting to facilitate this process. To evaluate the output, we compare the concepts generated by the LLM with two other methods: concepts generated by humans and the ECII heuristic concept induction system. Since there is no established metric to determine the human understandability of concepts, we conducted a human study to assess the effectiveness of the LLM-generated concepts. Our findings indicate that while human-generated explanations remain superior, concepts derived from GPT-4 are more comprehensible to humans compared to those generated by ECII.",2404.11875,http://arxiv.org/abs/2404.11875v1,2024-04-18 03:22:02+00:00,2024-04-18 03:22:02+00:00,cs.AI,['cs.AI'],2
"Enhancing Financial Inclusion and Regulatory Challenges: A Critical Analysis of Digital Banks and Alternative Lenders Through Digital Platforms, Machine Learning, and Large Language Models Integration",['Luke Lee'],"This paper explores the dual impact of digital banks and alternative lenders on financial inclusion and the regulatory challenges posed by their business models. It discusses the integration of digital platforms, machine learning (ML), and Large Language Models (LLMs) in enhancing financial services accessibility for underserved populations. Through a detailed analysis of operational frameworks and technological infrastructures, this research identifies key mechanisms that facilitate broader financial access and mitigate traditional barriers. Additionally, the paper addresses significant regulatory concerns involving data privacy, algorithmic bias, financial stability, and consumer protection. Employing a mixed-methods approach, which combines quantitative financial data analysis with qualitative insights from industry experts, this paper elucidates the complexities of leveraging digital technology to foster financial inclusivity. The findings underscore the necessity of evolving regulatory frameworks that harmonize innovation with comprehensive risk management. This paper concludes with policy recommendations for regulators, financial institutions, and technology providers, aiming to cultivate a more inclusive and stable financial ecosystem through prudent digital technology integration.",2404.11898,http://arxiv.org/abs/2404.11898v1,2024-04-18 05:00:53+00:00,2024-04-18 05:00:53+00:00,cs.AI,['cs.AI'],0
Sampling-based Pareto Optimization for Chance-constrained Monotone Submodular Problems,"['Xiankun Yan', 'Aneta Neumann', 'Frank Neumann']","Recently surrogate functions based on the tail inequalities were developed to evaluate the chance constraints in the context of evolutionary computation and several Pareto optimization algorithms using these surrogates were successfully applied in optimizing chance-constrained monotone submodular problems. However, the difference in performance between algorithms using the surrogates and those employing the direct sampling-based evaluation remains unclear. Within the paper, a sampling-based method is proposed to directly evaluate the chance constraint. Furthermore, to address the problems with more challenging settings, an enhanced GSEMO algorithm integrated with an adaptive sliding window, called ASW-GSEMO, is introduced. In the experiments, the ASW-GSEMO employing the sampling-based approach is tested on the chance-constrained version of the maximum coverage problem with different settings. Its results are compared with those from other algorithms using different surrogate functions. The experimental findings indicate that the ASW-GSEMO with the sampling-based evaluation approach outperforms other algorithms, highlighting that the performances of algorithms using different evaluation methods are comparable. Additionally, the behaviors of ASW-GSEMO are visualized to explain the distinctions between it and the algorithms utilizing the surrogate functions.",2404.11907,http://arxiv.org/abs/2404.11907v1,2024-04-18 05:15:20+00:00,2024-04-18 05:15:20+00:00,cs.AI,['cs.AI'],15
Toward Short-Term Glucose Prediction Solely Based on CGM Time Series,"['Ming Cheng', 'Xingjian Diao', 'Ziyi Zhou', 'Yanjun Cui', 'Wenjun Liu', 'Shitong Cheng']","The global diabetes epidemic highlights the importance of maintaining good glycemic control. Glucose prediction is a fundamental aspect of diabetes management, facilitating real-time decision-making. Recent research has introduced models focusing on long-term glucose trend prediction, which are unsuitable for real-time decision-making and result in delayed responses. Conversely, models designed to respond to immediate glucose level changes cannot analyze glucose variability comprehensively. Moreover, contemporary research generally integrates various physiological parameters (e.g. insulin doses, food intake, etc.), which inevitably raises data privacy concerns. To bridge such a research gap, we propose TimeGlu -- an end-to-end pipeline for short-term glucose prediction solely based on CGM time series data. We implement four baseline methods to conduct a comprehensive comparative analysis of the model's performance. Through extensive experiments on two contrasting datasets (CGM Glucose and Colas dataset), TimeGlu achieves state-of-the-art performance without the need for additional personal data from patients, providing effective guidance for real-world diabetic glucose management.",2404.11924,http://arxiv.org/abs/2404.11924v1,2024-04-18 06:02:12+00:00,2024-04-18 06:02:12+00:00,cs.AI,['cs.AI'],0
©Plug-in Authorization for Human Content Copyright Protection in Text-to-Image Model,"['Chao Zhou', 'Huishuai Zhang', 'Jiang Bian', 'Weiming Zhang', 'Nenghai Yu']","This paper addresses the contentious issue of copyright infringement in images generated by text-to-image models, sparking debates among AI developers, content creators, and legal entities. State-of-the-art models create high-quality content without crediting original creators, causing concern in the artistic community. To mitigate this, we propose the \copyright Plug-in Authorization framework, introducing three operations: addition, extraction, and combination. Addition involves training a \copyright plug-in for specific copyright, facilitating proper credit attribution. Extraction allows creators to reclaim copyright from infringing models, and combination enables users to merge different \copyright plug-ins. These operations act as permits, incentivizing fair use and providing flexibility in authorization. We present innovative approaches,""Reverse LoRA"" for extraction and ""EasyMerge"" for seamless combination. Experiments in artist-style replication and cartoon IP recreation demonstrate \copyright plug-ins' effectiveness, offering a valuable solution for human copyright protection in the age of generative AIs.",2404.11962,http://arxiv.org/abs/2404.11962v1,2024-04-18 07:48:00+00:00,2024-04-18 07:48:00+00:00,cs.AI,"['cs.AI', 'cs.CR', 'cs.CV', 'cs.LG']",0
From Language Models to Practical Self-Improving Computer Agents,['Alex Sheng'],"We develop a simple and straightforward methodology to create AI computer agents that can carry out diverse computer tasks and self-improve by developing tools and augmentations to enable themselves to solve increasingly complex tasks. As large language models (LLMs) have been shown to benefit from non-parametric augmentations, a significant body of recent work has focused on developing software that augments LLMs with various capabilities. Rather than manually developing static software to augment LLMs through human engineering effort, we propose that an LLM agent can systematically generate software to augment itself. We show, through a few case studies, that a minimal querying loop with appropriate prompt engineering allows an LLM to generate and use various augmentations, freely extending its own capabilities to carry out real-world computer tasks. Starting with only terminal access, we prompt an LLM agent to augment itself with retrieval, internet search, web navigation, and text editor capabilities. The agent effectively uses these various tools to solve problems including automated software development and web-based tasks.",2404.11964,http://arxiv.org/abs/2404.11964v1,2024-04-18 07:50:10+00:00,2024-04-18 07:50:10+00:00,cs.AI,"['cs.AI', '68T01', 'I.2.0']",0
"Exploring the landscape of large language models: Foundations, techniques, and challenges","['Milad Moradi', 'Ke Yan', 'David Colwell', 'Matthias Samwald', 'Rhona Asgari']","In this review paper, we delve into the realm of Large Language Models (LLMs), covering their foundational principles, diverse applications, and nuanced training processes. The article sheds light on the mechanics of in-context learning and a spectrum of fine-tuning approaches, with a special focus on methods that optimize efficiency in parameter usage. Additionally, it explores how LLMs can be more closely aligned with human preferences through innovative reinforcement learning frameworks and other novel methods that incorporate human feedback. The article also examines the emerging technique of retrieval augmented generation, integrating external knowledge into LLMs. The ethical dimensions of LLM deployment are discussed, underscoring the need for mindful and responsible application. Concluding with a perspective on future research trajectories, this review offers a succinct yet comprehensive overview of the current state and emerging trends in the evolving landscape of LLMs, serving as an insightful guide for both researchers and practitioners in artificial intelligence.",2404.11973,http://arxiv.org/abs/2404.11973v1,2024-04-18 08:01:20+00:00,2024-04-18 08:01:20+00:00,cs.AI,['cs.AI'],0
The Emerging AI Divide in the United States,"['Madeleine I. G. Daepp', 'Scott Counts']","The digital divide describes disparities in access to and usage of digital tooling between social and economic groups. Emerging generative artificial intelligence tools, which strongly affect productivity, could magnify the impact of these divides. However, the affordability, multi-modality, and multilingual capabilities of these tools could also make them more accessible to diverse users in comparison with previous forms of digital tooling. In this study, we characterize spatial differences in U.S. residents' knowledge of a new generative AI tool, ChatGPT, through an analysis of state- and county-level search query data. In the first six months after the tool's release, we observe the highest rates of users searching for ChatGPT in West Coast states and persistently low rates of search in Appalachian and Gulf states. Counties with the highest rates of search are relatively more urbanized and have proportionally more educated, more economically advantaged, and more Asian residents in comparison with other counties or with the U.S. average. In multilevel models adjusting for socioeconomic and demographic factors as well as industry makeup, education is the strongest positive predictor of rates of search for generative AI tooling. Although generative AI technologies may be novel, early differences in uptake appear to be following familiar paths of digital marginalization.",2404.11988,http://arxiv.org/abs/2404.11988v1,2024-04-18 08:33:35+00:00,2024-04-18 08:33:35+00:00,cs.AI,"['cs.AI', 'cs.CY', 'K.4.2']",0
DST-GTN: Dynamic Spatio-Temporal Graph Transformer Network for Traffic Forecasting,"['Songtao Huang', 'Hongjin Song', 'Tianqi Jiang', 'Akbar Telikani', 'Jun Shen', 'Qingguo Zhou', 'Binbin Yong', 'Qiang Wu']","Accurate traffic forecasting is essential for effective urban planning and congestion management. Deep learning (DL) approaches have gained colossal success in traffic forecasting but still face challenges in capturing the intricacies of traffic dynamics. In this paper, we identify and address this challenges by emphasizing that spatial features are inherently dynamic and change over time. A novel in-depth feature representation, called Dynamic Spatio-Temporal (Dyn-ST) features, is introduced, which encapsulates spatial characteristics across varying times. Moreover, a Dynamic Spatio-Temporal Graph Transformer Network (DST-GTN) is proposed by capturing Dyn-ST features and other dynamic adjacency relations between intersections. The DST-GTN can model dynamic ST relationships between nodes accurately and refine the representation of global and local ST characteristics by adopting adaptive weights in low-pass and all-pass filters, enabling the extraction of Dyn-ST features from traffic time-series data. Through numerical experiments on public datasets, the DST-GTN achieves state-of-the-art performance for a range of traffic forecasting tasks and demonstrates enhanced stability.",2404.11996,http://arxiv.org/abs/2404.11996v1,2024-04-18 08:44:52+00:00,2024-04-18 08:44:52+00:00,cs.AI,['cs.AI'],16
X-Light: Cross-City Traffic Signal Control Using Transformer on Transformer as Meta Multi-Agent Reinforcement Learner,"['Haoyuan Jiang', 'Ziyue Li', 'Hua Wei', 'Xuantang Xiong', 'Jingqing Ruan', 'Jiaming Lu', 'Hangyu Mao', 'Rui Zhao']","The effectiveness of traffic light control has been significantly improved by current reinforcement learning-based approaches via better cooperation among multiple traffic lights. However, a persisting issue remains: how to obtain a multi-agent traffic signal control algorithm with remarkable transferability across diverse cities? In this paper, we propose a Transformer on Transformer (TonT) model for cross-city meta multi-agent traffic signal control, named as X-Light: We input the full Markov Decision Process trajectories, and the Lower Transformer aggregates the states, actions, rewards among the target intersection and its neighbors within a city, and the Upper Transformer learns the general decision trajectories across different cities. This dual-level approach bolsters the model's robust generalization and transferability. Notably, when directly transferring to unseen scenarios, ours surpasses all baseline methods with +7.91% on average, and even +16.3% in some cases, yielding the best results.",2404.1209,http://arxiv.org/abs/2404.12090v1,2024-04-18 11:17:58+00:00,2024-04-18 11:17:58+00:00,cs.AI,['cs.AI'],11
Warped Time Series Anomaly Detection,"['Charlotte Lacoquelle', 'Xavier Pucel', 'Louise Travé-Massuyès', 'Axel Reymonet', 'Benoît Enaux']","This paper addresses the problem of detecting time series outliers, focusing on systems with repetitive behavior, such as industrial robots operating on production lines.Notable challenges arise from the fact that a task performed multiple times may exhibit different duration in each repetition and that the time series reported by the sensors are irregularly sampled because of data gaps. The anomaly detection approach presented in this paper consists of three stages.The first stage identifies the repetitive cycles in the lengthy time series and segments them into individual time series corresponding to one task cycle, while accounting for possible temporal distortions.The second stage computes a prototype for the cycles using a GPU-based barycenter algorithm, specifically tailored for very large time series.The third stage uses the prototype to detect abnormal cycles by computing an anomaly score for each cycle.The overall approach, named WarpEd Time Series ANomaly Detection (WETSAND), makes use of the Dynamic Time Warping algorithm and its variants because they are suited to the distorted nature of the time series.The experiments show that \wetsand scales to large signals, computes human-friendly prototypes, works with very little data, and outperforms some general purpose anomaly detection approaches such as autoencoders.",2404.12134,http://arxiv.org/abs/2404.12134v1,2024-04-18 12:35:24+00:00,2024-04-18 12:35:24+00:00,cs.AI,"['cs.AI', 'eess.SP']",0
Character is Destiny: Can Large Language Models Simulate Persona-Driven Decisions in Role-Playing?,"['Rui Xu', 'Xintao Wang', 'Jiangjie Chen', 'Siyu Yuan', 'Xinfeng Yuan', 'Jiaqing Liang', 'Zulong Chen', 'Xiaoqing Dong', 'Yanghua Xiao']","Can Large Language Models substitute humans in making important decisions? Recent research has unveiled the potential of LLMs to role-play assigned personas, mimicking their knowledge and linguistic habits. However, imitative decision-making requires a more nuanced understanding of personas. In this paper, we benchmark the ability of LLMs in persona-driven decision-making. Specifically, we investigate whether LLMs can predict characters' decisions provided with the preceding stories in high-quality novels. Leveraging character analyses written by literary experts, we construct a dataset LIFECHOICE comprising 1,401 character decision points from 395 books. Then, we conduct comprehensive experiments on LIFECHOICE, with various LLMs and methods for LLM role-playing. The results demonstrate that state-of-the-art LLMs exhibit promising capabilities in this task, yet there is substantial room for improvement. Hence, we further propose the CHARMAP method, which achieves a 6.01% increase in accuracy via persona-based memory retrieval. We will make our datasets and code publicly available.",2404.12138,http://arxiv.org/abs/2404.12138v1,2024-04-18 12:40:59+00:00,2024-04-18 12:40:59+00:00,cs.AI,['cs.AI'],0
AccidentBlip2: Accident Detection With Multi-View MotionBlip2,"['Yihua Shao', 'Hongyi Cai', 'Wenxin Long', 'Weiyi Lang', 'Zhe Wang', 'Haoran Wu', 'Yan Wang', 'Yang Yang', 'Zhen Lei']","Multimodal Large Language Models (MLLMs) have shown outstanding capabilities in many areas of multimodal reasoning. Therefore, we use the reasoning ability of Multimodal Large Language Models for environment description and scene understanding in complex transportation environments. In this paper, we propose AccidentBlip2, a multimodal large language model that can predict in real time whether an accident risk will occur. Our approach involves feature extraction based on the temporal scene of the six-view surround view graphs and temporal inference using the temporal blip framework through the vision transformer. We then input the generated temporal token into the MLLMs for inference to determine whether an accident will occur or not. Since AccidentBlip2 does not rely on any BEV images and LiDAR, the number of inference parameters and the inference cost of MLLMs can be significantly reduced, and it also does not incur a large training overhead during training. AccidentBlip2 outperforms existing solutions on the DeepAccident dataset and can also provide a reference solution for end-to-end automated driving accident prediction.",2404.12149,http://arxiv.org/abs/2404.12149v1,2024-04-18 12:54:25+00:00,2024-04-18 12:54:25+00:00,cs.AI,['cs.AI'],16
An Adaptive Metaheuristic Framework for Changing Environments,['Bestoun S. Ahmed'],"The rapidly changing landscapes of modern optimization problems require algorithms that can be adapted in real-time. This paper introduces an Adaptive Metaheuristic Framework (AMF) designed for dynamic environments. It is capable of intelligently adapting to changes in the problem parameters. The AMF combines a dynamic representation of problems, a real-time sensing system, and adaptive techniques to navigate continuously changing optimization environments. Through a simulated dynamic optimization problem, the AMF's capability is demonstrated to detect environmental changes and proactively adjust its search strategy. This framework utilizes a differential evolution algorithm that is improved with an adaptation module that adjusts solutions in response to detected changes. The capability of the AMF to adjust is tested through a series of iterations, demonstrating its resilience and robustness in sustaining solution quality despite the problem's development. The effectiveness of AMF is demonstrated through a series of simulations on a dynamic optimization problem. Robustness and agility characterize the algorithm's performance, as evidenced by the presented fitness evolution and solution path visualizations. The findings show that AMF is a practical solution to dynamic optimization and a major step forward in the creation of algorithms that can handle the unpredictability of real-world problems.",2404.12185,http://arxiv.org/abs/2404.12185v1,2024-04-18 13:47:53+00:00,2024-04-18 13:47:53+00:00,cs.AI,['cs.AI'],0
Relationship Discovery for Drug Recommendation,"['Xiang Li', 'Shunpan Liang', 'Yu Lei', 'Chen Li', 'Yulei Hou', 'Tengfei Ma']","Medication recommendation systems are designed to deliver personalized drug suggestions that are closely aligned with individual patient needs. Previous studies have primarily concentrated on developing medication embeddings, achieving significant progress. Nonetheless, these approaches often fall short in accurately reflecting individual patient profiles, mainly due to challenges in distinguishing between various patient conditions and the inability to establish precise correlations between specific conditions and appropriate medications. In response to these issues, we introduce DisMed, a model that focuses on patient conditions to enhance personalization. DisMed employs causal inference to discern clear, quantifiable causal links. It then examines patient conditions in depth, recognizing and adapting to the evolving nuances of these conditions, and mapping them directly to corresponding medications. Additionally, DisMed leverages data from multiple patient visits to propose combinations of medications. Comprehensive testing on real-world datasets demonstrates that DisMed not only improves the customization of patient profiles but also surpasses leading models in both precision and safety.",2404.12228,http://arxiv.org/abs/2404.12228v1,2024-04-18 14:44:08+00:00,2024-04-18 14:44:08+00:00,cs.AI,"['cs.AI', 'cs.LG']",4
Learning the Domain Specific Inverse NUFFT for Accelerated Spiral MRI using Diffusion Models,"['Trevor J. Chan', 'Chamith S. Rajapakse']","Deep learning methods for accelerated MRI achieve state-of-the-art results but largely ignore additional speedups possible with noncartesian sampling trajectories. To address this gap, we created a generative diffusion model-based reconstruction algorithm for multi-coil highly undersampled spiral MRI. This model uses conditioning during training as well as frequency-based guidance to ensure consistency between images and measurements. Evaluated on retrospective data, we show high quality (structural similarity > 0.87) in reconstructed images with ultrafast scan times (0.02 seconds for a 2D image). We use this algorithm to identify a set of optimal variable-density spiral trajectories and show large improvements in image quality compared to conventional reconstruction using the non-uniform fast Fourier transform. By combining efficient spiral sampling trajectories, multicoil imaging, and deep learning reconstruction, these methods could enable the extremely high acceleration factors needed for real-time 3D imaging.",2404.12361,http://arxiv.org/abs/2404.12361v1,2024-04-18 17:40:23+00:00,2024-04-18 17:40:23+00:00,cs.AI,"['cs.AI', 'physics.med-ph']",0
Music Enhancement with Deep Filters: A Technical Report for The ICASSP 2024 Cadenza Challenge,"['Keren Shao', 'Ke Chen', 'Shlomo Dubnov']","In this challenge, we disentangle the deep filters from the original DeepfilterNet and incorporate them into our Spec-UNet-based network to further improve a hybrid Demucs (hdemucs) based remixing pipeline. The motivation behind the use of the deep filter component lies at its potential in better handling temporal fine structures. We demonstrate an incremental improvement in both the Signal-to-Distortion Ratio (SDR) and the Hearing Aid Audio Quality Index (HAAQI) metrics when comparing the performance of hdemucs against different versions of our model.",2404.11116,http://arxiv.org/abs/2404.11116v1,2024-04-17 07:01:29+00:00,2024-04-17 07:01:29+00:00,cs.SD,"['cs.SD', 'cs.AI', 'cs.LG', 'cs.MM', 'eess.AS']",0
Mapping back and forth between model predictive control and neural networks,"['Ross Drummond', 'Pablo R Baldivieso-Monasterios', 'Giorgio Valmorbida']","Model predictive control (MPC) for linear systems with quadratic costs and linear constraints is shown to admit an exact representation as an implicit neural network. A method to ""unravel"" the implicit neural network of MPC into an explicit one is also introduced. As well as building links between model-based and data-driven control, these results emphasize the capability of implicit neural networks for representing solutions of optimisation problems, as such problems are themselves implicitly defined functions.",2404.1203,http://arxiv.org/abs/2404.12030v1,2024-04-18 09:29:08+00:00,2024-04-18 09:29:08+00:00,eess.SY,"['eess.SY', 'cs.AI', 'cs.SY']",0
Function Approximation for Reinforcement Learning Controller for Energy from Spread Waves,"['Soumyendu Sarkar', 'Vineet Gundecha', 'Sahand Ghorbanpour', 'Alexander Shmakov', 'Ashwin Ramesh Babu', 'Avisek Naug', 'Alexandre Pichard', 'Mathieu Cocho']","The industrial multi-generator Wave Energy Converters (WEC) must handle multiple simultaneous waves coming from different directions called spread waves. These complex devices in challenging circumstances need controllers with multiple objectives of energy capture efficiency, reduction of structural stress to limit maintenance, and proactive protection against high waves. The Multi-Agent Reinforcement Learning (MARL) controller trained with the Proximal Policy Optimization (PPO) algorithm can handle these complexities. In this paper, we explore different function approximations for the policy and critic networks in modeling the sequential nature of the system dynamics and find that they are key to better performance. We investigated the performance of a fully connected neural network (FCN), LSTM, and Transformer model variants with varying depths and gated residual connections. Our results show that the transformer model of moderate depth with gated residual connections around the multi-head attention, multi-layer perceptron, and the transformer block (STrXL) proposed in this paper is optimal and boosts energy efficiency by an average of 22.1% for these complex spread waves over the existing spring damper (SD) controller. Furthermore, unlike the default SD controller, the transformer controller almost eliminated the mechanical stress from the rotational yaw motion for angled waves. Demo: https://tinyurl.com/yueda3jh",2404.10991,http://arxiv.org/abs/2404.10991v1,2024-04-17 02:04:10+00:00,2024-04-17 02:04:10+00:00,cs.AI,"['cs.AI', 'cs.LG', 'cs.SY', 'eess.SY']",6
Empowering Large Language Models on Robotic Manipulation with Affordance Prompting,"['Guangran Cheng', 'Chuheng Zhang', 'Wenzhe Cai', 'Li Zhao', 'Changyin Sun', 'Jiang Bian']","While large language models (LLMs) are successful in completing various language processing tasks, they easily fail to interact with the physical world by generating control sequences properly. We find that the main reason is that LLMs are not grounded in the physical world. Existing LLM-based approaches circumvent this problem by relying on additional pre-defined skills or pre-trained sub-policies, making it hard to adapt to new tasks. In contrast, we aim to address this problem and explore the possibility to prompt pre-trained LLMs to accomplish a series of robotic manipulation tasks in a training-free paradigm. Accordingly, we propose a framework called LLM+A(ffordance) where the LLM serves as both the sub-task planner (that generates high-level plans) and the motion controller (that generates low-level control sequences). To ground these plans and control sequences on the physical world, we develop the affordance prompting technique that stimulates the LLM to 1) predict the consequences of generated plans and 2) generate affordance values for relevant objects. Empirically, we evaluate the effectiveness of LLM+A in various language-conditioned robotic manipulation tasks, which show that our approach substantially improves performance by enhancing the feasibility of generated plans and control and can easily generalize to different environments.",2404.11027,http://arxiv.org/abs/2404.11027v1,2024-04-17 03:06:32+00:00,2024-04-17 03:06:32+00:00,cs.AI,['cs.AI'],3
Lightweight Unsupervised Federated Learning with Pretrained Vision Language Model,"['Hao Yan', 'Yuhong Guo']","Federated learning aims to tackle the ``isolated data island"" problem, where it trains a collective model from physically isolated clients while safeguarding the privacy of users' data. However, supervised federated learning necessitates that each client labels their data for training, which can be both time-consuming and resource-intensive, and may even be impractical for edge devices. Moreover, the training and transmission of deep models present challenges to the computation and communication capabilities of the clients. To address these two inherent challenges in supervised federated learning, we propose a novel lightweight unsupervised federated learning approach that leverages unlabeled data on each client to perform lightweight model training and communication by harnessing pretrained vision-language models, such as CLIP. By capitalizing on the zero-shot prediction capability and the well-trained image encoder of the pre-trained CLIP model, we have carefully crafted an efficient and resilient self-training approach. This method refines the initial zero-shot predicted pseudo-labels of unlabeled instances through the sole training of a linear classifier on top of the fixed image encoder. Additionally, to address data heterogeneity within each client, we propose a class-balanced text feature sampling strategy for generating synthetic instances in the feature space to support local training. Experiments are conducted on multiple benchmark datasets. The experimental results demonstrate that our proposed method greatly enhances model performance in comparison to CLIP's zero-shot predictions and even outperforms supervised federated learning benchmark methods given limited computational and communication overhead.",2404.11046,http://arxiv.org/abs/2404.11046v1,2024-04-17 03:42:48+00:00,2024-04-17 03:42:48+00:00,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']",0
Self-adaptive PSRO: Towards an Automatic Population-based Game Solver,"['Pengdeng Li', 'Shuxin Li', 'Chang Yang', 'Xinrun Wang', 'Xiao Huang', 'Hau Chan', 'Bo An']","Policy-Space Response Oracles (PSRO) as a general algorithmic framework has achieved state-of-the-art performance in learning equilibrium policies of two-player zero-sum games. However, the hand-crafted hyperparameter value selection in most of the existing works requires extensive domain knowledge, forming the main barrier to applying PSRO to different games. In this work, we make the first attempt to investigate the possibility of self-adaptively determining the optimal hyperparameter values in the PSRO framework. Our contributions are three-fold: (1) Using several hyperparameters, we propose a parametric PSRO that unifies the gradient descent ascent (GDA) and different PSRO variants. (2) We propose the self-adaptive PSRO (SPSRO) by casting the hyperparameter value selection of the parametric PSRO as a hyperparameter optimization (HPO) problem where our objective is to learn an HPO policy that can self-adaptively determine the optimal hyperparameter values during the running of the parametric PSRO. (3) To overcome the poor performance of online HPO methods, we propose a novel offline HPO approach to optimize the HPO policy based on the Transformer architecture. Experiments on various two-player zero-sum games demonstrate the superiority of SPSRO over different baselines.",2404.11144,http://arxiv.org/abs/2404.11144v1,2024-04-17 07:40:57+00:00,2024-04-17 07:40:57+00:00,cs.AI,"['cs.AI', 'cs.GT', 'cs.MA']",26
Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients,['Nantika Nguycharoen'],"As the global population ages, the incidence of Chronic Kidney Disease (CKD) is rising. CKD often remains asymptomatic until advanced stages, which significantly burdens both the healthcare system and patient quality of life. This research developed an explainable machine learning system for predicting CKD in patients with cardiovascular risks, utilizing medical history and laboratory data. The Random Forest model achieved the highest sensitivity of 88.2%. The study introduces a comprehensive explainability framework that extends beyond traditional feature importance methods, incorporating global and local interpretations, bias inspection, biomedical relevance, and safety assessments. Key predictive features identified in global interpretation were the use of diabetic and ACEI/ARB medications, and initial eGFR values. Local interpretation provided model insights through counterfactual explanations, which aligned with other system parts. After conducting a bias inspection, it was found that the initial eGFR values and CKD predictions exhibited some bias, but no significant gender bias was identified. The model's logic, extracted by scoped rules, was confirmed to align with existing medical literature. The safety assessment tested potentially dangerous cases and confirmed that the model behaved safely. This system enhances the explainability, reliability, and accountability of the model, promoting its potential integration into healthcare settings and compliance with upcoming regulatory standards, and showing promise for broader applications in healthcare machine learning.",2404.11148,http://arxiv.org/abs/2404.11148v1,2024-04-17 07:59:33+00:00,2024-04-17 07:59:33+00:00,cs.AI,"['cs.AI', 'cs.LG', 'J.3; I.2.6']",0
CAGE: Causality-Aware Shapley Value for Global Explanations,"['Nils Ole Breuer', 'Andreas Sauter', 'Majid Mohammadi', 'Erman Acar']","As Artificial Intelligence (AI) is having more influence on our everyday lives, it becomes important that AI-based decisions are transparent and explainable. As a consequence, the field of eXplainable AI (or XAI) has become popular in recent years. One way to explain AI models is to elucidate the predictive importance of the input features for the AI model in general, also referred to as global explanations. Inspired by cooperative game theory, Shapley values offer a convenient way for quantifying the feature importance as explanations. However many methods based on Shapley values are built on the assumption of feature independence and often overlook causal relations of the features which could impact their importance for the ML model. Inspired by studies of explanations at the local level, we propose CAGE (Causally-Aware Shapley Values for Global Explanations). In particular, we introduce a novel sampling procedure for out-coalition features that respects the causal relations of the input features. We derive a practical approach that incorporates causal knowledge into global explanation and offers the possibility to interpret the predictive feature importance considering their causal relation. We evaluate our method on synthetic data and real-world data. The explanations from our approach suggest that they are not only more intuitive but also more faithful compared to previous global explanation methods.",2404.11208,http://arxiv.org/abs/2404.11208v1,2024-04-17 09:43:54+00:00,2024-04-17 09:43:54+00:00,cs.AI,['cs.AI'],0
RD2Bench: Toward Data-Centric Automatic R&D,"['Haotian Chen', 'Xinjie Shen', 'Zeqi Ye', 'Xiao Yang', 'Xu Yang', 'Weiqing Liu', 'Jiang Bian']","The progress of humanity is driven by those successful discoveries accompanied by countless failed experiments. Researchers often seek the potential research directions by reading and then verifying them through experiments. The process imposes a significant burden on researchers. In the past decade, the data-driven black-box deep learning method demonstrates its effectiveness in a wide range of real-world scenarios, which exacerbates the experimental burden of researchers and thus renders the potential successful discoveries veiled. Therefore, automating such a research and development (R&D) process is an urgent need. In this paper, we serve as the first effort to formalize the goal by proposing a Real-world Data-centric automatic R&D Benchmark, namely RD2Bench. RD2Bench benchmarks all the operations in data-centric automatic R&D (D-CARD) as a whole to navigate future work toward our goal directly. We focuses on evaluating the interaction and synergistic effects of various model capabilities and aiding to select the well-performed trustworthy models. Although RD2Bench is very challenging to the state-of-the-art (SOTA) large language model (LLM) named GPT-4, indicating ample research opportunities and more research efforts, LLMs possess promising potential to bring more significant development to D-CARD: They are able to implement some simple methods without adopting any additional techniques. We appeal to future work to take developing techniques for tackling automatic R&D into consideration, thus bringing the opportunities of the potential revolutionary upgrade to human productivity.",2404.11276,http://arxiv.org/abs/2404.11276v1,2024-04-17 11:33:21+00:00,2024-04-17 11:33:21+00:00,cs.AI,"['cs.AI', 'q-fin.GN']",0
Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Online Intelligent Education Systems,"['Shuo Liu', 'Junhao Shen', 'Hong Qian', 'Aimin Zhou']","Cognitive diagnosis aims to gauge students' mastery levels based on their response logs. Serving as a pivotal module in web-based online intelligent education systems (WOIESs), it plays an upstream and fundamental role in downstream tasks like learning item recommendation and computerized adaptive testing. WOIESs are open learning environment where numerous new students constantly register and complete exercises. In WOIESs, efficient cognitive diagnosis is crucial to fast feedback and accelerating student learning. However, the existing cognitive diagnosis methods always employ intrinsically transductive student-specific embeddings, which become slow and costly due to retraining when dealing with new students who are unseen during training. To this end, this paper proposes an inductive cognitive diagnosis model (ICDM) for fast new students' mastery levels inference in WOIESs. Specifically, in ICDM, we propose a novel student-centered graph (SCG). Rather than inferring mastery levels through updating student-specific embedding, we derive the inductive mastery levels as the aggregated outcomes of students' neighbors in SCG. Namely, SCG enables to shift the task from finding the most suitable student-specific embedding that fits the response logs to finding the most suitable representations for different node types in SCG, and the latter is more efficient since it no longer requires retraining. To obtain this representation, ICDM consists of a construction-aggregation-generation-transformation process to learn the final representation of students, exercises and concepts. Extensive experiments across real-world datasets show that, compared with the existing cognitive diagnosis methods that are always transductive, ICDM is much more faster while maintains the competitive inference performance for new students.",2404.1129,http://arxiv.org/abs/2404.11290v1,2024-04-17 11:55:43+00:00,2024-04-17 11:55:43+00:00,cs.AI,['cs.AI'],16
The Causal Chambers: Real Physical Systems as a Testbed for AI Methodology,"['Juan L. Gamella', 'Jonas Peters', 'Peter Bühlmann']","In some fields of AI, machine learning and statistics, the validation of new methods and algorithms is often hindered by the scarcity of suitable real-world datasets. Researchers must often turn to simulated data, which yields limited information about the applicability of the proposed methods to real problems. As a step forward, we have constructed two devices that allow us to quickly and inexpensively produce large datasets from non-trivial but well-understood physical systems. The devices, which we call causal chambers, are computer-controlled laboratories that allow us to manipulate and measure an array of variables from these physical systems, providing a rich testbed for algorithms from a variety of fields. We illustrate potential applications through a series of case studies in fields such as causal discovery, out-of-distribution generalization, change point detection, independent component analysis, and symbolic regression. For applications to causal inference, the chambers allow us to carefully perform interventions. We also provide and empirically validate a causal model of each chamber, which can be used as ground truth for different tasks. All hardware and software is made open source, and the datasets are publicly available at causalchamber.org or through the Python package causalchamber.",2404.11341,http://arxiv.org/abs/2404.11341v1,2024-04-17 13:00:52+00:00,2024-04-17 13:00:52+00:00,cs.AI,"['cs.AI', 'cs.LG', 'stat.ME', 'stat.ML']",0
Learn to Tour: Operator Design For Solution Feasibility Mapping in Pickup-and-delivery Traveling Salesman Problem,"['Bowen Fang', 'Xu Chen', 'Xuan Di']","This paper aims to develop a learning method for a special class of traveling salesman problems (TSP), namely, the pickup-and-delivery TSP (PDTSP), which finds the shortest tour along a sequence of one-to-one pickup-and-delivery nodes. One-to-one here means that the transported people or goods are associated with designated pairs of pickup and delivery nodes, in contrast to that indistinguishable goods can be delivered to any nodes. In PDTSP, precedence constraints need to be satisfied that each pickup node must be visited before its corresponding delivery node. Classic operations research (OR) algorithms for PDTSP are difficult to scale to large-sized problems. Recently, reinforcement learning (RL) has been applied to TSPs. The basic idea is to explore and evaluate visiting sequences in a solution space. However, this approach could be less computationally efficient, as it has to potentially evaluate many infeasible solutions of which precedence constraints are violated. To restrict solution search within a feasible space, we utilize operators that always map one feasible solution to another, without spending time exploring the infeasible solution space. Such operators are evaluated and selected as policies to solve PDTSPs in an RL framework. We make a comparison of our method and baselines, including classic OR algorithms and existing learning methods. Results show that our approach can find tours shorter than baselines.",2404.11458,http://arxiv.org/abs/2404.11458v1,2024-04-17 15:05:51+00:00,2024-04-17 15:05:51+00:00,cs.AI,['cs.AI'],0
"AgentKit: Flow Engineering with Graphs, not Coding","['Yue Wu', 'Yewen Fan', 'So Yeon Min', 'Shrimai Prabhumoye', 'Stephen McAleer', 'Yonatan Bisk', 'Ruslan Salakhutdinov', 'Yuanzhi Li', 'Tom Mitchell']","We propose an intuitive LLM prompting framework (AgentKit) for multifunctional agents. AgentKit offers a unified framework for explicitly constructing a complex ""thought process"" from simple natural language prompts. The basic building block in AgentKit is a node, containing a natural language prompt for a specific subtask. The user then puts together chains of nodes, like stacking LEGO pieces. The chains of nodes can be designed to explicitly enforce a naturally structured ""thought process"". For example, for the task of writing a paper, one may start with the thought process of 1) identify a core message, 2) identify prior research gaps, etc. The nodes in AgentKit can be designed and combined in different ways to implement multiple advanced capabilities including on-the-fly hierarchical planning, reflection, and learning from interactions. In addition, due to the modular nature and the intuitive design to simulate explicit human thought process, a basic agent could be implemented as simple as a list of prompts for the subtasks and therefore could be designed and tuned by someone without any programming experience. Quantitatively, we show that agents designed through AgentKit achieve SOTA performance on WebShop and Crafter. These advances underscore AgentKit's potential in making LLM agents effective and accessible for a wider range of applications. https://github.com/holmeswww/AgentKit",2404.11483,http://arxiv.org/abs/2404.11483v1,2024-04-17 15:40:45+00:00,2024-04-17 15:40:45+00:00,cs.AI,"['cs.AI', 'cs.LG']",16
Embedding Privacy in Computational Social Science and Artificial Intelligence Research,"['Keenan Jones', 'Fatima Zahrah', 'Jason R. C. Nurse']","Privacy is a human right. It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them. Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights. The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society. We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start. This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face. It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results.",2404.11515,http://arxiv.org/abs/2404.11515v1,2024-04-17 16:07:53+00:00,2024-04-17 16:07:53+00:00,cs.AI,"['cs.AI', 'cs.CY', 'cs.ET', 'cs.HC']",0
Pretraining Billion-scale Geospatial Foundational Models on Frontier,"['Aristeidis Tsaris', 'Philipe Ambrozio Dias', 'Abhishek Potnis', 'Junqi Yin', 'Feiyi Wang', 'Dalton Lunga']","As AI workloads increase in scope, generalization capability becomes challenging for small task-specific models and their demand for large amounts of labeled training samples increases. On the contrary, Foundation Models (FMs) are trained with internet-scale unlabeled data via self-supervised learning and have been shown to adapt to various tasks with minimal fine-tuning. Although large FMs have demonstrated significant impact in natural language processing and computer vision, efforts toward FMs for geospatial applications have been restricted to smaller size models, as pretraining larger models requires very large computing resources equipped with state-of-the-art hardware accelerators. Current satellite constellations collect 100+TBs of data a day, resulting in images that are billions of pixels and multimodal in nature. Such geospatial data poses unique challenges opening up new opportunities to develop FMs. We investigate billion scale FMs and HPC training profiles for geospatial applications by pretraining on publicly available data. We studied from end-to-end the performance and impact in the solution by scaling the model size. Our larger 3B parameter size model achieves up to 30% improvement in top1 scene classification accuracy when comparing a 100M parameter model. Moreover, we detail performance experiments on the Frontier supercomputer, America's first exascale system, where we study different model and data parallel approaches using PyTorch's Fully Sharded Data Parallel library. Specifically, we study variants of the Vision Transformer architecture (ViT), conducting performance analysis for ViT models with size up to 15B parameters. By discussing throughput and performance bottlenecks under different parallelism configurations, we offer insights on how to leverage such leadership-class HPC resources when developing large models for geospatial imagery applications.",2404.11706,http://arxiv.org/abs/2404.11706v1,2024-04-17 19:16:32+00:00,2024-04-17 19:16:32+00:00,cs.AI,['cs.AI'],0
"GEOBIND: Binding Text, Image, and Audio through Satellite Images","['Aayush Dhakal', 'Subash Khanal', 'Srikumar Sastry', 'Adeel Ahmad', 'Nathan Jacobs']","In remote sensing, we are interested in modeling various modalities for some geographic location. Several works have focused on learning the relationship between a location and type of landscape, habitability, audio, textual descriptions, etc. Recently, a common way to approach these problems is to train a deep-learning model that uses satellite images to infer some unique characteristics of the location. In this work, we present a deep-learning model, GeoBind, that can infer about multiple modalities, specifically text, image, and audio, from satellite imagery of a location. To do this, we use satellite images as the binding element and contrastively align all other modalities to the satellite image data. Our training results in a joint embedding space with multiple types of data: satellite image, ground-level image, audio, and text. Furthermore, our approach does not require a single complex dataset that contains all the modalities mentioned above. Rather it only requires multiple satellite-image paired data. While we only align three modalities in this paper, we present a general framework that can be used to create an embedding space with any number of modalities by using satellite images as the binding element. Our results show that, unlike traditional unimodal models, GeoBind is versatile and can reason about multiple modalities for a given satellite image input.",2404.1172,http://arxiv.org/abs/2404.11720v1,2024-04-17 20:13:37+00:00,2024-04-17 20:13:37+00:00,cs.AI,['cs.AI'],0
Meta-Decomposition: Dynamic Segmentation Approach Selection in IoT-based Activity Recognition,"['Seyed M. R. Modaresi', 'Aomar Osmani', 'Mohammadreza Razzazi', 'Abdelghani Chibani']","Internet of Things (IoT) devices generate heterogeneous data over time; and relying solely on individual data points is inadequate for accurate analysis.   Segmentation is a common preprocessing step in many IoT applications, including IoT-based activity recognition, aiming to address the limitations of individual events and streamline the process. However, this step introduces at least two families of uncontrollable biases. The first is caused by the changes made by the segmentation process on the initial problem space, such as dividing the input data into 60 seconds windows. The second category of biases results from the segmentation process itself, including the fixation of the segmentation method and its parameters.   To address these biases, we propose to redefine the segmentation problem as a special case of a decomposition problem, including three key components: a decomposer, resolutions, and a composer.   The inclusion of the composer task in the segmentation process facilitates an assessment of the relationship between the original problem and the problem after the segmentation. Therefore, It leads to an improvement in the evaluation process and, consequently, in the selection of the appropriate segmentation method.   Then, we formally introduce our novel meta-decomposition or learning-to-decompose approach. It reduces the segmentation biases by considering the segmentation as a hyperparameter to be optimized by the outer learning problem. Therefore, meta-decomposition improves the overall system performance by dynamically selecting the appropriate segmentation method without including the mentioned biases. Extensive experiments on four real-world datasets demonstrate the effectiveness of our proposal.",2404.11742,http://arxiv.org/abs/2404.11742v1,2024-04-17 20:50:28+00:00,2024-04-17 20:50:28+00:00,cs.AI,['cs.AI'],9
Incremental Bootstrapping and Classification of Structured Scenes in a Fuzzy Ontology,"['Luca Buoncompagni', 'Fulvio Mastrogiovanni']","We foresee robots that bootstrap knowledge representations and use them for classifying relevant situations and making decisions based on future observations. Particularly for assistive robots, the bootstrapping mechanism might be supervised by humans who should not repeat a training phase several times and should be able to refine the taught representation. We consider robots that bootstrap structured representations to classify some intelligible categories. Such a structure should be incrementally bootstrapped, i.e., without invalidating the identified category models when a new additional category is considered. To tackle this scenario, we presented the Scene Identification and Tagging (SIT) algorithm, which bootstraps structured knowledge representation in a crisp OWL-DL ontology. Over time, SIT bootstraps a graph representing scenes, sub-scenes and similar scenes. Then, SIT can classify new scenes within the bootstrapped graph through logic-based reasoning. However, SIT has issues with sensory data because its crisp implementation is not robust to perception noises. This paper presents a reformulation of SIT within the fuzzy domain, which exploits a fuzzy DL ontology to overcome the robustness issues. By comparing the performances of fuzzy and crisp implementations of SIT, we show that fuzzy SIT is robust, preserves the properties of its crisp formulation, and enhances the bootstrapped representations. On the contrary, the fuzzy implementation of SIT leads to less intelligible knowledge representations than the one bootstrapped in the crisp domain.",2404.11744,http://arxiv.org/abs/2404.11744v1,2024-04-17 20:51:13+00:00,2024-04-17 20:51:13+00:00,cs.AI,"['cs.AI', 'cs.HC', 'cs.LO', 'cs.RO', '68T40 (Primary) 68T30, 68T27, 68T37, 03B52 (Secondary)', 'I.2.4; I.2.6; I.2.3; I.2.9; I.2.10']",0
Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools,"['Yilun Hao', 'Yongchao Chen', 'Yang Zhang', 'Chuchu Fan']","The recent advancements of Large Language Models (LLMs), with their abundant world knowledge and capabilities of tool-using and reasoning, fostered many LLM planning algorithms. However, LLMs have not shown to be able to accurately solve complex combinatorial optimization problems. In Xie et al. (2024), the authors proposed TravelPlanner, a U.S. domestic travel planning benchmark, and showed that LLMs themselves cannot make travel plans that satisfy user requirements with a best success rate of 0.6%. In this work, we propose a framework that enables LLMs to formally formulate and solve the travel planning problem as a satisfiability modulo theory (SMT) problem and use SMT solvers interactively and automatically solve the combinatorial search problem. The SMT solvers guarantee the satisfiable of input constraints and the LLMs can enable a language-based interaction with our framework. When the input constraints cannot be satisfiable, our LLM-based framework will interactively offer suggestions to users to modify their travel requirements via automatic reasoning using the SMT solvers. We evaluate our framework with TravelPlanner and achieve a success rate of 97%. We also create a separate dataset that contain international travel benchmarks and use both dataset to evaluate the effectiveness of our interactive planning framework when the initial user queries cannot be satisfied. Our framework could generate valid plans with an average success rate of 78.6% for our dataset and 85.0% for TravelPlanner according to diverse humans preferences.",2404.11891,http://arxiv.org/abs/2404.11891v1,2024-04-18 04:36:37+00:00,2024-04-18 04:36:37+00:00,cs.AI,['cs.AI'],20
Evolutionary Multi-Objective Optimisation for Fairness-Aware Self Adjusting Memory Classifiers in Data Streams,"['Pivithuru Thejan Amarasinghe', 'Diem Pham', 'Binh Tran', 'Su Nguyen', 'Yuan Sun', 'Damminda Alahakoon']","This paper introduces a novel approach, evolutionary multi-objective optimisation for fairness-aware self-adjusting memory classifiers, designed to enhance fairness in machine learning algorithms applied to data stream classification. With the growing concern over discrimination in algorithmic decision-making, particularly in dynamic data stream environments, there is a need for methods that ensure fair treatment of individuals across sensitive attributes like race or gender. The proposed approach addresses this challenge by integrating the strengths of the self-adjusting memory K-Nearest-Neighbour algorithm with evolutionary multi-objective optimisation. This combination allows the new approach to efficiently manage concept drift in streaming data and leverage the flexibility of evolutionary multi-objective optimisation to maximise accuracy and minimise discrimination simultaneously. We demonstrate the effectiveness of the proposed approach through extensive experiments on various datasets, comparing its performance against several baseline methods in terms of accuracy and fairness metrics. Our results show that the proposed approach maintains competitive accuracy and significantly reduces discrimination, highlighting its potential as a robust solution for fairness-aware data stream classification. Further analyses also confirm the effectiveness of the strategies to trigger evolutionary multi-objective optimisation and adapt classifiers in the proposed approach.",2404.12076,http://arxiv.org/abs/2404.12076v1,2024-04-18 10:59:04+00:00,2024-04-18 10:59:04+00:00,cs.AI,"['cs.AI', 'cs.NE']",11
Personalized Forgetting Mechanism with Concept-Driven Knowledge Tracing,"['Shanshan Wang', 'Ying Hu', 'Xun Yang', 'Zhongzhou Zhang', 'Keyang Wang', 'Xingyi Zhang']","Knowledge Tracing (KT) aims to trace changes in students' knowledge states throughout their entire learning process by analyzing their historical learning data and predicting their future learning performance. Existing forgetting curve theory based knowledge tracing models only consider the general forgetting caused by time intervals, ignoring the individualization of students and the causal relationship of the forgetting process. To address these problems, we propose a Concept-driven Personalized Forgetting knowledge tracing model (CPF) which integrates hierarchical relationships between knowledge concepts and incorporates students' personalized cognitive abilities. First, we integrate the students' personalized capabilities into both the learning and forgetting processes to explicitly distinguish students' individual learning gains and forgetting rates according to their cognitive abilities. Second, we take into account the hierarchical relationships between knowledge points and design a precursor-successor knowledge concept matrix to simulate the causal relationship in the forgetting process, while also integrating the potential impact of forgetting prior knowledge points on subsequent ones. The proposed personalized forgetting mechanism can not only be applied to the learning of specifc knowledge concepts but also the life-long learning process. Extensive experimental results on three public datasets show that our CPF outperforms current forgetting curve theory based methods in predicting student performance, demonstrating CPF can better simulate changes in students' knowledge status through the personalized forgetting mechanism.",2404.12127,http://arxiv.org/abs/2404.12127v1,2024-04-18 12:28:50+00:00,2024-04-18 12:28:50+00:00,cs.AI,['cs.AI'],0
The Neutrality Fallacy: When Algorithmic Fairness Interventions are (Not) Positive Action,"['Hilde Weerts', 'Raphaële Xenidis', 'Fabien Tarissan', 'Henrik Palmer Olsen', 'Mykola Pechenizkiy']","Various metrics and interventions have been developed to identify and mitigate unfair outputs of machine learning systems. While individuals and organizations have an obligation to avoid discrimination, the use of fairness-aware machine learning interventions has also been described as amounting to 'algorithmic positive action' under European Union (EU) non-discrimination law. As the Court of Justice of the European Union has been strict when it comes to assessing the lawfulness of positive action, this would impose a significant legal burden on those wishing to implement fair-ml interventions. In this paper, we propose that algorithmic fairness interventions often should be interpreted as a means to prevent discrimination, rather than a measure of positive action. Specifically, we suggest that this category mistake can often be attributed to neutrality fallacies: faulty assumptions regarding the neutrality of fairness-aware algorithmic decision-making. Our findings raise the question of whether a negative obligation to refrain from discrimination is sufficient in the context of algorithmic decision-making. Consequently, we suggest moving away from a duty to 'not do harm' towards a positive obligation to actively 'do no harm' as a more adequate framework for algorithmic decision-making and fair ml-interventions.",2404.12143,http://arxiv.org/abs/2404.12143v1,2024-04-18 12:44:35+00:00,2024-04-18 12:44:35+00:00,cs.AI,"['cs.AI', 'cs.CY']",0
A Time-Inhomogeneous Markov Model for Resource Availability under Sparse Observations,"['Lukas Rottkamp', 'Matthias Schubert']","Accurate spatio-temporal information about the current situation is crucial for smart city applications such as modern routing algorithms. Often, this information describes the state of stationary resources, e.g. the availability of parking bays, charging stations or the amount of people waiting for a vehicle to pick them up near a given location. To exploit this kind of information, predicting future states of the monitored resources is often mandatory because a resource might change its state within the time until it is needed. To train an accurate predictive model, it is often not possible to obtain a continuous time series on the state of the resource. For example, the information might be collected from traveling agents visiting the resource with an irregular frequency. Thus, it is necessary to develop methods which work on sparse observations for training and prediction. In this paper, we propose time-inhomogeneous discrete Markov models to allow accurate prediction even when the frequency of observation is very rare. Our new model is able to blend recent observations with historic data and also provide useful probabilistic estimates for future states. Since resources availability in a city is typically time-dependent, our Markov model is time-inhomogeneous and cyclic within a predefined time interval. To train our model, we propose a modified Baum-Welch algorithm. Evaluations on real-world datasets of parking bay availability show that our new method indeed yields good results compared to methods being trained on complete data and non-cyclic variants.",2404.1224,http://arxiv.org/abs/2404.12240v1,2024-04-18 15:00:59+00:00,2024-04-18 15:00:59+00:00,cs.AI,['cs.AI'],0
FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom,"['Yuanqin He', 'Yan Kang', 'Lixin Fan', 'Qiang Yang']","Federated Learning (FL) has emerged as a promising solution for collaborative training of large language models (LLMs). However, the integration of LLMs into FL introduces new challenges, particularly concerning the evaluation of LLMs. Traditional evaluation methods that rely on labeled test sets and similarity-based metrics cover only a subset of the acceptable answers, thereby failing to accurately reflect the performance of LLMs on generative tasks. Meanwhile, although automatic evaluation methods that leverage advanced LLMs present potential, they face critical risks of data leakage due to the need to transmit data to external servers and suboptimal performance on downstream tasks due to the lack of domain knowledge. To address these issues, we propose a Federated Evaluation framework of Large Language Models, named FedEval-LLM, that provides reliable performance measurements of LLMs on downstream tasks without the reliance on labeled test sets and external tools, thus ensuring strong privacy-preserving capability. FedEval-LLM leverages a consortium of personalized LLMs from participants as referees to provide domain knowledge and collective evaluation capability, thus aligning to the respective downstream tasks and mitigating uncertainties and biases associated with a single referee. Experimental results demonstrate a significant improvement in the evaluation capability of personalized evaluation models on downstream tasks. When applied to FL, these evaluation models exhibit strong agreement with human preference and RougeL-score on meticulously curated test sets. FedEval-LLM effectively overcomes the limitations of traditional metrics and the reliance on external services, making it a promising framework for the evaluation of LLMs within collaborative training scenarios.",2404.12273,http://arxiv.org/abs/2404.12273v1,2024-04-18 15:46:26+00:00,2024-04-18 15:46:26+00:00,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']",0
DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era,"['David Restrepo', 'Chenwei Wu', 'Constanza Vásquez-Venegas', 'Luis Filipe Nakayama', 'Leo Anthony Celi', 'Diego M López']","In the big data era, integrating diverse data modalities poses significant challenges, particularly in complex fields like healthcare. This paper introduces a new process model for multimodal Data Fusion for Data Mining, integrating embeddings and the Cross-Industry Standard Process for Data Mining with the existing Data Fusion Information Group model. Our model aims to decrease computational costs, complexity, and bias while improving efficiency and reliability. We also propose ""disentangled dense fusion"", a novel embedding fusion method designed to optimize mutual information and facilitate dense inter-modality feature interaction, thereby minimizing redundant information.   We demonstrate the model's efficacy through three use cases: predicting diabetic retinopathy using retinal images and patient metadata, domestic violence prediction employing satellite imagery, internet, and census data, and identifying clinical and demographic features from radiography images and clinical notes. The model achieved a Macro F1 score of 0.92 in diabetic retinopathy prediction, an R-squared of 0.854 and sMAPE of 24.868 in domestic violence prediction, and a macro AUC of 0.92 and 0.99 for disease prediction and sex classification, respectively, in radiological analysis.   These results underscore the Data Fusion for Data Mining model's potential to significantly impact multimodal data processing, promoting its adoption in diverse, resource-constrained settings.",2404.12278,http://arxiv.org/abs/2404.12278v1,2024-04-18 15:52:42+00:00,2024-04-18 15:52:42+00:00,cs.AI,"['cs.AI', '68T30', 'I.2.0; I.3.6']",0
Group-Aware Coordination Graph for Multi-Agent Reinforcement Learning,"['Wei Duan', 'Jie Lu', 'Junyu Xuan']","Cooperative Multi-Agent Reinforcement Learning (MARL) necessitates seamless collaboration among agents, often represented by an underlying relation graph. Existing methods for learning this graph primarily focus on agent-pair relations, neglecting higher-order relationships. While several approaches attempt to extend cooperation modelling to encompass behaviour similarities within groups, they commonly fall short in concurrently learning the latent graph, thereby constraining the information exchange among partially observed agents. To overcome these limitations, we present a novel approach to infer the Group-Aware Coordination Graph (GACG), which is designed to capture both the cooperation between agent pairs based on current observations and group-level dependencies from behaviour patterns observed across trajectories. This graph is further used in graph convolution for information exchange between agents during decision-making. To further ensure behavioural consistency among agents within the same group, we introduce a group distance loss, which promotes group cohesion and encourages specialization between groups. Our evaluations, conducted on StarCraft II micromanagement tasks, demonstrate GACG's superior performance. An ablation study further provides experimental evidence of the effectiveness of each component of our method.",2404.10976,http://arxiv.org/abs/2404.10976v1,2024-04-17 01:17:10+00:00,2024-04-17 01:17:10+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.MA']",0
Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection,"['Nawfal Guefrachi', 'Jian Shi', 'Hakim Ghazzai', 'Ahmad Alsharoa']","The integration of Light Detection and Ranging (LiDAR) and Internet of Things (IoT) technologies offers transformative opportunities for public health informatics in urban safety and pedestrian well-being. This paper proposes a novel framework utilizing these technologies for enhanced 3D object detection and activity classification in urban traffic scenarios. By employing elevated LiDAR, we obtain detailed 3D point cloud data, enabling precise pedestrian activity monitoring. To overcome urban data scarcity, we create a specialized dataset through simulated traffic environments in Blender, facilitating targeted model training. Our approach employs a modified Point Voxel-Region-based Convolutional Neural Network (PV-RCNN) for robust 3D detection and PointNet for classifying pedestrian activities, significantly benefiting urban traffic management and public health by offering insights into pedestrian behavior and promoting safer urban environments. Our dual-model approach not only enhances urban traffic management but also contributes significantly to public health by providing insights into pedestrian behavior and promoting safer urban environment.",2404.10978,http://arxiv.org/abs/2404.10978v1,2024-04-17 01:23:49+00:00,2024-04-17 01:23:49+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",0
Stepwise Alignment for Constrained Language Model Policy Optimization,"['Akifumi Wachi', 'Thien Q Tran', 'Rei Sato', 'Takumi Tanabe', 'Yohei Akimoto']","Safety and trustworthiness are indispensable requirements for applying AI systems based on large language models (LLMs) in real-world applications. This paper formulates a human value alignment as a language model policy optimization problem to maximize reward under a safety constraint and then proposes an algorithm called Stepwise Alignment for Constrained Policy Optimization (SACPO). A key idea behind SACPO, supported by theory, is that the optimal policy incorporating both reward and safety can be directly obtained from a reward-aligned policy. Based on this key idea, SACPO aligns the LLMs with each metric step-wise while leveraging simple yet powerful alignment algorithms such as direct preference optimization (DPO). SACPO provides many benefits such as simplicity, stability, computational efficiency, and flexibility regarding algorithms and dataset selection. Under mild assumption, our theoretical analysis provides the upper bounds regarding near-optimality and safety constraint violation. Our experimental results show that SACPO can fine-tune Alpaca-7B better than the state-of-the-art method in terms of both helpfulness and harmlessness",2404.11049,http://arxiv.org/abs/2404.11049v1,2024-04-17 03:44:58+00:00,2024-04-17 03:44:58+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CL']",17
LMEraser: Large Model Unlearning through Adaptive Prompt Tuning,"['Jie Xu', 'Zihan Wu', 'Cong Wang', 'Xiaohua Jia']","To address the growing demand for privacy protection in machine learning, we propose a novel and efficient machine unlearning approach for \textbf{L}arge \textbf{M}odels, called \textbf{LM}Eraser. Existing unlearning research suffers from entangled training data and complex model architectures, incurring extremely high computational costs for large models. LMEraser takes a divide-and-conquer strategy with a prompt tuning architecture to isolate data influence. The training dataset is partitioned into public and private datasets. Public data are used to train the backbone of the model. Private data are adaptively clustered based on their diversity, and each cluster is used to optimize a prompt separately. This adaptive prompt tuning mechanism reduces unlearning costs and maintains model performance. Experiments demonstrate that LMEraser achieves a $100$-fold reduction in unlearning costs without compromising accuracy compared to prior work. Our code is available at: \url{https://github.com/lmeraser/lmeraser}.",2404.11056,http://arxiv.org/abs/2404.11056v1,2024-04-17 04:08:38+00:00,2024-04-17 04:08:38+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CR']",55
ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours,"['Feiwen Zhu', 'Arkadiusz Nowaczynski', 'Rundong Li', 'Jie Xin', 'Yifei Song', 'Michal Marcinkiewicz', 'Sukru Burc Eryilmaz', 'Jun Yang', 'Michael Andersch']","AlphaFold2 has been hailed as a breakthrough in protein folding. It can rapidly predict protein structures with lab-grade accuracy. However, its implementation does not include the necessary training code. OpenFold is the first trainable public reimplementation of AlphaFold. AlphaFold training procedure is prohibitively time-consuming, and gets diminishing benefits from scaling to more compute resources. In this work, we conducted a comprehensive analysis on the AlphaFold training procedure based on Openfold, identified that inefficient communications and overhead-dominated computations were the key factors that prevented the AlphaFold training from effective scaling. We introduced ScaleFold, a systematic training method that incorporated optimizations specifically for these factors. ScaleFold successfully scaled the AlphaFold training to 2080 NVIDIA H100 GPUs with high resource utilization. In the MLPerf HPC v3.0 benchmark, ScaleFold finished the OpenFold benchmark in 7.51 minutes, shown over $6\times$ speedup than the baseline. For training the AlphaFold model from scratch, ScaleFold completed the pretraining in 10 hours, a significant improvement over the seven days required by the original AlphaFold pretraining baseline.",2404.11068,http://arxiv.org/abs/2404.11068v1,2024-04-17 04:55:33+00:00,2024-04-17 04:55:33+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.DC', 'q-bio.QM']",0
Large Language Models Meet User Interfaces: The Case of Provisioning Feedback,"['Stanislav Pozdniakov', 'Jonathan Brazil', 'Solmaz Abdi', 'Aneesha Bakharia', 'Shazia Sadiq', 'Dragan Gasevic', 'Paul Denny', 'Hassan Khosravi']","Incorporating Generative AI (GenAI) and Large Language Models (LLMs) in education can enhance teaching efficiency and enrich student learning. Current LLM usage involves conversational user interfaces (CUIs) for tasks like generating materials or providing feedback. However, this presents challenges including the need for educator expertise in AI and CUIs, ethical concerns with high-stakes decisions, and privacy risks. CUIs also struggle with complex tasks. To address these, we propose transitioning from CUIs to user-friendly applications leveraging LLMs via API calls. We present a framework for ethically incorporating GenAI into educational tools and demonstrate its application in our tool, Feedback Copilot, which provides personalized feedback on student assignments. Our evaluation shows the effectiveness of this approach, with implications for GenAI researchers, educators, and technologists. This work charts a course for the future of GenAI in education.",2404.11072,http://arxiv.org/abs/2404.11072v1,2024-04-17 05:05:05+00:00,2024-04-17 05:05:05+00:00,cs.HC,"['cs.HC', 'cs.AI']",0
ViLLM-Eval: A Comprehensive Evaluation Suite for Vietnamese Large Language Models,"['Trong-Hieu Nguyen', 'Anh-Cuong Le', 'Viet-Cuong Nguyen']","The rapid advancement of large language models (LLMs) necessitates the development of new benchmarks to accurately assess their capabilities. To address this need for Vietnamese, this work aims to introduce ViLLM-Eval, the comprehensive evaluation suite designed to measure the advanced knowledge and reasoning abilities of foundation models within a Vietnamese context. ViLLM-Eval consists of multiple-choice questions and predict next word tasks spanning various difficulty levels and diverse disciplines, ranging from humanities to science and engineering. A thorough evaluation of the most advanced LLMs on ViLLM-Eval revealed that even the best performing models have significant room for improvement in understanding and responding to Vietnamese language tasks. ViLLM-Eval is believed to be instrumental in identifying key strengths and weaknesses of foundation models, ultimately promoting their development and enhancing their performance for Vietnamese users. This paper provides a thorough overview of ViLLM-Eval as part of the Vietnamese Large Language Model shared task, held within the 10th International Workshop on Vietnamese Language and Speech Processing (VLSP 2023).",2404.11086,http://arxiv.org/abs/2404.11086v2,2024-04-17 05:57:17+00:00,2024-04-18 07:41:23+00:00,cs.CL,"['cs.CL', 'cs.AI']",11
Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues,"['Jiao Ou', 'Jiayu Wu', 'Che Liu', 'Fuzheng Zhang', 'Di Zhang', 'Kun Gai']","Aligning large language models (LLMs) with human expectations requires high-quality instructional dialogues, which can be achieved by raising diverse, in-depth, and insightful instructions that deepen interactions. Existing methods target instructions from real instruction dialogues as a learning goal and fine-tune a user simulator for posing instructions. However, the user simulator struggles to implicitly model complex dialogue flows and pose high-quality instructions. In this paper, we take inspiration from the cognitive abilities inherent in human learning and propose the explicit modeling of complex dialogue flows through instructional strategy reuse. Specifically, we first induce high-level strategies from various real instruction dialogues. These strategies are applied to new dialogue scenarios deductively, where the instructional strategies facilitate high-quality instructions. Experimental results show that our method can generate diverse, in-depth, and insightful instructions for a given dialogue history. The constructed multi-turn instructional dialogues can outperform competitive baselines on the downstream chat model.",2404.11095,http://arxiv.org/abs/2404.11095v1,2024-04-17 06:26:32+00:00,2024-04-17 06:26:32+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment,"['Qinfeng Li', 'Zhiqiang Shen', 'Zhenghan Qin', 'Yangfan Xie', 'Xuhong Zhang', 'Tianyu Du', 'Jianwei Yin']","Proprietary large language models (LLMs) have been widely applied in various scenarios. Additionally, deploying LLMs on edge devices is trending for efficiency and privacy reasons. However, edge deployment of proprietary LLMs introduces new security challenges: edge-deployed models are exposed as white-box accessible to users, enabling adversaries to conduct effective model stealing (MS) attacks. Unfortunately, existing defense mechanisms fail to provide effective protection. Specifically, we identify four critical protection properties that existing methods fail to simultaneously satisfy: (1) maintaining protection after a model is physically copied; (2) authorizing model access at request level; (3) safeguarding runtime reverse engineering; (4) achieving high security with negligible runtime overhead. To address the above issues, we propose TransLinkGuard, a plug-and-play model protection approach against model stealing on edge devices. The core part of TransLinkGuard is a lightweight authorization module residing in a secure environment, e.g., TEE. The authorization module can freshly authorize each request based on its input. Extensive experiments show that TransLinkGuard achieves the same security protection as the black-box security guarantees with negligible overhead.",2404.11121,http://arxiv.org/abs/2404.11121v1,2024-04-17 07:08:45+00:00,2024-04-17 07:08:45+00:00,cs.CR,"['cs.CR', 'cs.AI']",17
Personalized Heart Disease Detection via ECG Digital Twin Generation,"['Yaojun Hu', 'Jintai Chen', 'Lianting Hu', 'Dantong Li', 'Jiahuan Yan', 'Haochao Ying', 'Huiying Liang', 'Jian Wu']","Heart diseases rank among the leading causes of global mortality, demonstrating a crucial need for early diagnosis and intervention. Most traditional electrocardiogram (ECG) based automated diagnosis methods are trained at population level, neglecting the customization of personalized ECGs to enhance individual healthcare management. A potential solution to address this limitation is to employ digital twins to simulate symptoms of diseases in real patients. In this paper, we present an innovative prospective learning approach for personalized heart disease detection, which generates digital twins of healthy individuals' anomalous ECGs and enhances the model sensitivity to the personalized symptoms. In our approach, a vector quantized feature separator is proposed to locate and isolate the disease symptom and normal segments in ECG signals with ECG report guidance. Thus, the ECG digital twins can simulate specific heart diseases used to train a personalized heart disease detection model. Experiments demonstrate that our approach not only excels in generating high-fidelity ECG signals but also improves personalized heart disease detection. Moreover, our approach ensures robust privacy protection, safeguarding patient data in model development.",2404.11171,http://arxiv.org/abs/2404.11171v1,2024-04-17 08:40:54+00:00,2024-04-17 08:40:54+00:00,cs.LG,"['cs.LG', 'cs.AI', 'eess.SP']",0
Revisiting Noise Resilience Strategies in Gesture Recognition: Short-Term Enhancement in Surface Electromyographic Signal Analysis,"['Weiyu Guo', 'Ziyue Qiao', 'Ying Sun', 'Hui Xiong']","Gesture recognition based on surface electromyography (sEMG) has been gaining importance in many 3D Interactive Scenes. However, sEMG is easily influenced by various forms of noise in real-world environments, leading to challenges in providing long-term stable interactions through sEMG. Existing methods often struggle to enhance model noise resilience through various predefined data augmentation techniques. In this work, we revisit the problem from a short term enhancement perspective to improve precision and robustness against various common noisy scenarios with learnable denoise using sEMG intrinsic pattern information and sliding-window attention. We propose a Short Term Enhancement Module(STEM) which can be easily integrated with various models. STEM offers several benefits: 1) Learnable denoise, enabling noise reduction without manual data augmentation; 2) Scalability, adaptable to various models; and 3) Cost-effectiveness, achieving short-term enhancement through minimal weight-sharing in an efficient attention mechanism. In particular, we incorporate STEM into a transformer, creating the Short Term Enhanced Transformer (STET). Compared with best-competing approaches, the impact of noise on STET is reduced by more than 20%. We also report promising results on both classification and regression datasets and demonstrate that STEM generalizes across different gesture recognition tasks.",2404.11213,http://arxiv.org/abs/2404.11213v1,2024-04-17 09:57:40+00:00,2024-04-17 09:57:40+00:00,eess.SP,"['eess.SP', 'cs.AI']",8
Position Engineering: Boosting Large Language Models through Positional Information Manipulation,"['Zhiyuan He', 'Huiqiang Jiang', 'Zilong Wang', 'Yuqing Yang', 'Luna Qiu', 'Lili Qiu']","The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance. In this paper, we introduce a novel technique termed position engineering, which offers a more efficient way to guide large language models. Unlike prompt engineering, which requires substantial effort to modify the text provided to LLMs, position engineering merely involves altering the positional information in the prompt without modifying the text itself. We have evaluated position engineering in two widely-used LLM scenarios: retrieval-augmented generation (RAG) and in-context learning (ICL). Our findings show that position engineering substantially improves upon the baseline in both cases. Position engineering thus represents a promising new strategy for exploiting the capabilities of large language models.",2404.11216,http://arxiv.org/abs/2404.11216v1,2024-04-17 10:00:56+00:00,2024-04-17 10:00:56+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",16
Optical Image-to-Image Translation Using Denoising Diffusion Models: Heterogeneous Change Detection as a Use Case,"['João Gabriel Vinholi', 'Marco Chini', 'Anis Amziane', 'Renato Machado', 'Danilo Silva', 'Patrick Matgen']","We introduce an innovative deep learning-based method that uses a denoising diffusion-based model to translate low-resolution images to high-resolution ones from different optical sensors while preserving the contents and avoiding undesired artifacts. The proposed method is trained and tested on a large and diverse data set of paired Sentinel-II and Planet Dove images. We show that it can solve serious image generation issues observed when the popular classifier-free guided Denoising Diffusion Implicit Model (DDIM) framework is used in the task of Image-to-Image Translation of multi-sensor optical remote sensing images and that it can generate large images with highly consistent patches, both in colors and in features. Moreover, we demonstrate how our method improves heterogeneous change detection results in two urban areas: Beirut, Lebanon, and Austin, USA. Our contributions are: i) a new training and testing algorithm based on denoising diffusion models for optical image translation; ii) a comprehensive image quality evaluation and ablation study; iii) a comparison with the classifier-free guided DDIM framework; and iv) change detection experiments on heterogeneous data.",2404.11243,http://arxiv.org/abs/2404.11243v1,2024-04-17 10:49:00+00:00,2024-04-17 10:49:00+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
Characterizing and modeling harms from interactions with design patterns in AI interfaces,"['Lujain Ibrahim', 'Luc Rocher', 'Ana Valdivia']","The proliferation of applications using artificial intelligence (AI) systems has led to a growing number of users interacting with these systems through sophisticated interfaces. Human-computer interaction research has long shown that interfaces shape both user behavior and user perception of technical capabilities and risks. Yet, practitioners and researchers evaluating the social and ethical risks of AI systems tend to overlook the impact of anthropomorphic, deceptive, and immersive interfaces on human-AI interactions. Here, we argue that design features of interfaces with adaptive AI systems can have cascading impacts, driven by feedback loops, which extend beyond those previously considered. We first conduct a scoping review of AI interface designs and their negative impact to extract salient themes of potentially harmful design patterns in AI interfaces. Then, we propose Design-Enhanced Control of AI systems (DECAI), a conceptual model to structure and facilitate impact assessments of AI interface designs. DECAI draws on principles from control systems theory -- a theory for the analysis and design of dynamic physical systems -- to dissect the role of the interface in human-AI systems. Through two case studies on recommendation systems and conversational language model systems, we show how DECAI can be used to evaluate AI interface designs.",2404.1137,http://arxiv.org/abs/2404.11370v1,2024-04-17 13:30:45+00:00,2024-04-17 13:30:45+00:00,cs.HC,"['cs.HC', 'cs.AI', 'cs.CY']",0
Short-term wind speed forecasting model based on an attention-gated recurrent neural network and error correction strategy,['Haojian Huang'],"The accurate wind speed series forecast is very pivotal to security of grid dispatching and the application of wind power. Nevertheless, on account of their nonlinear and non-stationary nature, their short-term forecast is extremely challenging. Therefore, this dissertation raises one short-term wind speed forecast pattern on the foundation of attention with an improved gated recurrent neural network (AtGRU) and a tactic of error correction. That model uses the AtGRU model as the preliminary predictor and the GRU model as the error corrector. At the beginning, SSA (singular spectrum analysis) is employed in previous wind speed series for lessening the noise. Subsequently, historical wind speed series is going to be used for the predictor training. During this process, the prediction can have certain errors. The sequence of these errors processed by variational modal decomposition (VMD) is used to train the corrector of error. The eventual forecast consequence is just the sum of predictor forecast and error corrector. The proposed SSA-AtGRU-VMD-GRU model outperforms the compared models in three case studies on Woodburn, St. Thomas, and Santa Cruz. It is indicated that the model evidently enhances the correction of the wind speed forecast.",2404.11422,http://arxiv.org/abs/2404.11422v1,2024-04-17 14:27:45+00:00,2024-04-17 14:27:45+00:00,cs.LG,"['cs.LG', 'cs.AI', 'physics.ao-ph']",2
Open-Ended Wargames with Large Language Models,"['Daniel P. Hogan', 'Andrea Brennen']","Wargames are a powerful tool for understanding and rehearsing real-world decision making. Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes. There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses. Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames. We introduce ""Snow Globe,"" an LLM-powered multi-agent system for playing qualitative wargames. With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof. We describe its software architecture conceptually and release an open-source implementation alongside this publication. As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis. We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem.",2404.11446,http://arxiv.org/abs/2404.11446v1,2024-04-17 14:54:58+00:00,2024-04-17 14:54:58+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.CY']",3
Discovering Nuclear Models from Symbolic Machine Learning,"['Jose M. Munoz', 'Silviu M. Udrescu', 'Ronald F. Garcia Ruiz']","Numerous phenomenological nuclear models have been proposed to describe specific observables within different regions of the nuclear chart. However, developing a unified model that describes the complex behavior of all nuclei remains an open challenge. Here, we explore whether novel symbolic Machine Learning (ML) can rediscover traditional nuclear physics models or identify alternatives with improved simplicity, fidelity, and predictive power. To address this challenge, we developed a Multi-objective Iterated Symbolic Regression approach that handles symbolic regressions over multiple target observables, accounts for experimental uncertainties and is robust against high-dimensional problems. As a proof of principle, we applied this method to describe the nuclear binding energies and charge radii of light and medium mass nuclei. Our approach identified simple analytical relationships based on the number of protons and neutrons, providing interpretable models with precision comparable to state-of-the-art nuclear models. Additionally, we integrated this ML-discovered model with an existing complementary model to estimate the limits of nuclear stability. These results highlight the potential of symbolic ML to develop accurate nuclear models and guide our description of complex many-body problems.",2404.11477,http://arxiv.org/abs/2404.11477v1,2024-04-17 15:32:58+00:00,2024-04-17 15:32:58+00:00,nucl-th,"['nucl-th', 'cs.AI', 'cs.LG', 'nucl-ex']",23
Multi-resolution Rescored ByteTrack for Video Object Detection on Ultra-low-power Embedded Systems,"['Luca Bompani', 'Manuele Rusci', 'Daniele Palossi', 'Francesco Conti', 'Luca Benini']","This paper introduces Multi-Resolution Rescored Byte-Track (MR2-ByteTrack), a novel video object detection framework for ultra-low-power embedded processors. This method reduces the average compute load of an off-the-shelf Deep Neural Network (DNN) based object detector by up to 2.25$\times$ by alternating the processing of high-resolution images (320$\times$320 pixels) with multiple down-sized frames (192$\times$192 pixels). To tackle the accuracy degradation due to the reduced image input size, MR2-ByteTrack correlates the output detections over time using the ByteTrack tracker and corrects potential misclassification using a novel probabilistic Rescore algorithm. By interleaving two down-sized images for every high-resolution one as the input of different state-of-the-art DNN object detectors with our MR2-ByteTrack, we demonstrate an average accuracy increase of 2.16% and a latency reduction of 43% on the GAP9 microcontroller compared to a baseline frame-by-frame inference scheme using exclusively full-resolution images. Code available at: https://github.com/Bomps4/Multi_Resolution_Rescored_ByteTrack",2404.11488,http://arxiv.org/abs/2404.11488v1,2024-04-17 15:45:49+00:00,2024-04-17 15:45:49+00:00,cs.CV,"['cs.CV', 'cs.AI', 'I.4']",0
arcjetCV: an open-source software to analyze material ablation,"['Alexandre Quintart', 'Magnus Haw', 'Federico Semeraro']","arcjetCV is an open-source Python software designed to automate time-resolved measurements of heatshield material recession and recession rates from arcjet test video footage. This new automated and accessible capability greatly exceeds previous manual extraction methods, enabling rapid and detailed characterization of material recession for any sample with a profile video. arcjetCV automates the video segmentation process using machine learning models, including a one-dimensional (1D) Convolutional Neural Network (CNN) to infer the time-window of interest, a two-dimensional (2D) CNN for image and edge segmentation, and a Local Outlier Factor (LOF) for outlier filtering. A graphical user interface (GUI) simplifies the user experience and an application programming interface (API) allows users to call the core functions from scripts, enabling video batch processing. arcjetCV's capability to measure time-resolved recession in turn enables characterization of non-linear processes (shrinkage, swelling, melt flows, etc.), contributing to higher fidelity validation and improved modeling of heatshield material performance. The source code associated with this article can be found at https://github.com/magnus-haw/arcjetCV.",2404.11492,http://arxiv.org/abs/2404.11492v1,2024-04-17 15:47:26+00:00,2024-04-17 15:47:26+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",0
Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models,"['Yue Zhou', 'Yada Zhu', 'Diego Antognini', 'Yoon Kim', 'Yang Zhang']","This paper studies the relationship between the surface form of a mathematical problem and its solvability by large language models. We find that subtle alterations in the surface form can significantly impact the answer distribution and the solve rate, exposing the language model's lack of robustness and sensitivity to the surface form in reasoning through complex problems. To improve mathematical reasoning performance, we propose Self-Consistency-over-Paraphrases (SCoP), which diversifies reasoning paths from specific surface forms of the problem. We evaluate our approach on four mathematics reasoning benchmarks over three large language models and show that SCoP improves mathematical reasoning performance over vanilla self-consistency, particularly for problems initially deemed unsolvable. Finally, we provide additional experiments and discussion regarding problem difficulty and surface forms, including cross-model difficulty agreement and paraphrasing transferability, and Variance of Variations (VOV) for language model evaluation.",2404.115,http://arxiv.org/abs/2404.11500v1,2024-04-17 15:53:49+00:00,2024-04-17 15:53:49+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large Language Models,"['Yushuo Chen', 'Tianyi Tang', 'Erge Xiang', 'Linjiang Li', 'Wayne Xin Zhao', 'Jing Wang', 'Yunpeng Chai', 'Ji-Rong Wen']","In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications. For the wide application of LLMs, the inference efficiency is an essential concern, which has been widely studied in existing work, and numerous optimization algorithms and code libraries have been proposed to improve it. Nonetheless, users still find it challenging to compare the effectiveness of all the above methods and understand the underlying mechanisms. In this work, we perform a detailed coarse-to-fine analysis of the inference performance of various code libraries. To evaluate the overall effectiveness, we examine four usage scenarios within two practical applications. We further provide both theoretical and empirical fine-grained analyses of each module in the Transformer architecture. Our experiments yield comprehensive results that are invaluable for researchers to evaluate code libraries and improve inference strategies.",2404.11502,http://arxiv.org/abs/2404.11502v1,2024-04-17 15:57:50+00:00,2024-04-17 15:57:50+00:00,cs.CL,"['cs.CL', 'cs.AI']",10
Decomposing and Editing Predictions by Modeling Model Computation,"['Harshay Shah', 'Andrew Ilyas', 'Aleksander Madry']","How does the internal computation of a machine learning model transform inputs into predictions? In this paper, we introduce a task called component modeling that aims to address this question. The goal of component modeling is to decompose an ML model's prediction in terms of its components -- simple functions (e.g., convolution filters, attention heads) that are the ""building blocks"" of model computation. We focus on a special case of this task, component attribution, where the goal is to estimate the counterfactual impact of individual components on a given prediction. We then present COAR, a scalable algorithm for estimating component attributions; we demonstrate its effectiveness across models, datasets, and modalities. Finally, we show that component attributions estimated with COAR directly enable model editing across five tasks, namely: fixing model errors, ``forgetting'' specific classes, boosting subpopulation robustness, localizing backdoor attacks, and improving robustness to typographic attacks. We provide code for COAR at https://github.com/MadryLab/modelcomponents .",2404.11534,http://arxiv.org/abs/2404.11534v1,2024-04-17 16:28:08+00:00,2024-04-17 16:28:08+00:00,cs.LG,"['cs.LG', 'cs.AI', 'stat.ML']",0
FedPFT: Federated Proxy Fine-Tuning of Foundation Models,"['Zhaopeng Peng', 'Xiaoliang Fan', 'Yufan Chen', 'Zheng Wang', 'Shirui Pan', 'Chenglu Wen', 'Ruisheng Zhang', 'Cheng Wang']","Adapting Foundation Models (FMs) for downstream tasks through Federated Learning (FL) emerges a promising strategy for protecting data privacy and valuable FMs. Existing methods fine-tune FM by allocating sub-FM to clients in FL, however, leading to suboptimal performance due to insufficient tuning and inevitable error accumulations of gradients. In this paper, we propose Federated Proxy Fine-Tuning (FedPFT), a novel method enhancing FMs adaptation in downstream tasks through FL by two key modules. First, the sub-FM construction module employs a layer-wise compression approach, facilitating comprehensive FM fine-tuning across all layers by emphasizing those crucial neurons. Second, the sub-FM alignment module conducts a two-step distillations-layer-level and neuron-level-before and during FL fine-tuning respectively, to reduce error of gradient by accurately aligning sub-FM with FM under theoretical guarantees. Experimental results on seven commonly used datasets (i.e., four text and three vision) demonstrate the superiority of FedPFT.",2404.11536,http://arxiv.org/abs/2404.11536v1,2024-04-17 16:30:06+00:00,2024-04-17 16:30:06+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
Quantifying Multilingual Performance of Large Language Models Across Languages,"['Zihao Li', 'Yucheng Shi', 'Zirui Liu', 'Fan Yang', 'Ninghao Liu', 'Mengnan Du']","The training process of Large Language Models (LLMs) requires extensive text corpus. However, these data are often unevenly distributed in different languages. As a result, LLMs perform well on common languages, such as English, German, and French, but perform poorly on low-resource languages. However, currently there is no work to quantitatively measure the performance of LLMs in low-resource languages. To fill this gap, we proposed the Language Ranker that aims to benchmark and rank different languages according to the performance of LLMs on those languages. We employ the LLM's performance on the English corpus as a baseline to compare the performances of different languages and English. We have the following three findings: 1. The performance rankings of different LLMs in all languages are roughly the same. 2. LLMs with different sizes have the same partial order of performance. 3. There is a strong correlation between LlaMa2's performance in different languages and the proportion of the pre-training corpus. These findings illustrate that the Language Ranker can be used as an indicator to measure the language performance of LLMs.",2404.11553,http://arxiv.org/abs/2404.11553v1,2024-04-17 16:53:16+00:00,2024-04-17 16:53:16+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",0
MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation,"['Kuan-Chieh', 'Wang', 'Daniil Ostashev', 'Yuwei Fang', 'Sergey Tulyakov', 'Kfir Aberman']","We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch. MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch. A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable. Project page: https://snap-research.github.io/mixture-of-attention",2404.11565,http://arxiv.org/abs/2404.11565v1,2024-04-17 17:08:05+00:00,2024-04-17 17:08:05+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.GR']",0
Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View,"['Yiwen Tu', 'Pingbang Hu', 'Jiaqi Ma']","Machine unlearning is the process of updating machine learning models to remove the information of specific training data samples, in order to comply with data protection regulations that allow individuals to request the removal of their personal data. Despite the recent development of numerous unlearning algorithms, reliable evaluation of these algorithms remains an open research question. In this work, we focus on membership inference attack (MIA) based evaluation, one of the most common approaches for evaluating unlearning algorithms, and address various pitfalls of existing evaluation metrics that lack reliability. Specifically, we propose a game-theoretic framework that formalizes the evaluation process as a game between unlearning algorithms and MIA adversaries, measuring the data removal efficacy of unlearning algorithms by the capability of the MIA adversaries. Through careful design of the game, we demonstrate that the natural evaluation metric induced from the game enjoys provable guarantees that the existing evaluation metrics fail to satisfy. Furthermore, we propose a practical and efficient algorithm to estimate the evaluation metric induced from the game, and demonstrate its effectiveness through both theoretical analysis and empirical experiments. This work presents a novel and reliable approach to empirically evaluating unlearning algorithms, paving the way for the development of more effective unlearning techniques.",2404.11577,http://arxiv.org/abs/2404.11577v1,2024-04-17 17:20:27+00:00,2024-04-17 17:20:27+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
Deep Policy Optimization with Temporal Logic Constraints,"['Ameesh Shah', 'Cameron Voloshin', 'Chenxi Yang', 'Abhinav Verma', 'Swarat Chaudhuri', 'Sanjit A. Seshia']","Temporal logics, such as linear temporal logic (LTL), offer a precise means of specifying tasks for (deep) reinforcement learning (RL) agents. In our work, we consider the setting where the task is specified by an LTL objective and there is an additional scalar reward that we need to optimize. Previous works focus either on learning a LTL task-satisfying policy alone or are restricted to finite state spaces. We make two contributions: First, we introduce an RL-friendly approach to this setting by formulating this problem as a single optimization objective. Our formulation guarantees that an optimal policy will be reward-maximal from the set of policies that maximize the likelihood of satisfying the LTL specification. Second, we address a sparsity issue that often arises for LTL-guided Deep RL policies by introducing Cycle Experience Replay (CyclER), a technique that automatically guides RL agents towards the satisfaction of an LTL specification. Our experiments demonstrate the efficacy of CyclER in finding performant deep RL policies in both continuous and discrete experimental domains.",2404.11578,http://arxiv.org/abs/2404.11578v1,2024-04-17 17:24:44+00:00,2024-04-17 17:24:44+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.FL']",34
Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models,"['Shivvrat Arya', 'Tahrima Rahman', 'Vibhav Gogate']","We propose a self-supervised learning approach for solving the following constrained optimization task in log-linear models or Markov networks. Let $f$ and $g$ be two log-linear models defined over the sets $\mathbf{X}$ and $\mathbf{Y}$ of random variables respectively. Given an assignment $\mathbf{x}$ to all variables in $\mathbf{X}$ (evidence) and a real number $q$, the constrained most-probable explanation (CMPE) task seeks to find an assignment $\mathbf{y}$ to all variables in $\mathbf{Y}$ such that $f(\mathbf{x}, \mathbf{y})$ is maximized and $g(\mathbf{x}, \mathbf{y})\leq q$. In our proposed self-supervised approach, given assignments $\mathbf{x}$ to $\mathbf{X}$ (data), we train a deep neural network that learns to output near-optimal solutions to the CMPE problem without requiring access to any pre-computed solutions. The key idea in our approach is to use first principles and approximate inference methods for CMPE to derive novel loss functions that seek to push infeasible solutions towards feasible ones and feasible solutions towards optimal ones. We analyze the properties of our proposed method and experimentally demonstrate its efficacy on several benchmark problems.",2404.11606,http://arxiv.org/abs/2404.11606v1,2024-04-17 17:55:17+00:00,2024-04-17 17:55:17+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
Deep Dependency Networks and Advanced Inference Schemes for Multi-Label Classification,"['Shivvrat Arya', 'Yu Xiang', 'Vibhav Gogate']","We present a unified framework called deep dependency networks (DDNs) that combines dependency networks and deep learning architectures for multi-label classification, with a particular emphasis on image and video data. The primary advantage of dependency networks is their ease of training, in contrast to other probabilistic graphical models like Markov networks. In particular, when combined with deep learning architectures, they provide an intuitive, easy-to-use loss function for multi-label classification. A drawback of DDNs compared to Markov networks is their lack of advanced inference schemes, necessitating the use of Gibbs sampling. To address this challenge, we propose novel inference schemes based on local search and integer linear programming for computing the most likely assignment to the labels given observations. We evaluate our novel methods on three video datasets (Charades, TACoS, Wetlab) and three image datasets (MS-COCO, PASCAL VOC, NUS-WIDE), comparing their performance with (a) basic neural architectures and (b) neural architectures combined with Markov networks equipped with advanced inference and learning techniques. Our results demonstrate the superiority of our new DDN methods over the two competing approaches.",2404.11667,http://arxiv.org/abs/2404.11667v1,2024-04-17 18:04:37+00:00,2024-04-17 18:04:37+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']",0
Missed Connections: Lateral Thinking Puzzles for Large Language Models,"['Graham Todd', 'Tim Merino', 'Sam Earle', 'Julian Togelius']","The Connections puzzle published each day by the New York Times tasks players with dividing a bank of sixteen words into four groups of four words that each relate to a common theme. Solving the puzzle requires both common linguistic knowledge (i.e. definitions and typical usage) as well as, in many cases, lateral or abstract thinking. This is because the four categories ascend in complexity, with the most challenging category often requiring thinking about words in uncommon ways or as parts of larger phrases. We investigate the capacity for automated AI systems to play Connections and explore the game's potential as an automated benchmark for abstract reasoning and a way to measure the semantic information encoded by data-driven linguistic systems. In particular, we study both a sentence-embedding baseline and modern large language models (LLMs). We report their accuracy on the task, measure the impacts of chain-of-thought prompting, and discuss their failure modes. Overall, we find that the Connections task is challenging yet feasible, and a strong test-bed for future work.",2404.1173,http://arxiv.org/abs/2404.11730v1,2024-04-17 20:31:05+00:00,2024-04-17 20:31:05+00:00,cs.CL,"['cs.CL', 'cs.AI']",1
Improved Generalization Bounds for Communication Efficient Federated Learning,"['Peyman Gholami', 'Hulya Seferoglu']","This paper focuses on reducing the communication cost of federated learning by exploring generalization bounds and representation learning. We first characterize a tighter generalization bound for one-round federated learning based on local clients' generalizations and heterogeneity of data distribution (non-iid scenario). We also characterize a generalization bound in R-round federated learning and its relation to the number of local updates (local stochastic gradient descents (SGDs)). Then, based on our generalization bound analysis and our representation learning interpretation of this analysis, we show for the first time that less frequent aggregations, hence more local updates, for the representation extractor (usually corresponds to initial layers) leads to the creation of more generalizable models, particularly for non-iid scenarios. We design a novel Federated Learning with Adaptive Local Steps (FedALS) algorithm based on our generalization bound and representation learning analysis. FedALS employs varying aggregation frequencies for different parts of the model, so reduces the communication cost. The paper is followed with experimental results showing the effectiveness of FedALS.",2404.11754,http://arxiv.org/abs/2404.11754v1,2024-04-17 21:17:48+00:00,2024-04-17 21:17:48+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
Prompt-Driven Feature Diffusion for Open-World Semi-Supervised Learning,"['Marzi Heidari', 'Hanping Zhang', 'Yuhong Guo']","In this paper, we present a novel approach termed Prompt-Driven Feature Diffusion (PDFD) within a semi-supervised learning framework for Open World Semi-Supervised Learning (OW-SSL). At its core, PDFD deploys an efficient feature-level diffusion model with the guidance of class-specific prompts to support discriminative feature representation learning and feature generation, tackling the challenge of the non-availability of labeled data for unseen classes in OW-SSL. In particular, PDFD utilizes class prototypes as prompts in the diffusion model, leveraging their class-discriminative and semantic generalization ability to condition and guide the diffusion process across all the seen and unseen classes. Furthermore, PDFD incorporates a class-conditional adversarial loss for diffusion model training, ensuring that the features generated via the diffusion process can be discriminatively aligned with the class-conditional features of the real data. Additionally, the class prototypes of the unseen classes are computed using only unlabeled instances with confident predictions within a semi-supervised learning framework. We conduct extensive experiments to evaluate the proposed PDFD. The empirical results show PDFD exhibits remarkable performance enhancements over many state-of-the-art existing methods.",2404.11795,http://arxiv.org/abs/2404.11795v1,2024-04-17 23:10:11+00:00,2024-04-17 23:10:11+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CV']",0
Developing Situational Awareness for Joint Action with Autonomous Vehicles,"['Robert Kaufman', 'David Kirsh', 'Nadir Weibel']","Unanswered questions about how human-AV interaction designers can support rider's informational needs hinders Autonomous Vehicles (AV) adoption. To achieve joint human-AV action goals - such as safe transportation, trust, or learning from an AV - sufficient situational awareness must be held by the human, AV, and human-AV system collectively. We present a systems-level framework that integrates cognitive theories of joint action and situational awareness as a means to tailor communications that meet the criteria necessary for goal success. This framework is based on four components of the shared situation: AV traits, action goals, subject-specific traits and states, and the situated driving context. AV communications should be tailored to these factors and be sensitive when they change. This framework can be useful for understanding individual, shared, and distributed human-AV situational awareness and designing for future AV communications that meet the informational needs and goals of diverse groups and in diverse driving contexts.",2404.118,http://arxiv.org/abs/2404.11800v1,2024-04-17 23:41:48+00:00,2024-04-17 23:41:48+00:00,cs.HC,"['cs.HC', 'cs.AI', 'cs.RO']",0
Physics-informed active learning for accelerating quantum chemical simulations,"['Yi-Fan Hou', 'Lina Zhang', 'Quanhao Zhang', 'Fuchun Ge', 'Pavlo O. Dral']","Quantum chemical simulations can be greatly accelerated by constructing machine learning potentials, which is often done using active learning (AL). The usefulness of the constructed potentials is often limited by the high effort required and their insufficient robustness in the simulations. Here we introduce the end-to-end AL for constructing robust data-efficient potentials with affordable investment of time and resources and minimum human interference. Our AL protocol is based on the physics-informed sampling of training points, automatic selection of initial data, and uncertainty quantification. The versatility of this protocol is shown in our implementation of quasi-classical molecular dynamics for simulating vibrational spectra, conformer search of a key biochemical molecule, and time-resolved mechanism of the Diels-Alder reaction. These investigations took us days instead of weeks of pure quantum chemical calculations on a high-performance computing cluster.",2404.11811,http://arxiv.org/abs/2404.11811v1,2024-04-18 00:17:01+00:00,2024-04-18 00:17:01+00:00,physics.chem-ph,"['physics.chem-ph', 'cs.AI', 'cs.LG']",0
Using a Local Surrogate Model to Interpret Temporal Shifts in Global Annual Data,"['Shou Nakano', 'Yang Liu']","This paper focuses on explaining changes over time in globally-sourced, annual temporal data, with the specific objective of identifying pivotal factors that contribute to these temporal shifts. Leveraging such analytical frameworks can yield transformative impacts, including the informed refinement of public policy and the identification of key drivers affecting a country's economic evolution. We employ Local Interpretable Model-agnostic Explanations (LIME) to shed light on national happiness indices, economic freedom, and population metrics, spanning variable time frames. Acknowledging the presence of missing values, we employ three imputation approaches to generate robust multivariate time-series datasets apt for LIME's input requirements. Our methodology's efficacy is substantiated through a series of empirical evaluations involving multiple datasets. These evaluations include comparative analyses against random feature selection, correlation with real-world events as elucidated by LIME, and validation through Individual Conditional Expectation (ICE) plots, a state-of-the-art technique proficient in feature importance detection.",2404.11874,http://arxiv.org/abs/2404.11874v1,2024-04-18 03:17:45+00:00,2024-04-18 03:17:45+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
SKIP: Skill-Localized Prompt Tuning for Inference Speed Boost-Up,"['Nakyeong Yang', 'Junseok Kim', 'Jiwon Moon', 'Yunah Jang', 'Kyomin Jung']","Prompt-tuning methods have shown comparable performance as parameter-efficient fine-tuning (PEFT) methods in various natural language understanding tasks. However, existing prompt tuning methods still utilize the entire model architecture; thus, they fail to accelerate inference speed in the application. In this paper, we propose a novel approach called SKIll-localized Prompt tuning (SKIP), which is extremely efficient in inference time. Our method significantly enhances inference efficiency by investigating and utilizing a skill-localized subnetwork in a language model. Surprisingly, our method improves the inference speed up to 160% while pruning 52% of the parameters. Furthermore, we demonstrate that our method is applicable across various transformer-based architectures, thereby confirming its practicality and scalability.",2404.11916,http://arxiv.org/abs/2404.11916v1,2024-04-18 05:43:50+00:00,2024-04-18 05:43:50+00:00,cs.CL,"['cs.CL', 'cs.AI']",41
Expected Coordinate Improvement for High-Dimensional Bayesian Optimization,['Dawei Zhan'],"Bayesian optimization (BO) algorithm is very popular for solving low-dimensional expensive optimization problems. Extending Bayesian optimization to high dimension is a meaningful but challenging task. One of the major challenges is that it is difficult to find good infill solutions as the acquisition functions are also high-dimensional. In this work, we propose the expected coordinate improvement (ECI) criterion for high-dimensional Bayesian optimization. The proposed ECI criterion measures the potential improvement we can get by moving the current best solution along one coordinate. The proposed approach selects the coordinate with the highest ECI value to refine in each iteration and covers all the coordinates gradually by iterating over the coordinates. The greatest advantage of the proposed ECI-BO (expected coordinate improvement based Bayesian optimization) algorithm over the standard BO algorithm is that the infill selection problem of the proposed algorithm is always a one-dimensional problem thus can be easily solved. Numerical experiments show that the proposed algorithm can achieve significantly better results than the standard BO algorithm and competitive results when compared with five state-of-the-art high-dimensional BOs. This work provides a simple but efficient approach for high-dimensional Bayesian optimization.",2404.11917,http://arxiv.org/abs/2404.11917v1,2024-04-18 05:48:15+00:00,2024-04-18 05:48:15+00:00,cs.LG,"['cs.LG', 'cs.AI', 'stat.ML']",0
EdgeFusion: On-Device Text-to-Image Generation,"['Thibault Castells', 'Hyoung-Kyu Song', 'Tairen Piao', 'Shinkook Choi', 'Bo-Kyeong Kim', 'Hanyoung Yim', 'Changgwun Lee', 'Jae Gon Kim', 'Tae-Ho Kim']","The intensive computational burden of Stable Diffusion (SD) for text-to-image generation poses a significant hurdle for its practical application. To tackle this challenge, recent research focuses on methods to reduce sampling steps, such as Latent Consistency Model (LCM), and on employing architectural optimizations, including pruning and knowledge distillation. Diverging from existing approaches, we uniquely start with a compact SD variant, BK-SDM. We observe that directly applying LCM to BK-SDM with commonly used crawled datasets yields unsatisfactory results. It leads us to develop two strategies: (1) leveraging high-quality image-text pairs from leading generative models and (2) designing an advanced distillation process tailored for LCM. Through our thorough exploration of quantization, profiling, and on-device deployment, we achieve rapid generation of photo-realistic, text-aligned images in just two steps, with latency under one second on resource-limited edge devices.",2404.11925,http://arxiv.org/abs/2404.11925v1,2024-04-18 06:02:54+00:00,2024-04-18 06:02:54+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CV']",0
CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignment,"['Geyu Lin', 'Bin Wang', 'Zhengyuan Liu', 'Nancy F. Chen']","Multilingual proficiency presents a significant challenge for large language models (LLMs). English-centric models are usually suboptimal in other languages, particularly those that are linguistically distant from English. This performance discrepancy mainly stems from the imbalanced distribution of training data across languages during pre-training and instruction tuning stages. To address this problem, we propose a novel approach called CrossIn, which utilizes a mixed composition of cross-lingual instruction tuning data. Our method leverages the compressed representation shared by various languages to efficiently enhance the model's task-solving capabilities and multilingual proficiency within a single process. In addition, we introduce a multi-task and multi-faceted benchmark to evaluate the effectiveness of CrossIn. Experimental results demonstrate that our method substantially improves performance across tasks and languages, and we provide extensive insights into the impact of cross-lingual data volume and the integration of translation data on enhancing multilingual consistency and accuracy.",2404.11932,http://arxiv.org/abs/2404.11932v1,2024-04-18 06:20:50+00:00,2024-04-18 06:20:50+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity,"['Lasal Jayawardena', 'Prasan Yapa']","Paraphrase generation is a pivotal task in natural language processing (NLP). Existing datasets in the domain lack syntactic and lexical diversity, resulting in paraphrases that closely resemble the source sentences. Moreover, these datasets often contain hate speech and noise, and may unintentionally include non-English language sentences. This research introduces ParaFusion, a large-scale, high-quality English paraphrase dataset developed using Large Language Models (LLM) to address these challenges. ParaFusion augments existing datasets with high-quality data, significantly enhancing both lexical and syntactic diversity while maintaining close semantic similarity. It also mitigates the presence of hate speech and reduces noise, ensuring a cleaner and more focused English dataset. Results show that ParaFusion offers at least a 25% improvement in both syntactic and lexical diversity, measured across several metrics for each data source. The paper also aims to set a gold standard for paraphrase evaluation as it contains one of the most comprehensive evaluation strategies to date. The results underscore the potential of ParaFusion as a valuable resource for improving NLP applications.",2404.1201,http://arxiv.org/abs/2404.12010v1,2024-04-18 09:02:45+00:00,2024-04-18 09:02:45+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",0
Can We Catch the Elephant? The Evolvement of Hallucination Evaluation on Natural Language Generation: A Survey,"['Siya Qi', 'Yulan He', 'Zheng Yuan']","Hallucination in Natural Language Generation (NLG) is like the elephant in the room, obvious but often overlooked until recent achievements significantly improved the fluency and grammatical accuracy of generated text. For Large Language Models (LLMs), hallucinations can happen in various downstream tasks and casual conversations, which need accurate assessment to enhance reliability and safety. However, current studies on hallucination evaluation vary greatly, and people still find it difficult to sort out and select the most appropriate evaluation methods. Moreover, as NLP research gradually shifts to the domain of LLMs, it brings new challenges to this direction. This paper provides a comprehensive survey on the evolvement of hallucination evaluation methods, aiming to address three key aspects: 1) Diverse definitions and granularity of facts; 2) The categories of automatic evaluators and their applicability; 3) Unresolved issues and future directions.",2404.12041,http://arxiv.org/abs/2404.12041v1,2024-04-18 09:52:18+00:00,2024-04-18 09:52:18+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
"Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation","['Steffen Holter', 'Mennatallah El-Assady']","As full AI-based automation remains out of reach in most real-world applications, the focus has instead shifted to leveraging the strengths of both human and AI agents, creating effective collaborative systems. The rapid advances in this area have yielded increasingly more complex systems and frameworks, while the nuance of their characterization has gotten more vague. Similarly, the existing conceptual models no longer capture the elaborate processes of these systems nor describe the entire scope of their collaboration paradigms. In this paper, we propose a new unified set of dimensions through which to analyze and describe human-AI systems. Our conceptual model is centered around three high-level aspects - agency, interaction, and adaptation - and is developed through a multi-step process. Firstly, an initial design space is proposed by surveying the literature and consolidating existing definitions and conceptual frameworks. Secondly, this model is iteratively refined and validated by conducting semi-structured interviews with nine researchers in this field. Lastly, to illustrate the applicability of our design space, we utilize it to provide a structured description of selected human-AI systems.",2404.12056,http://arxiv.org/abs/2404.12056v1,2024-04-18 10:12:18+00:00,2024-04-18 10:12:18+00:00,cs.HC,"['cs.HC', 'cs.AI']",0
"RAGAR, Your Falsehood RADAR: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models","['M. Abdul Khaliq', 'P. Chang', 'M. Ma', 'B. Pflugfelder', 'F. Miletić']","The escalating challenge of misinformation, particularly in the context of political discourse, necessitates advanced solutions for fact-checking. We introduce innovative approaches to enhance the reliability and efficiency of multimodal fact-checking through the integration of Large Language Models (LLMs) with Retrieval-augmented Generation (RAG)- based advanced reasoning techniques. This work proposes two novel methodologies, Chain of RAG (CoRAG) and Tree of RAG (ToRAG). The approaches are designed to handle multimodal claims by reasoning the next questions that need to be answered based on previous evidence. Our approaches improve the accuracy of veracity predictions and the generation of explanations over the traditional fact-checking approach of sub-question generation with chain of thought veracity prediction. By employing multimodal LLMs adept at analyzing both text and images, this research advances the capability of automated systems in identifying and countering misinformation.",2404.12065,http://arxiv.org/abs/2404.12065v1,2024-04-18 10:25:42+00:00,2024-04-18 10:25:42+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.ET', 'cs.MA']",0
TIMIT Speaker Profiling: A Comparison of Multi-task learning and Single-task learning Approaches,"['Rong Wang', 'Kun Sun']","This study employs deep learning techniques to explore four speaker profiling tasks on the TIMIT dataset, namely gender classification, accent classification, age estimation, and speaker identification, highlighting the potential and challenges of multi-task learning versus single-task models. The motivation for this research is twofold: firstly, to empirically assess the advantages and drawbacks of multi-task learning over single-task models in the context of speaker profiling; secondly, to emphasize the undiminished significance of skillful feature engineering for speaker recognition tasks. The findings reveal challenges in accent classification, and multi-task learning is found advantageous for tasks of similar complexity. Non-sequential features are favored for speaker recognition, but sequential ones can serve as starting points for complex models. The study underscores the necessity of meticulous experimentation and parameter tuning for deep learning models.",2404.12077,http://arxiv.org/abs/2404.12077v1,2024-04-18 10:59:54+00:00,2024-04-18 10:59:54+00:00,cs.SD,"['cs.SD', 'cs.AI', 'cs.CL', 'cs.LG', 'eess.AS']",0
"Fortify the Guardian, Not the Treasure: Resilient Adversarial Detectors","['Raz Lapid', 'Almog Dubin', 'Moshe Sipper']","This paper presents RADAR-Robust Adversarial Detection via Adversarial Retraining-an approach designed to enhance the robustness of adversarial detectors against adaptive attacks, while maintaining classifier performance. An adaptive attack is one where the attacker is aware of the defenses and adapts their strategy accordingly. Our proposed method leverages adversarial training to reinforce the ability to detect attacks, without compromising clean accuracy. During the training phase, we integrate into the dataset adversarial examples, which were optimized to fool both the classifier and the adversarial detector, enabling the adversarial detector to learn and adapt to potential attack scenarios. Experimental evaluations on the CIFAR-10 and SVHN datasets demonstrate that our proposed algorithm significantly improves a detector's ability to accurately identify adaptive adversarial attacks -- without sacrificing clean accuracy.",2404.1212,http://arxiv.org/abs/2404.12120v1,2024-04-18 12:13:09+00:00,2024-04-18 12:13:09+00:00,cs.CV,"['cs.CV', 'cs.AI']",38
Real-World Efficient Blind Motion Deblurring via Blur Pixel Discretization,"['Insoo Kim', 'Jae Seok Choi', 'Geonseok Seo', 'Kinam Kwon', 'Jinwoo Shin', 'Hyong-Euk Lee']","As recent advances in mobile camera technology have enabled the capability to capture high-resolution images, such as 4K images, the demand for an efficient deblurring model handling large motion has increased. In this paper, we discover that the image residual errors, i.e., blur-sharp pixel differences, can be grouped into some categories according to their motion blur type and how complex their neighboring pixels are. Inspired by this, we decompose the deblurring (regression) task into blur pixel discretization (pixel-level blur classification) and discrete-to-continuous conversion (regression with blur class map) tasks. Specifically, we generate the discretized image residual errors by identifying the blur pixels and then transform them to a continuous form, which is computationally more efficient than naively solving the original regression problem with continuous values. Here, we found that the discretization result, i.e., blur segmentation map, remarkably exhibits visual similarity with the image residual errors. As a result, our efficient model shows comparable performance to state-of-the-art methods in realistic benchmarks, while our method is up to 10 times computationally more efficient.",2404.12168,http://arxiv.org/abs/2404.12168v1,2024-04-18 13:22:56+00:00,2024-04-18 13:22:56+00:00,cs.CV,"['cs.CV', 'cs.AI']",4
Food Portion Estimation via 3D Object Scaling,"['Gautham Vinod', 'Jiangpeng He', 'Zeman Shao', 'Fengqing Zhu']","Image-based methods to analyze food images have alleviated the user burden and biases associated with traditional methods. However, accurate portion estimation remains a major challenge due to the loss of 3D information in the 2D representation of foods captured by smartphone cameras or wearable devices. In this paper, we propose a new framework to estimate both food volume and energy from 2D images by leveraging the power of 3D food models and physical reference in the eating scene. Our method estimates the pose of the camera and the food object in the input image and recreates the eating occasion by rendering an image of a 3D model of the food with the estimated poses. We also introduce a new dataset, SimpleFood45, which contains 2D images of 45 food items and associated annotations including food volume, weight, and energy. Our method achieves an average error of 31.10 kCal (17.67%) on this dataset, outperforming existing portion estimation methods.",2404.12257,http://arxiv.org/abs/2404.12257v1,2024-04-18 15:23:37+00:00,2024-04-18 15:23:37+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.MM', 'eess.IV']",0
Augmenting emotion features in irony detection with Large language modeling,"['Yucheng Lin', 'Yuhan Xia', 'Yunfei Long']","This study introduces a novel method for irony detection, applying Large Language Models (LLMs) with prompt-based learning to facilitate emotion-centric text augmentation. Traditional irony detection techniques typically fall short due to their reliance on static linguistic features and predefined knowledge bases, often overlooking the nuanced emotional dimensions integral to irony. In contrast, our methodology augments the detection process by integrating subtle emotional cues, augmented through LLMs, into three benchmark pre-trained NLP models - BERT, T5, and GPT-2 - which are widely recognized as foundational in irony detection. We assessed our method using the SemEval-2018 Task 3 dataset and observed substantial enhancements in irony detection capabilities.",2404.12291,http://arxiv.org/abs/2404.12291v1,2024-04-18 16:11:17+00:00,2024-04-18 16:11:17+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair,"['Yusuke Sakai', 'Mana Makinae', 'Hidetaka Kamigaito', 'Taro Watanabe']","In Simultaneous Machine Translation (SiMT) systems, training with a simultaneous interpretation (SI) corpus is an effective method for achieving high-quality yet low-latency systems. However, it is very challenging to curate such a corpus due to limitations in the abilities of annotators, and hence, existing SI corpora are limited. Therefore, we propose a method to convert existing speech translation corpora into interpretation-style data, maintaining the original word order and preserving the entire source content using Large Language Models (LLM-SI-Corpus). We demonstrate that fine-tuning SiMT models in text-to-text and speech-to-text settings with the LLM-SI-Corpus reduces latencies while maintaining the same level of quality as the models trained with offline datasets. The LLM-SI-Corpus is available at \url{https://github.com/yusuke1997/LLM-SI-Corpus}.",2404.12299,http://arxiv.org/abs/2404.12299v1,2024-04-18 16:24:12+00:00,2024-04-18 16:24:12+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG', 'cs.SD', 'eess.AS']",1
Large Language Models for Synthetic Participatory Planning of Shared Automated Electric Mobility Systems,['Jiangbo Yu'],"Unleashing the synergies of rapidly evolving mobility technologies in a multi-stakeholder landscape presents unique challenges and opportunities for addressing urban transportation problems. This paper introduces a novel synthetic participatory method, critically leveraging large language models (LLMs) to create digital avatars representing diverse stakeholders to plan shared automated electric mobility systems (SAEMS). These calibratable agents collaboratively identify objectives, envision and evaluate SAEMS alternatives, and strategize implementation under risks and constraints. The results of a Montreal case study indicate that a structured and parameterized workflow provides outputs with high controllability and comprehensiveness on an SAEMS plan than generated using a single LLM-enabled expert agent. Consequently, the approach provides a promising avenue for cost-efficiently improving the inclusivity and interpretability of multi-objective transportation planning, suggesting a paradigm shift in how we envision and strategize for sustainable and equitable transportation systems.",2404.12317,http://arxiv.org/abs/2404.12317v1,2024-04-18 16:51:23+00:00,2024-04-18 16:51:23+00:00,cs.CE,"['cs.CE', 'cs.AI', 'cs.CY', 'cs.HC', 'cs.MA']",0
6Img-to-3D: Few-Image Large-Scale Outdoor Driving Scene Reconstruction,"['Théo Gieruc', 'Marius Kästingschäfer', 'Sebastian Bernhard', 'Mathieu Salzmann']","Current 3D reconstruction techniques struggle to infer unbounded scenes from a few images faithfully. Specifically, existing methods have high computational demands, require detailed pose information, and cannot reconstruct occluded regions reliably. We introduce 6Img-to-3D, an efficient, scalable transformer-based encoder-renderer method for single-shot image to 3D reconstruction. Our method outputs a 3D-consistent parameterized triplane from only six outward-facing input images for large-scale, unbounded outdoor driving scenarios. We take a step towards resolving existing shortcomings by combining contracted custom cross- and self-attention mechanisms for triplane parameterization, differentiable volume rendering, scene contraction, and image feature projection. We showcase that six surround-view vehicle images from a single timestamp without global pose information are enough to reconstruct 360$^{\circ}$ scenes during inference time, taking 395 ms. Our method allows, for example, rendering third-person images and birds-eye views. Our code is available at https://github.com/continental/6Img-to-3D, and more examples can be found at our website here https://6Img-to-3D.GitHub.io/.",2404.12378,http://arxiv.org/abs/2404.12378v1,2024-04-18 17:58:16+00:00,2024-04-18 17:58:16+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",0
Lazy Diffusion Transformer for Interactive Image Editing,"['Yotam Nitzan', 'Zongze Wu', 'Richard Zhang', 'Eli Shechtman', 'Daniel Cohen-Or', 'Taesung Park', 'Michaël Gharbi']","We introduce a novel diffusion transformer, LazyDiffusion, that generates partial image updates efficiently. Our approach targets interactive image editing applications in which, starting from a blank canvas or an image, a user specifies a sequence of localized image modifications using binary masks and text prompts. Our generator operates in two phases. First, a context encoder processes the current canvas and user mask to produce a compact global context tailored to the region to generate. Second, conditioned on this context, a diffusion-based transformer decoder synthesizes the masked pixels in a ""lazy"" fashion, i.e., it only generates the masked region. This contrasts with previous works that either regenerate the full canvas, wasting time and computation, or confine processing to a tight rectangular crop around the mask, ignoring the global image context altogether. Our decoder's runtime scales with the mask size, which is typically small, while our encoder introduces negligible overhead. We demonstrate that our approach is competitive with state-of-the-art inpainting methods in terms of quality and fidelity while providing a 10x speedup for typical user interactions, where the editing mask represents 10% of the image.",2404.12382,http://arxiv.org/abs/2404.12382v1,2024-04-18 17:59:27+00:00,2024-04-18 17:59:27+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.GR']",21
AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation,"['Qing En', 'Yuhong Guo']","Lung-infected area segmentation is crucial for assessing the severity of lung diseases. However, existing image-text multi-modal methods typically rely on labour-intensive annotations for model training, posing challenges regarding time and expertise. To address this issue, we propose a novel attribute knowledge-guided framework for unsupervised lung-infected area segmentation (AKGNet), which achieves segmentation solely based on image-text data without any mask annotation. AKGNet facilitates text attribute knowledge learning, attribute-image cross-attention fusion, and high-confidence-based pseudo-label exploration simultaneously. It can learn statistical information and capture spatial correlations between image and text attributes in the embedding space, iteratively refining the mask to enhance segmentation. Specifically, we introduce a text attribute knowledge learning module by extracting attribute knowledge and incorporating it into feature representations, enabling the model to learn statistical information and adapt to different attributes. Moreover, we devise an attribute-image cross-attention module by calculating the correlation between attributes and images in the embedding space to capture spatial dependency information, thus selectively focusing on relevant regions while filtering irrelevant areas. Finally, a self-training mask improvement process is employed by generating pseudo-labels using high-confidence predictions to iteratively enhance the mask and segmentation. Experimental results on a benchmark medical image dataset demonstrate the superior performance of our method compared to state-of-the-art segmentation techniques in unsupervised scenarios.",2404.11008,http://arxiv.org/abs/2404.11008v1,2024-04-17 02:36:02+00:00,2024-04-17 02:36:02+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs,"['Kang Wang', 'Zhishu Shen', 'Zhen Lei', 'Tiehua Zhang']","Traffic signal control systems (TSCSs) are integral to intelligent traffic management, fostering efficient vehicle flow. Traditional approaches often simplify road networks into standard graphs, which results in a failure to consider the dynamic nature of traffic data at neighboring intersections, thereby neglecting higher-order interconnections necessary for real-time control. To address this, we propose a novel TSCS framework to realize intelligent traffic control. This framework collaborates with multiple neighboring edge computing servers to collect traffic information across the road network. To elevate the efficiency of traffic signal control, we have crafted a multi-agent soft actor-critic (MA-SAC) reinforcement learning algorithm. Within this algorithm, individual agents are deployed at each intersection with a mandate to optimize traffic flow across the entire road network collectively. Furthermore, we introduce hypergraph learning into the critic network of MA-SAC to enable the spatio-temporal interactions from multiple intersections in the road network. This method fuses hypergraph and spatio-temporal graph structures to encode traffic data and capture the complex spatial and temporal correlations between multiple intersections. Our empirical evaluation, tested on varied datasets, demonstrates the superiority of our framework in minimizing average vehicle travel times and sustaining high-throughput performance. This work facilitates the development of more intelligent and reactive urban traffic management solutions.",2404.11014,http://arxiv.org/abs/2404.11014v1,2024-04-17 02:46:18+00:00,2024-04-17 02:46:18+00:00,cs.MA,"['cs.MA', 'cs.AI']",0
FedFa: A Fully Asynchronous Training Paradigm for Federated Learning,"['Haotian Xu', 'Zhaorui Zhang', 'Sheng Di', 'Benben Liu', 'Alharthi Khalid', 'Jiannong Cao']","Federated learning has been identified as an efficient decentralized training paradigm for scaling the machine learning model training on a large number of devices while guaranteeing the data privacy of the trainers. FedAvg has become a foundational parameter update strategy for federated learning, which has been promising to eliminate the effect of the heterogeneous data across clients and guarantee convergence. However, the synchronization parameter update barriers for each communication round during the training significant time on waiting, slowing down the training procedure. Therefore, recent state-of-the-art solutions propose using semi-asynchronous approaches to mitigate the waiting time cost with guaranteed convergence. Nevertheless, emerging semi-asynchronous approaches are unable to eliminate the waiting time completely.   We propose a full asynchronous training paradigm, called FedFa, which can guarantee model convergence and eliminate the waiting time completely for federated learning by using a few buffered results on the server for parameter updating. Further, we provide theoretical proof of the convergence rate for our proposed FedFa. Extensive experimental results indicate our approach effectively improves the training performance of federated learning by up to 6x and 4x speedup compared to the state-of-the-art synchronous and semi-asynchronous strategies while retaining high accuracy in both IID and Non-IID scenarios.",2404.11015,http://arxiv.org/abs/2404.11015v1,2024-04-17 02:46:59+00:00,2024-04-17 02:46:59+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.DC']",65
MaeFuse: Transferring Omni Features with Pretrained Masked Autoencoders for Infrared and Visible Image Fusion via Guided Training,"['Jiayang Li', 'Junjun Jiang', 'Pengwei Liang', 'Jiayi Ma']","In this research, we introduce MaeFuse, a novel autoencoder model designed for infrared and visible image fusion (IVIF). The existing approaches for image fusion often rely on training combined with downstream tasks to obtain high-level visual information, which is effective in emphasizing target objects and delivering impressive results in visual quality and task-specific applications. MaeFuse, however, deviates from the norm. Instead of being driven by downstream tasks, our model utilizes a pretrained encoder from Masked Autoencoders (MAE), which facilities the omni features extraction for low-level reconstruction and high-level vision tasks, to obtain perception friendly features with a low cost. In order to eliminate the domain gap of different modal features and the block effect caused by the MAE encoder, we further develop a guided training strategy. This strategy is meticulously crafted to ensure that the fusion layer seamlessly adjusts to the feature space of the encoder, gradually enhancing the fusion effect. It facilitates the comprehensive integration of feature vectors from both infrared and visible modalities, preserving the rich details inherent in each. MaeFuse not only introduces a novel perspective in the realm of fusion techniques but also stands out with impressive performance across various public datasets.",2404.11016,http://arxiv.org/abs/2404.11016v1,2024-04-17 02:47:39+00:00,2024-04-17 02:47:39+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
Many-Shot In-Context Learning,"['Rishabh Agarwal', 'Avi Singh', 'Lei M. Zhang', 'Bernd Bohnet', 'Stephanie Chan', 'Ankesh Anand', 'Zaheer Abbas', 'Azade Nova', 'John D. Co-Reyes', 'Eric Chu', 'Feryal Behbahani', 'Aleksandra Faust', 'Hugo Larochelle']","Large language models (LLMs) excel at few-shot in-context learning (ICL) -- learning from a few examples provided in context at inference, without any weight updates. Newly expanded context windows allow us to investigate ICL with hundreds or thousands of examples -- the many-shot regime. Going from few-shot to many-shot, we observe significant performance gains across a wide variety of generative and discriminative tasks. While promising, many-shot ICL can be bottlenecked by the available amount of human-generated examples. To mitigate this limitation, we explore two new settings: Reinforced and Unsupervised ICL. Reinforced ICL uses model-generated chain-of-thought rationales in place of human examples. Unsupervised ICL removes rationales from the prompt altogether, and prompts the model only with domain-specific questions. We find that both Reinforced and Unsupervised ICL can be quite effective in the many-shot regime, particularly on complex reasoning tasks. Finally, we demonstrate that, unlike few-shot learning, many-shot learning is effective at overriding pretraining biases and can learn high-dimensional functions with numerical inputs. Our analysis also reveals the limitations of next-token prediction loss as an indicator of downstream ICL performance.",2404.11018,http://arxiv.org/abs/2404.11018v1,2024-04-17 02:49:26+00:00,2024-04-17 02:49:26+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CL']",26
Rethinking 3D Dense Caption and Visual Grounding in A Unified Framework through Prompt-based Localization,"['Yongdong Luo', 'Haojia Lin', 'Xiawu Zheng', 'Yigeng Jiang', 'Fei Chao', 'Jie Hu', 'Guannan Jiang', 'Songan Zhang', 'Rongrong Ji']","3D Visual Grounding (3DVG) and 3D Dense Captioning (3DDC) are two crucial tasks in various 3D applications, which require both shared and complementary information in localization and visual-language relationships. Therefore, existing approaches adopt the two-stage ""detect-then-describe/discriminate"" pipeline, which relies heavily on the performance of the detector, resulting in suboptimal performance. Inspired by DETR, we propose a unified framework, 3DGCTR, to jointly solve these two distinct but closely related tasks in an end-to-end fashion. The key idea is to reconsider the prompt-based localization ability of the 3DVG model. In this way, the 3DVG model with a well-designed prompt as input can assist the 3DDC task by extracting localization information from the prompt. In terms of implementation, we integrate a Lightweight Caption Head into the existing 3DVG network with a Caption Text Prompt as a connection, effectively harnessing the existing 3DVG model's inherent localization capacity, thereby boosting 3DDC capability. This integration facilitates simultaneous multi-task training on both tasks, mutually enhancing their performance. Extensive experimental results demonstrate the effectiveness of this approach. Specifically, on the ScanRefer dataset, 3DGCTR surpasses the state-of-the-art 3DDC method by 4.3% in CIDEr@0.5IoU in MLE training and improves upon the SOTA 3DVG method by 3.16% in Acc@0.25IoU.",2404.11064,http://arxiv.org/abs/2404.11064v1,2024-04-17 04:46:27+00:00,2024-04-17 04:46:27+00:00,cs.CV,"['cs.CV', 'cs.AI']",13
What's under the hood: Investigating Automatic Metrics on Meeting Summarization,"['Frederic Kirstein', 'Jan Philip Wahle', 'Terry Ruas', 'Bela Gipp']","Meeting summarization has become a critical task considering the increase in online interactions. While new techniques are introduced regularly, their evaluation uses metrics not designed to capture meeting-specific errors, undermining effective evaluation. This paper investigates what the frequently used automatic metrics capture and which errors they mask by correlating automatic metric scores with human evaluations across a broad error taxonomy. We commence with a comprehensive literature review on English meeting summarization to define key challenges like speaker dynamics and contextual turn-taking and error types such as missing information and linguistic inaccuracy, concepts previously loosely defined in the field. We examine the relationship between characteristic challenges and errors by using annotated transcripts and summaries from Transformer-based sequence-to-sequence and autoregressive models from the general summary QMSum dataset. Through experimental validation, we find that different model architectures respond variably to challenges in meeting transcripts, resulting in different pronounced links between challenges and errors. Current default-used metrics struggle to capture observable errors, showing weak to mid-correlations, while a third of the correlations show trends of error masking. Only a subset reacts accurately to specific errors, while most correlations show either unresponsiveness or failure to reflect the error's impact on summary quality.",2404.11124,http://arxiv.org/abs/2404.11124v1,2024-04-17 07:15:07+00:00,2024-04-17 07:15:07+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
Deep Neural Networks via Complex Network Theory: a Perspective,"['Emanuele La Malfa', 'Gabriele La Malfa', 'Giuseppe Nicosia', 'Vito Latora']","Deep Neural Networks (DNNs) can be represented as graphs whose links and vertices iteratively process data and solve tasks sub-optimally. Complex Network Theory (CNT), merging statistical physics with graph theory, provides a method for interpreting neural networks by analysing their weights and neuron structures. However, classic works adapt CNT metrics that only permit a topological analysis as they do not account for the effect of the input data. In addition, CNT metrics have been applied to a limited range of architectures, mainly including Fully Connected neural networks. In this work, we extend the existing CNT metrics with measures that sample from the DNNs' training distribution, shifting from a purely topological analysis to one that connects with the interpretability of deep learning. For the novel metrics, in addition to the existing ones, we provide a mathematical formalisation for Fully Connected, AutoEncoder, Convolutional and Recurrent neural networks, of which we vary the activation functions and the number of hidden layers. We show that these metrics differentiate DNNs based on the architecture, the number of hidden layers, and the activation function. Our contribution provides a method rooted in physics for interpreting DNNs that offers insights beyond the traditional input-output relationship and the CNT topological analysis.",2404.11172,http://arxiv.org/abs/2404.11172v2,2024-04-17 08:42:42+00:00,2024-04-18 11:17:43+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
KI-GAN: Knowledge-Informed Generative Adversarial Networks for Enhanced Multi-Vehicle Trajectory Forecasting at Signalized Intersections,"['Chuheng Wei', 'Guoyuan Wu', 'Matthew J. Barth', 'Amr Abdelraouf', 'Rohit Gupta', 'Kyungtae Han']","Reliable prediction of vehicle trajectories at signalized intersections is crucial to urban traffic management and autonomous driving systems. However, it presents unique challenges, due to the complex roadway layout at intersections, involvement of traffic signal controls, and interactions among different types of road users. To address these issues, we present in this paper a novel model called Knowledge-Informed Generative Adversarial Network (KI-GAN), which integrates both traffic signal information and multi-vehicle interactions to predict vehicle trajectories accurately. Additionally, we propose a specialized attention pooling method that accounts for vehicle orientation and proximity at intersections. Based on the SinD dataset, our KI-GAN model is able to achieve an Average Displacement Error (ADE) of 0.05 and a Final Displacement Error (FDE) of 0.12 for a 6-second observation and 6-second prediction cycle. When the prediction window is extended to 9 seconds, the ADE and FDE values are further reduced to 0.11 and 0.26, respectively. These results demonstrate the effectiveness of the proposed KI-GAN model in vehicle trajectory prediction under complex scenarios at signalized intersections, which represents a significant advancement in the target field.",2404.11181,http://arxiv.org/abs/2404.11181v1,2024-04-17 08:53:59+00:00,2024-04-17 08:53:59+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.RO']",11
Exploring the Transferability of Visual Prompting for Multimodal Large Language Models,"['Yichi Zhang', 'Yinpeng Dong', 'Siyuan Zhang', 'Tianzan Min', 'Hang Su', 'Jun Zhu']","Although Multimodal Large Language Models (MLLMs) have demonstrated promising versatile capabilities, their performance is still inferior to specialized models on downstream tasks, which makes adaptation necessary to enhance their utility. However, fine-tuning methods require independent training for every model, leading to huge computation and memory overheads. In this paper, we propose a novel setting where we aim to improve the performance of diverse MLLMs with a group of shared parameters optimized for a downstream task. To achieve this, we propose Transferable Visual Prompting (TVP), a simple and effective approach to generate visual prompts that can transfer to different models and improve their performance on downstream tasks after trained on only one model. We introduce two strategies to address the issue of cross-model feature corruption of existing visual prompting methods and enhance the transferability of the learned prompts, including 1) Feature Consistency Alignment: which imposes constraints to the prompted feature changes to maintain task-agnostic knowledge; 2) Task Semantics Enrichment: which encourages the prompted images to contain richer task-specific semantics with language guidance. We validate the effectiveness of TVP through extensive experiments with 6 modern MLLMs on a wide variety of tasks ranging from object recognition and counting to multimodal reasoning and hallucination correction.",2404.11207,http://arxiv.org/abs/2404.11207v1,2024-04-17 09:39:07+00:00,2024-04-17 09:39:07+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",0
Feature Corrective Transfer Learning: End-to-End Solutions to Object Detection in Non-Ideal Visual Conditions,"['Chuheng Wei', 'Guoyuan Wu', 'Matthew J. Barth']","A significant challenge in the field of object detection lies in the system's performance under non-ideal imaging conditions, such as rain, fog, low illumination, or raw Bayer images that lack ISP processing. Our study introduces ""Feature Corrective Transfer Learning"", a novel approach that leverages transfer learning and a bespoke loss function to facilitate the end-to-end detection of objects in these challenging scenarios without the need to convert non-ideal images into their RGB counterparts. In our methodology, we initially train a comprehensive model on a pristine RGB image dataset. Subsequently, non-ideal images are processed by comparing their feature maps against those from the initial ideal RGB model. This comparison employs the Extended Area Novel Structural Discrepancy Loss (EANSDL), a novel loss function designed to quantify similarities and integrate them into the detection loss. This approach refines the model's ability to perform object detection across varying conditions through direct feature map correction, encapsulating the essence of Feature Corrective Transfer Learning. Experimental validation on variants of the KITTI dataset demonstrates a significant improvement in mean Average Precision (mAP), resulting in a 3.8-8.1% relative enhancement in detection under non-ideal conditions compared to the baseline model, and a less marginal performance difference within 1.3% of the mAP@[0.5:0.95] achieved under ideal conditions by the standard Faster RCNN algorithm.",2404.11214,http://arxiv.org/abs/2404.11214v1,2024-04-17 09:58:53+00:00,2024-04-17 09:58:53+00:00,cs.CV,"['cs.CV', 'cs.AI']",2
In-Context Learning State Vector with Inner and Momentum Optimization,"['Dongfang Li', 'Zhenyu Liu', 'Xinshuo Hu', 'Zetian Sun', 'Baotian Hu', 'Min Zhang']","Large Language Models (LLMs) have exhibited an impressive ability to perform In-Context Learning (ICL) from only a few examples. Recent works have indicated that the functions learned by ICL can be represented through compressed vectors derived from the transformer. However, the working mechanisms and optimization of these vectors are yet to be thoroughly explored. In this paper, we address this gap by presenting a comprehensive analysis of these compressed vectors, drawing parallels to the parameters trained with gradient descent, and introduce the concept of state vector. Inspired by the works on model soup and momentum-based gradient descent, we propose inner and momentum optimization methods that are applied to refine the state vector progressively as test-time adaptation. Moreover, we simulate state vector aggregation in the multiple example setting, where demonstrations comprising numerous examples are usually too lengthy for regular ICL, and further propose a divide-and-conquer aggregation method to address this challenge. We conduct extensive experiments using Llama-2 and GPT-J in both zero-shot setting and few-shot setting. The experimental results show that our optimization method effectively enhances the state vector and achieves the state-of-the-art performance on diverse tasks. Code is available at https://github.com/HITsz-TMG/ICL-State-Vector",2404.11225,http://arxiv.org/abs/2404.11225v1,2024-04-17 10:19:15+00:00,2024-04-17 10:19:15+00:00,cs.CL,"['cs.CL', 'cs.AI']",17
Energy-Efficient Uncertainty-Aware Biomass Composition Prediction at the Edge,"['Muhammad Zawish', 'Paul Albert', 'Flavio Esposito', 'Steven Davy', 'Lizy Abraham']","Clover fixates nitrogen from the atmosphere to the ground, making grass-clover mixtures highly desirable to reduce external nitrogen fertilization. Herbage containing clover additionally promotes higher food intake, resulting in higher milk production. Herbage probing however remains largely unused as it requires a time-intensive manual laboratory analysis. Without this information, farmers are unable to perform localized clover sowing or take targeted fertilization decisions. Deep learning algorithms have been proposed with the goal to estimate the dry biomass composition from images of the grass directly in the fields. The energy-intensive nature of deep learning however limits deployment to practical edge devices such as smartphones. This paper proposes to fill this gap by applying filter pruning to reduce the energy requirement of existing deep learning solutions. We report that although pruned networks are accurate on controlled, high-quality images of the grass, they struggle to generalize to real-world smartphone images that are blurry or taken from challenging angles. We address this challenge by training filter-pruned models using a variance attenuation loss so they can predict the uncertainty of their predictions. When the uncertainty exceeds a threshold, we re-infer using a more accurate unpruned model. This hybrid approach allows us to reduce energy consumption while retaining a high accuracy. We evaluate our algorithm on two datasets: the GrassClover and the Irish clover using an NVIDIA Jetson Nano edge device. We find that we reduce energy reduction with respect to state-of-the-art solutions by 50% on average with only 4% accuracy loss.",2404.1123,http://arxiv.org/abs/2404.11230v1,2024-04-17 10:26:49+00:00,2024-04-17 10:26:49+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
DACAD: Domain Adaptation Contrastive Learning for Anomaly Detection in Multivariate Time Series,"['Zahra Zamanzadeh Darban', 'Geoffrey I. Webb', 'Mahsa Salehi']","Time series anomaly detection (TAD) faces a significant challenge due to the scarcity of labelled data, which hinders the development of accurate detection models. Unsupervised domain adaptation (UDA) addresses this challenge by leveraging a labelled dataset from a related domain to detect anomalies in a target dataset. Existing domain adaptation techniques assume that the number of anomalous classes does not change between the source and target domains. In this paper, we propose a novel Domain Adaptation Contrastive learning for Anomaly Detection in multivariate time series (DACAD) model to address this issue by combining UDA and contrastive representation learning. DACAD's approach includes an anomaly injection mechanism that introduces various types of synthetic anomalies, enhancing the model's ability to generalise across unseen anomalous classes in different domains. This method significantly broadens the model's adaptability and robustness. Additionally, we propose a supervised contrastive loss for the source domain and a self-supervised contrastive triplet loss for the target domain, improving comprehensive feature representation learning and extraction of domain-invariant features. Finally, an effective Centre-based Entropy Classifier (CEC) is proposed specifically for anomaly detection, facilitating accurate learning of normal boundaries in the source domain. Our extensive evaluation across multiple real-world datasets against leading models in time series anomaly detection and UDA underscores DACAD's effectiveness. The results validate DACAD's superiority in transferring knowledge across domains and its potential to mitigate the challenge of limited labelled data in time series anomaly detection.",2404.11269,http://arxiv.org/abs/2404.11269v1,2024-04-17 11:20:14+00:00,2024-04-17 11:20:14+00:00,cs.LG,"['cs.LG', 'cs.AI']",0
Improving Composed Image Retrieval via Contrastive Learning with Scaling Positives and Negatives,"['Zhangchi Feng', 'Richong Zhang', 'Zhijie Nie']","The Composed Image Retrieval (CIR) task aims to retrieve target images using a composed query consisting of a reference image and a modified text. Advanced methods often utilize contrastive learning as the optimization objective, which benefits from adequate positive and negative examples. However, the triplet for CIR incurs high manual annotation costs, resulting in limited positive examples. Furthermore, existing methods commonly use in-batch negative sampling, which reduces the negative number available for the model. To address the problem of lack of positives, we propose a data generation method by leveraging a multi-modal large language model to construct triplets for CIR. To introduce more negatives during fine-tuning, we design a two-stage fine-tuning framework for CIR, whose second stage introduces plenty of static representations of negatives to optimize the representation space rapidly. The above two improvements can be effectively stacked and designed to be plug-and-play, easily applied to existing CIR models without changing their original architectures. Extensive experiments and ablation analysis demonstrate that our method effectively scales positives and negatives and achieves state-of-the-art results on both FashionIQ and CIRR datasets. In addition, our methods also perform well in zero-shot composed image retrieval, providing a new CIR solution for the low-resources scenario.",2404.11317,http://arxiv.org/abs/2404.11317v1,2024-04-17 12:30:54+00:00,2024-04-17 12:30:54+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
"Calibrating Bayesian Learning via Regularization, Confidence Minimization, and Selective Inference","['Jiayi Huang', 'Sangwoo Park', 'Osvaldo Simeone']","The application of artificial intelligence (AI) models in fields such as engineering is limited by the known difficulty of quantifying the reliability of an AI's decision. A well-calibrated AI model must correctly report its accuracy on in-distribution (ID) inputs, while also enabling the detection of out-of-distribution (OOD) inputs. A conventional approach to improve calibration is the application of Bayesian ensembling. However, owing to computational limitations and model misspecification, practical ensembling strategies do not necessarily enhance calibration. This paper proposes an extension of variational inference (VI)-based Bayesian learning that integrates calibration regularization for improved ID performance, confidence minimization for OOD detection, and selective calibration to ensure a synergistic use of calibration regularization and confidence minimization. The scheme is constructed successively by first introducing calibration-regularized Bayesian learning (CBNN), then incorporating out-of-distribution confidence minimization (OCM) to yield CBNN-OCM, and finally integrating also selective calibration to produce selective CBNN-OCM (SCBNN-OCM). Selective calibration rejects inputs for which the calibration performance is expected to be insufficient. Numerical results illustrate the trade-offs between ID accuracy, ID calibration, and OOD calibration attained by both frequentist and Bayesian learning methods. Among the main conclusions, SCBNN-OCM is seen to achieve best ID and OOD performance as compared to existing state-of-the-art approaches at the cost of rejecting a sufficiently large number of inputs.",2404.1135,http://arxiv.org/abs/2404.11350v1,2024-04-17 13:08:26+00:00,2024-04-17 13:08:26+00:00,cs.LG,"['cs.LG', 'cs.AI', 'eess.SP']",0
Using Game Engines and Machine Learning to Create Synthetic Satellite Imagery for a Tabletop Verification Exercise,"['Johannes Hoster', 'Sara Al-Sayed', 'Felix Biessmann', 'Alexander Glaser', 'Kristian Hildebrand', 'Igor Moric', 'Tuong Vy Nguyen']","Satellite imagery is regarded as a great opportunity for citizen-based monitoring of activities of interest. Relevant imagery may however not be available at sufficiently high resolution, quality, or cadence -- let alone be uniformly accessible to open-source analysts. This limits an assessment of the true long-term potential of citizen-based monitoring of nuclear activities using publicly available satellite imagery. In this article, we demonstrate how modern game engines combined with advanced machine-learning techniques can be used to generate synthetic imagery of sites of interest with the ability to choose relevant parameters upon request; these include time of day, cloud cover, season, or level of activity onsite. At the same time, resolution and off-nadir angle can be adjusted to simulate different characteristics of the satellite. While there are several possible use-cases for synthetic imagery, here we focus on its usefulness to support tabletop exercises in which simple monitoring scenarios can be examined to better understand verification capabilities enabled by new satellite constellations and very short revisit times.",2404.11461,http://arxiv.org/abs/2404.11461v1,2024-04-17 15:09:31+00:00,2024-04-17 15:09:31+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.HC', 'cs.LG']",24
AdaIR: Exploiting Underlying Similarities of Image Restoration Tasks with Adapters,"['Hao-Wei Chen', 'Yu-Syuan Xu', 'Kelvin C. K. Chan', 'Hsien-Kai Kuo', 'Chun-Yi Lee', 'Ming-Hsuan Yang']","Existing image restoration approaches typically employ extensive networks specifically trained for designated degradations. Despite being effective, such methods inevitably entail considerable storage costs and computational overheads due to the reliance on task-specific networks. In this work, we go beyond this well-established framework and exploit the inherent commonalities among image restoration tasks. The primary objective is to identify components that are shareable across restoration tasks and augment the shared components with modules specifically trained for individual tasks. Towards this goal, we propose AdaIR, a novel framework that enables low storage cost and efficient training without sacrificing performance. Specifically, a generic restoration network is first constructed through self-supervised pre-training using synthetic degradations. Subsequent to the pre-training phase, adapters are trained to adapt the pre-trained network to specific degradations. AdaIR requires solely the training of lightweight, task-specific modules, ensuring a more efficient storage and training regimen. We have conducted extensive experiments to validate the effectiveness of AdaIR and analyze the influence of the pre-training strategy on discovering shareable components. Extensive experimental results show that AdaIR achieves outstanding results on multi-task restoration while utilizing significantly fewer parameters (1.9 MB) and less training time (7 hours) for each restoration task. The source codes and trained models will be released.",2404.11475,http://arxiv.org/abs/2404.11475v1,2024-04-17 15:31:06+00:00,2024-04-17 15:31:06+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
"Runtime Analysis of Evolutionary Diversity Optimization on the Multi-objective (LeadingOnes, TrailingZeros) Problem","['Denis Antipov', 'Aneta Neumann', 'Frank Neumann. Andrew M. Sutton']","The diversity optimization is the class of optimization problems, in which we aim at finding a diverse set of good solutions. One of the frequently used approaches to solve such problems is to use evolutionary algorithms which evolve a desired diverse population. This approach is called evolutionary diversity optimization (EDO).   In this paper, we analyse EDO on a 3-objective function LOTZ$_k$, which is a modification of the 2-objective benchmark function (LeadingOnes, TrailingZeros). We prove that the GSEMO computes a set of all Pareto-optimal solutions in $O(kn^3)$ expected iterations. We also analyze the runtime of the GSEMO$_D$ (a modification of the GSEMO for diversity optimization) until it finds a population with the best possible diversity for two different diversity measures, the total imbalance and the sorted imbalances vector. For the first measure we show that the GSEMO$_D$ optimizes it asymptotically faster than it finds a Pareto-optimal population, in $O(kn^2\log(n))$ expected iterations, and for the second measure we show an upper bound of $O(k^2n^3\log(n))$ expected iterations. We complement our theoretical analysis with an empirical study, which shows a very similar behavior for both diversity measures that is close to the theory predictions.",2404.11496,http://arxiv.org/abs/2404.11496v1,2024-04-17 15:51:15+00:00,2024-04-17 15:51:15+00:00,cs.NE,"['cs.NE', 'cs.AI']",15
A Data-Driven Representation for Sign Language Production,"['Harry Walsh', 'Abolfazl Ravanshad', 'Mariam Rahmani', 'Richard Bowden']","Phonetic representations are used when recording spoken languages, but no equivalent exists for recording signed languages. As a result, linguists have proposed several annotation systems that operate on the gloss or sub-unit level; however, these resources are notably irregular and scarce.   Sign Language Production (SLP) aims to automatically translate spoken language sentences into continuous sequences of sign language. However, current state-of-the-art approaches rely on scarce linguistic resources to work. This has limited progress in the field. This paper introduces an innovative solution by transforming the continuous pose generation problem into a discrete sequence generation problem. Thus, overcoming the need for costly annotation. Although, if available, we leverage the additional information to enhance our approach.   By applying Vector Quantisation (VQ) to sign language data, we first learn a codebook of short motions that can be combined to create a natural sequence of sign. Where each token in the codebook can be thought of as the lexicon of our representation. Then using a transformer we perform a translation from spoken language text to a sequence of codebook tokens. Each token can be directly mapped to a sequence of poses allowing the translation to be performed by a single network. Furthermore, we present a sign stitching method to effectively join tokens together. We evaluate on the RWTH-PHOENIX-Weather-2014T (PHOENIX14T) and the more challenging Meine DGS Annotated (mDGS) datasets. An extensive evaluation shows our approach outperforms previous methods, increasing the BLEU-1 back translation score by up to 72%.",2404.11499,http://arxiv.org/abs/2404.11499v1,2024-04-17 15:52:38+00:00,2024-04-17 15:52:38+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
Prompt Optimizer of Text-to-Image Diffusion Models for Abstract Concept Understanding,"['Zezhong Fan', 'Xiaohan Li', 'Chenhao Fang', 'Topojoy Biswas', 'Kaushiki Nag', 'Jianpeng Xu', 'Kannan Achan']","The rapid evolution of text-to-image diffusion models has opened the door of generative AI, enabling the translation of textual descriptions into visually compelling images with remarkable quality. However, a persistent challenge within this domain is the optimization of prompts to effectively convey abstract concepts into concrete objects. For example, text encoders can hardly express ""peace"", while can easily illustrate olive branches and white doves. This paper introduces a novel approach named Prompt Optimizer for Abstract Concepts (POAC) specifically designed to enhance the performance of text-to-image diffusion models in interpreting and generating images from abstract concepts. We propose a Prompt Language Model (PLM), which is initialized from a pre-trained language model, and then fine-tuned with a curated dataset of abstract concept prompts. The dataset is created with GPT-4 to extend the abstract concept to a scene and concrete objects. Our framework employs a Reinforcement Learning (RL)-based optimization strategy, focusing on the alignment between the generated images by a stable diffusion model and optimized prompts. Through extensive experiments, we demonstrate that our proposed POAC significantly improves the accuracy and aesthetic quality of generated images, particularly in the description of abstract concepts and alignment with optimized prompts. We also present a comprehensive analysis of our model's performance across diffusion models under different settings, showcasing its versatility and effectiveness in enhancing abstract concept representation.",2404.11589,http://arxiv.org/abs/2404.11589v1,2024-04-17 17:38:56+00:00,2024-04-17 17:38:56+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",1
VG4D: Vision-Language Model Goes 4D Video Recognition,"['Zhichao Deng', 'Xiangtai Li', 'Xia Li', 'Yunhai Tong', 'Shen Zhao', 'Mengyuan Liu']","Understanding the real world through point cloud video is a crucial aspect of robotics and autonomous driving systems. However, prevailing methods for 4D point cloud recognition have limitations due to sensor resolution, which leads to a lack of detailed information. Recent advances have shown that Vision-Language Models (VLM) pre-trained on web-scale text-image datasets can learn fine-grained visual concepts that can be transferred to various downstream tasks. However, effectively integrating VLM into the domain of 4D point clouds remains an unresolved problem. In this work, we propose the Vision-Language Models Goes 4D (VG4D) framework to transfer VLM knowledge from visual-text pre-trained models to a 4D point cloud network. Our approach involves aligning the 4D encoder's representation with a VLM to learn a shared visual and text space from training on large-scale image-text pairs. By transferring the knowledge of the VLM to the 4D encoder and combining the VLM, our VG4D achieves improved recognition performance. To enhance the 4D encoder, we modernize the classic dynamic point cloud backbone and propose an improved version of PSTNet, im-PSTNet, which can efficiently model point cloud videos. Experiments demonstrate that our method achieves state-of-the-art performance for action recognition on both the NTU RGB+D 60 dataset and the NTU RGB+D 120 dataset. Code is available at \url{https://github.com/Shark0-0/VG4D}.",2404.11605,http://arxiv.org/abs/2404.11605v1,2024-04-17 17:54:49+00:00,2024-04-17 17:54:49+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.RO']",0
SNP: Structured Neuron-level Pruning to Preserve Attention Scores,"['Kyunghwan Shim', 'Jaewoong Yun', 'Shinkook Choi']","Multi-head self-attention (MSA) is a key component of Vision Transformers (ViTs), which have achieved great success in various vision tasks. However, their high computational cost and memory footprint hinder their deployment on resource-constrained devices. Conventional pruning approaches can only compress and accelerate the MSA module using head pruning, although the head is not an atomic unit. To address this issue, we propose a novel graph-aware neuron-level pruning method, Structured Neuron-level Pruning (SNP). SNP prunes neurons with less informative attention scores and eliminates redundancy among heads. Specifically, it prunes graphically connected query and key layers having the least informative attention scores while preserving the overall attention scores. Value layers, which can be pruned independently, are pruned to eliminate inter-head redundancy. Our proposed method effectively compresses and accelerates Transformer-based models for both edge devices and server processors. For instance, the DeiT-Small with SNP runs 3.1$\times$ faster than the original model and achieves performance that is 21.94\% faster and 1.12\% higher than the DeiT-Tiny. Additionally, SNP combine successfully with conventional head or block pruning approaches. SNP with head pruning could compress the DeiT-Base by 80\% of the parameters and computational costs and achieve 3.85$\times$ faster inference speed on RTX3090 and 4.93$\times$ on Jetson Nano.",2404.1163,http://arxiv.org/abs/2404.11630v1,2024-04-18 03:21:28+00:00,2024-04-18 03:21:28+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
Event-Based Eye Tracking. AIS 2024 Challenge Survey,"['Zuowen Wang', 'Chang Gao', 'Zongwei Wu', 'Marcos V. Conde', 'Radu Timofte', 'Shih-Chii Liu', 'Qinyu Chen', 'Zheng-jun Zha', 'Wei Zhai', 'Han Han', 'Bohao Liao', 'Yuliang Wu', 'Zengyu Wan', 'Zhong Wang', 'Yang Cao', 'Ganchao Tan', 'Jinze Chen', 'Yan Ru Pei', 'Sasskia Brüers', 'Sébastien Crouzet', 'Douglas McLelland', 'Oliver Coenen', 'Baoheng Zhang', 'Yizhao Gao', 'Jingyuan Li', 'Hayden Kwok-Hay So', 'Philippe Bich', 'Chiara Boretti', 'Luciano Prono', 'Mircea Lică', 'David Dinucu-Jianu', 'Cătălin Grîu', 'Xiaopeng Lin', 'Hongwei Ren', 'Bojun Cheng', 'Xinan Zhang', 'Valentin Vial', 'Anthony Yezzi', 'James Tsai']","This survey reviews the AIS 2024 Event-Based Eye Tracking (EET) Challenge. The task of the challenge focuses on processing eye movement recorded with event cameras and predicting the pupil center of the eye. The challenge emphasizes efficient eye tracking with event cameras to achieve good task accuracy and efficiency trade-off. During the challenge period, 38 participants registered for the Kaggle competition, and 8 teams submitted a challenge factsheet. The novel and diverse methods from the submitted factsheets are reviewed and analyzed in this survey to advance future event-based eye tracking research.",2404.1177,http://arxiv.org/abs/2404.11770v1,2024-04-17 21:53:01+00:00,2024-04-17 21:53:01+00:00,cs.CV,"['cs.CV', 'cs.AI']",24
REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models,"['Sana Ebrahimi', 'Nima Shahbazi', 'Abolfazl Asudeh']","The extensive scope of large language models (LLMs) across various domains underscores the critical importance of responsibility in their application, beyond natural language processing. In particular, the randomized nature of LLMs, coupled with inherent biases and historical stereotypes in data, raises critical concerns regarding reliability and equity. Addressing these challenges are necessary before using LLMs for applications with societal impact. Towards addressing this gap, we introduce REQUAL-LM, a novel method for finding reliable and equitable LLM outputs through aggregation. Specifically, we develop a Monte Carlo method based on repeated sampling to find a reliable output close to the mean of the underlying distribution of possible outputs. We formally define the terms such as reliability and bias, and design an equity-aware aggregation to minimize harmful bias while finding a highly reliable output. REQUAL-LM does not require specialized hardware, does not impose a significant computing load, and uses LLMs as a blackbox. This design choice enables seamless scalability alongside the rapid advancement of LLM technologies. Our system does not require retraining the LLMs, which makes it deployment ready and easy to adapt. Our comprehensive experiments using various tasks and datasets demonstrate that REQUAL- LM effectively mitigates bias and selects a more equitable response, specifically the outputs that properly represents minority groups.",2404.11782,http://arxiv.org/abs/2404.11782v1,2024-04-17 22:12:41+00:00,2024-04-17 22:12:41+00:00,cs.CL,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.LG']",1
TempBEV: Improving Learned BEV Encoders with Combined Image and BEV Space Temporal Aggregation,"['Thomas Monninger', 'Vandana Dokkadi', 'Md Zafar Anwar', 'Steffen Staab']","Autonomous driving requires an accurate representation of the environment. A strategy toward high accuracy is to fuse data from several sensors. Learned Bird's-Eye View (BEV) encoders can achieve this by mapping data from individual sensors into one joint latent space. For cost-efficient camera-only systems, this provides an effective mechanism to fuse data from multiple cameras with different views. Accuracy can further be improved by aggregating sensor information over time. This is especially important in monocular camera systems to account for the lack of explicit depth and velocity measurements. Thereby, the effectiveness of developed BEV encoders crucially depends on the operators used to aggregate temporal information and on the used latent representation spaces. We analyze BEV encoders proposed in the literature and compare their effectiveness, quantifying the effects of aggregation operators and latent representations. While most existing approaches aggregate temporal information either in image or in BEV latent space, our analyses and performance comparisons suggest that these latent representations exhibit complementary strengths. Therefore, we develop a novel temporal BEV encoder, TempBEV, which integrates aggregated temporal information from both latent spaces. We consider subsequent image frames as stereo through time and leverage methods from optical flow estimation for temporal stereo encoding. Empirical evaluation on the NuScenes dataset shows a significant improvement by TempBEV over the baseline for 3D object detection and BEV segmentation. The ablation uncovers a strong synergy of joint temporal aggregation in the image and BEV latent space. These results indicate the overall effectiveness of our approach and make a strong case for aggregating temporal information in both image and BEV latent spaces.",2404.11803,http://arxiv.org/abs/2404.11803v1,2024-04-17 23:49:00+00:00,2024-04-17 23:49:00+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO']",0
Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation,"['Qing En', 'Yuhong Guo']","Medical image segmentation typically demands extensive dense annotations for model training, which is both time-consuming and skill-intensive. To mitigate this burden, exemplar-based medical image segmentation methods have been introduced to achieve effective training with only one annotated image. In this paper, we introduce a novel Cross-model Mutual learning framework for Exemplar-based Medical image Segmentation (CMEMS), which leverages two models to mutually excavate implicit information from unlabeled data at multiple granularities. CMEMS can eliminate confirmation bias and enable collaborative training to learn complementary information by enforcing consistency at different granularities across models. Concretely, cross-model image perturbation based mutual learning is devised by using weakly perturbed images to generate high-confidence pseudo-labels, supervising predictions of strongly perturbed images across models. This approach enables joint pursuit of prediction consistency at the image granularity. Moreover, cross-model multi-level feature perturbation based mutual learning is designed by letting pseudo-labels supervise predictions from perturbed multi-level features with different resolutions, which can broaden the perturbation space and enhance the robustness of our framework. CMEMS is jointly trained using exemplar data, synthetic data, and unlabeled data in an end-to-end manner. Experimental results on two medical image datasets indicate that the proposed CMEMS outperforms the state-of-the-art segmentation methods with extremely limited supervision.",2404.11812,http://arxiv.org/abs/2404.11812v1,2024-04-18 00:18:07+00:00,2024-04-18 00:18:07+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
The Dog Walking Theory: Rethinking Convergence in Federated Learning,"['Kun Zhai', 'Yifeng Gao', 'Xingjun Ma', 'Difan Zou', 'Guangnan Ye', 'Yu-Gang Jiang']","Federated learning (FL) is a collaborative learning paradigm that allows different clients to train one powerful global model without sharing their private data. Although FL has demonstrated promising results in various applications, it is known to suffer from convergence issues caused by the data distribution shift across different clients, especially on non-independent and identically distributed (non-IID) data. In this paper, we study the convergence of FL on non-IID data and propose a novel \emph{Dog Walking Theory} to formulate and identify the missing element in existing research. The Dog Walking Theory describes the process of a dog walker leash walking multiple dogs from one side of the park to the other. The goal of the dog walker is to arrive at the right destination while giving the dogs enough exercise (i.e., space exploration). In FL, the server is analogous to the dog walker while the clients are analogous to the dogs. This analogy allows us to identify one crucial yet missing element in existing FL algorithms: the leash that guides the exploration of the clients. To address this gap, we propose a novel FL algorithm \emph{FedWalk} that leverages an external easy-to-converge task at the server side as a \emph{leash task} to guide the local training of the clients. We theoretically analyze the convergence of FedWalk with respect to data heterogeneity (between server and clients) and task discrepancy (between the leash and the original tasks). Experiments on multiple benchmark datasets demonstrate the superiority of FedWalk over state-of-the-art FL methods under both IID and non-IID settings.",2404.11888,http://arxiv.org/abs/2404.11888v1,2024-04-18 04:25:21+00:00,2024-04-18 04:25:21+00:00,cs.LG,"['cs.LG', 'cs.AI']",13
A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease,"['Walid Abdullah Al', 'Il Dong Yun', 'Yun Jung Bae']","Dopamine transporter (DAT) imaging is commonly used for monitoring Parkinson's disease (PD), where striatal DAT uptake amount is computed to assess PD severity. However, DAT imaging has a high cost and the risk of radiance exposure and is not available in general clinics. Recently, MRI patch of the nigral region has been proposed as a safer and easier alternative. This paper proposes a symmetric regressor for predicting the DAT uptake amount from the nigral MRI patch. Acknowledging the symmetry between the right and left nigrae, the proposed regressor incorporates a paired input-output model that simultaneously predicts the DAT uptake amounts for both the right and left striata. Moreover, it employs a symmetric loss that imposes a constraint on the difference between right-to-left predictions, resembling the high correlation in DAT uptake amounts in the two lateral sides. Additionally, we propose a symmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty estimate of the DAT uptake prediction, which utilizes the above symmetry. We evaluated the proposed approach on 734 nigral patches, which demonstrated significantly improved performance of the symmetric regressor compared with the standard regressors while giving better explainability and feature representation. The symmetric MC dropout also gave precise uncertainty ranges with a high probability of including the true DAT uptake amounts within the range.",2404.11929,http://arxiv.org/abs/2404.11929v1,2024-04-18 06:18:48+00:00,2024-04-18 06:18:48+00:00,eess.IV,"['eess.IV', 'cs.AI', 'cs.CV']",0
LD-Pruner: Efficient Pruning of Latent Diffusion Models using Task-Agnostic Insights,"['Thibault Castells', 'Hyoung-Kyu Song', 'Bo-Kyeong Kim', 'Shinkook Choi']","Latent Diffusion Models (LDMs) have emerged as powerful generative models, known for delivering remarkable results under constrained computational resources. However, deploying LDMs on resource-limited devices remains a complex issue, presenting challenges such as memory consumption and inference speed. To address this issue, we introduce LD-Pruner, a novel performance-preserving structured pruning method for compressing LDMs. Traditional pruning methods for deep neural networks are not tailored to the unique characteristics of LDMs, such as the high computational cost of training and the absence of a fast, straightforward and task-agnostic method for evaluating model performance. Our method tackles these challenges by leveraging the latent space during the pruning process, enabling us to effectively quantify the impact of pruning on model performance, independently of the task at hand. This targeted pruning of components with minimal impact on the output allows for faster convergence during training, as the model has less information to re-learn, thereby addressing the high computational cost of training. Consequently, our approach achieves a compressed model that offers improved inference speed and reduced parameter count, while maintaining minimal performance degradation. We demonstrate the effectiveness of our approach on three different tasks: text-to-image (T2I) generation, Unconditional Image Generation (UIG) and Unconditional Audio Generation (UAG). Notably, we reduce the inference time of Stable Diffusion (SD) by 34.9% while simultaneously improving its FID by 5.2% on MS-COCO T2I benchmark. This work paves the way for more efficient pruning methods for LDMs, enhancing their applicability.",2404.11936,http://arxiv.org/abs/2404.11936v1,2024-04-18 06:35:37+00:00,2024-04-18 06:35:37+00:00,cs.LG,"['cs.LG', 'cs.AI', 'cs.CV']",0
Sketch-guided Image Inpainting with Partial Discrete Diffusion Process,"['Nakul Sharma', 'Aditay Tripathi', 'Anirban Chakraborty', 'Anand Mishra']","In this work, we study the task of sketch-guided image inpainting. Unlike the well-explored natural language-guided image inpainting, which excels in capturing semantic details, the relatively less-studied sketch-guided inpainting offers greater user control in specifying the object's shape and pose to be inpainted. As one of the early solutions to this task, we introduce a novel partial discrete diffusion process (PDDP). The forward pass of the PDDP corrupts the masked regions of the image and the backward pass reconstructs these masked regions conditioned on hand-drawn sketches using our proposed sketch-guided bi-directional transformer. The proposed novel transformer module accepts two inputs -- the image containing the masked region to be inpainted and the query sketch to model the reverse diffusion process. This strategy effectively addresses the domain gap between sketches and natural images, thereby, enhancing the quality of inpainting results. In the absence of a large-scale dataset specific to this task, we synthesize a dataset from the MS-COCO to train and extensively evaluate our proposed framework against various competent approaches in the literature. The qualitative and quantitative results and user studies establish that the proposed method inpaints realistic objects that fit the context in terms of the visual appearance of the provided sketch. To aid further research, we have made our code publicly available at https://github.com/vl2g/Sketch-Inpainting .",2404.11949,http://arxiv.org/abs/2404.11949v1,2024-04-18 07:07:38+00:00,2024-04-18 07:07:38+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",7
Token-level Direct Preference Optimization,"['Yongcheng Zeng', 'Guoqing Liu', 'Weiyu Ma', 'Ning Yang', 'Haifeng Zhang', 'Jun Wang']","Fine-tuning pre-trained Large Language Models (LLMs) is essential to align them with human values and intentions. This process often utilizes methods like pairwise comparisons and KL divergence against a reference LLM, focusing on the evaluation of full answers generated by the models. However, the generation of these responses occurs in a token level, following a sequential, auto-regressive fashion. In this paper, we introduce Token-level Direct Preference Optimization (TDPO), a novel approach to align LLMs with human preferences by optimizing policy at the token level. Unlike previous methods, which face challenges in divergence efficiency, TDPO incorporates forward KL divergence constraints for each token, improving alignment and diversity. Utilizing the Bradley-Terry model for a token-based reward system, TDPO enhances the regulation of KL divergence, while preserving simplicity without the need for explicit reward modeling. Experimental results across various text tasks demonstrate TDPO's superior performance in balancing alignment with generation diversity. Notably, fine-tuning with TDPO strikes a better balance than DPO in the controlled sentiment generation and single-turn dialogue datasets, and significantly improves the quality of generated responses compared to both DPO and PPO-based RLHF methods. Our code is open-sourced at https://github.com/Vance0124/Token-level-Direct-Preference-Optimization.",2404.11999,http://arxiv.org/abs/2404.11999v1,2024-04-18 08:49:38+00:00,2024-04-18 08:49:38+00:00,cs.CL,"['cs.CL', 'cs.AI']",0
Context-Aware Orchestration of Energy-Efficient Gossip Learning Schemes,"['Mina Aghaei Dinani', 'Adrian Holzer', 'Hung Nguyen', 'Marco Ajmone Marsan', 'Gianluca Rizzo']","Fully distributed learning schemes such as Gossip Learning (GL) are gaining momentum due to their scalability and effectiveness even in dynamic settings. However, they often imply a high utilization of communication and computing resources, whose energy footprint may jeopardize the learning process, particularly on battery-operated IoT devices. To address this issue, we present Optimized Gossip Learning (OGL)}, a distributed training approach based on the combination of GL with adaptive optimization of the learning process, which allows for achieving a target accuracy while minimizing the energy consumption of the learning process. We propose a data-driven approach to OGL management that relies on optimizing in real-time for each node the number of training epochs and the choice of which model to exchange with neighbors based on patterns of node contacts, models' quality, and available resources at each node. Our approach employs a DNN model for dynamic tuning of the aforementioned parameters, trained by an infrastructure-based orchestrator function. We performed our assessments on two different datasets, leveraging time-varying random graphs and a measurement-based dynamic urban scenario. Results suggest that our approach is highly efficient and effective in a broad spectrum of network scenarios.",2404.12023,http://arxiv.org/abs/2404.12023v1,2024-04-18 09:17:46+00:00,2024-04-18 09:17:46+00:00,cs.NI,"['cs.NI', 'cs.AI', 'cs.DC']",0
Intelligence Education made in Europe,"['Lars Berger', 'Uwe M. Borghoff', 'Gerhard Conrad', 'Stefan Pickl']","Global conflicts and trouble spots have thrown the world into turmoil. Intelligence services have never been as necessary as they are today when it comes to providing political decision-makers with concrete, accurate, and up-to-date decision-making knowledge. This requires a common co-operation, a common working language and a common understanding of each other. The best way to create this ""intelligence community"" is through a harmonized intelligence education.   In this paper, we show how joint intelligence education can succeed. We draw on the experience of Germany, where all intelligence services and the Bundeswehr are academically educated together in a single degree program that lays the foundations for a common working language. We also show how these experiences have been successfully transferred to a European level, namely to ICE, the Intelligence College in Europe. Our experience has shown that three aspects are particularly important: firstly, interdisciplinarity or better, transdisciplinarity, secondly, the integration of IT knowhow and thirdly, the development and learning of methodological skills. Using the example of the cyber intelligence module with a special focus on data-driven decision support, additionally with its many points of reference to numerous other academic modules, we show how the specific analytic methodology presented is embedded in our specific European teaching context.",2404.12125,http://arxiv.org/abs/2404.12125v1,2024-04-18 12:25:46+00:00,2024-04-18 12:25:46+00:00,cs.CY,"['cs.CY', 'cs.AI', 'cs.CR']",0
From Form(s) to Meaning: Probing the Semantic Depths of Language Models Using Multisense Consistency,"['Xenia Ohmer', 'Elia Bruni', 'Dieuwke Hupkes']","The staggering pace with which the capabilities of large language models (LLMs) are increasing, as measured by a range of commonly used natural language understanding (NLU) benchmarks, raises many questions regarding what ""understanding"" means for a language model and how it compares to human understanding. This is especially true since many LLMs are exclusively trained on text, casting doubt on whether their stellar benchmark performances are reflective of a true understanding of the problems represented by these benchmarks, or whether LLMs simply excel at uttering textual forms that correlate with what someone who understands the problem would say. In this philosophically inspired work, we aim to create some separation between form and meaning, with a series of tests that leverage the idea that world understanding should be consistent across presentational modes - inspired by Fregean senses - of the same meaning. Specifically, we focus on consistency across languages as well as paraphrases. Taking GPT-3.5 as our object of study, we evaluate multisense consistency across five different languages and various tasks. We start the evaluation in a controlled setting, asking the model for simple facts, and then proceed with an evaluation on four popular NLU benchmarks. We find that the model's multisense consistency is lacking and run several follow-up analyses to verify that this lack of consistency is due to a sense-dependent task understanding. We conclude that, in this aspect, the understanding of LLMs is still quite far from being consistent and human-like, and deliberate on how this impacts their utility in the context of learning about human language and understanding.",2404.12145,http://arxiv.org/abs/2404.12145v1,2024-04-18 12:48:17+00:00,2024-04-18 12:48:17+00:00,cs.CL,"['cs.CL', 'cs.AI']",3
How to Benchmark Vision Foundation Models for Semantic Segmentation?,"['Tommie Kerssies', 'Daan de Geus', 'Gijs Dubbelman']","Recent vision foundation models (VFMs) have demonstrated proficiency in various tasks but require supervised fine-tuning to perform the task of semantic segmentation effectively. Benchmarking their performance is essential for selecting current models and guiding future model developments for this task. The lack of a standardized benchmark complicates comparisons. Therefore, the primary objective of this paper is to study how VFMs should be benchmarked for semantic segmentation. To do so, various VFMs are fine-tuned under various settings, and the impact of individual settings on the performance ranking and training time is assessed. Based on the results, the recommendation is to fine-tune the ViT-B variants of VFMs with a 16x16 patch size and a linear decoder, as these settings are representative of using a larger model, more advanced decoder and smaller patch size, while reducing training time by more than 13 times. Using multiple datasets for training and evaluation is also recommended, as the performance ranking across datasets and domain shifts varies. Linear probing, a common practice for some VFMs, is not recommended, as it is not representative of end-to-end fine-tuning. The benchmarking setup recommended in this paper enables a performance analysis of VFMs for semantic segmentation. The findings of such an analysis reveal that pretraining with promptable segmentation is not beneficial, whereas masked image modeling (MIM) with abstract representations is crucial, even more important than the type of supervision used. The code for efficiently fine-tuning VFMs for semantic segmentation can be accessed through the project page at: https://tue-mps.github.io/benchmark-vfm-ss/.",2404.12172,http://arxiv.org/abs/2404.12172v1,2024-04-18 13:27:29+00:00,2024-04-18 13:27:29+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO']",0
An Online Spatial-Temporal Graph Trajectory Planner for Autonomous Vehicles,"['Jilan Samiuddin', 'Benoit Boulet', 'Di Wu']","The autonomous driving industry is expected to grow by over 20 times in the coming decade and, thus, motivate researchers to delve into it. The primary focus of their research is to ensure safety, comfort, and efficiency. An autonomous vehicle has several modules responsible for one or more of the aforementioned items. Among these modules, the trajectory planner plays a pivotal role in the safety of the vehicle and the comfort of its passengers. The module is also responsible for respecting kinematic constraints and any applicable road constraints. In this paper, a novel online spatial-temporal graph trajectory planner is introduced to generate safe and comfortable trajectories. First, a spatial-temporal graph is constructed using the autonomous vehicle, its surrounding vehicles, and virtual nodes along the road with respect to the vehicle itself. Next, the graph is forwarded into a sequential network to obtain the desired states. To support the planner, a simple behavioral layer is also presented that determines kinematic constraints for the planner. Furthermore, a novel potential function is also proposed to train the network. Finally, the proposed planner is tested on three different complex driving tasks, and the performance is compared with two frequently used methods. The results show that the proposed planner generates safe and feasible trajectories while achieving similar or longer distances in the forward direction and comparable comfort ride.",2404.12256,http://arxiv.org/abs/2404.12256v1,2024-04-18 15:22:29+00:00,2024-04-18 15:22:29+00:00,cs.RO,"['cs.RO', 'cs.AI', 'cs.LG']",24
Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM,"['Michelle S. Lam', 'Janice Teoh', 'James Landay', 'Jeffrey Heer', 'Michael S. Bernstein']","Data analysts have long sought to turn unstructured text data into meaningful concepts. Though common, topic modeling and clustering focus on lower-level keywords and require significant interpretative work. We introduce concept induction, a computational process that instead produces high-level concepts, defined by explicit inclusion criteria, from unstructured text. For a dataset of toxic online comments, where a state-of-the-art BERTopic model outputs ""women, power, female,"" concept induction produces high-level concepts such as ""Criticism of traditional gender roles"" and ""Dismissal of women's concerns."" We present LLooM, a concept induction algorithm that leverages large language models to iteratively synthesize sampled text and propose human-interpretable concepts of increasing generality. We then instantiate LLooM in a mixed-initiative text analysis tool, enabling analysts to shift their attention from interpreting topics to engaging in theory-driven analysis. Through technical evaluations and four analysis scenarios ranging from literature review to content moderation, we find that LLooM's concepts improve upon the prior art of topic models in terms of quality and data coverage. In expert case studies, LLooM helped researchers to uncover new insights even from familiar datasets, for example by suggesting a previously unnoticed concept of attacks on out-party stances in a political social media dataset.",2404.12259,http://arxiv.org/abs/2404.12259v1,2024-04-18 15:26:02+00:00,2024-04-18 15:26:02+00:00,cs.HC,"['cs.HC', 'cs.AI']",0
Physics-integrated generative modeling using attentive planar normalizing flow based variational autoencoder,['Sheikh Waqas Akhtar'],"Physics-integrated generative modeling is a class of hybrid or grey-box modeling in which we augment the the data-driven model with the physics knowledge governing the data distribution. The use of physics knowledge allows the generative model to produce output in a controlled way, so that the output, by construction, complies with the physical laws. It imparts improved generalization ability to extrapolate beyond the training distribution as well as improved interpretability because the model is partly grounded in firm domain knowledge. In this work, we aim to improve the fidelity of reconstruction and robustness to noise in the physics integrated generative model. To this end, we use variational-autoencoder as a generative model. To improve the reconstruction results of the decoder, we propose to learn the latent posterior distribution of both the physics as well as the trainable data-driven components using planar normalizng flow. Normalizng flow based posterior distribution harnesses the inherent dynamical structure of the data distribution, hence the learned model gets closer to the true underlying data distribution. To improve the robustness of generative model against noise injected in the model, we propose a modification in the encoder part of the normalizing flow based VAE. We designed the encoder to incorporate scaled dot product attention based contextual information in the noisy latent vector which will mitigate the adverse effect of noise in the latent vector and make the model more robust. We empirically evaluated our models on human locomotion dataset [33] and the results validate the efficacy of our proposed models in terms of improvement in reconstruction quality as well as robustness against noise injected in the model.",2404.12267,http://arxiv.org/abs/2404.12267v1,2024-04-18 15:38:14+00:00,2024-04-18 15:38:14+00:00,cs.LG,"['cs.LG', 'cs.AI', 'stat.ML']",0
Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences,"['Shreya Shankar', 'J. D. Zamfirescu-Pereira', 'Björn Hartmann', 'Aditya G. Parameswaran', 'Ian Arawjo']","Due to the cumbersome nature of human evaluation and limitations of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply inherit all the problems of the LLMs they evaluate, requiring further human validation. We present a mixed-initiative approach to ``validate the validators'' -- aligning LLM-generated evaluation functions (be it prompts or code) with human requirements. Our interface, EvalGen, provides automated assistance to users in generating evaluation criteria and implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks humans to grade a subset of LLM outputs; this feedback is used to select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores the subjectivity and iterative process of alignment. In particular, we identify a phenomenon we dub \emph{criteria drift}: users need criteria to grade outputs, but grading outputs helps users define criteria. What is more, some criteria appears \emph{dependent} on the specific LLM outputs observed (rather than independent criteria that can be defined \emph{a priori}), raising serious questions for approaches that assume the independence of evaluation from observation of model outputs. We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.",2404.12272,http://arxiv.org/abs/2404.12272v1,2024-04-18 15:45:27+00:00,2024-04-18 15:45:27+00:00,cs.HC,"['cs.HC', 'cs.AI']",0
Advancing the Robustness of Large Language Models through Self-Denoised Smoothing,"['Jiabao Ji', 'Bairu Hou', 'Zhen Zhang', 'Guanhua Zhang', 'Wenqi Fan', 'Qing Li', 'Yang Zhang', 'Gaowen Liu', 'Sijia Liu', 'Shiyu Chang']","Although large language models (LLMs) have achieved significant success, their vulnerability to adversarial perturbations, including recent jailbreak attacks, has raised considerable concerns. However, the increasing size of these models and their limited access make improving their robustness a challenging task. Among various defense strategies, randomized smoothing has shown great potential for LLMs, as it does not require full access to the model's parameters or fine-tuning via adversarial training. However, randomized smoothing involves adding noise to the input before model prediction, and the final model's robustness largely depends on the model's performance on these noise corrupted data. Its effectiveness is often limited by the model's sub-optimal performance on noisy data. To address this issue, we propose to leverage the multitasking nature of LLMs to first denoise the noisy inputs and then to make predictions based on these denoised versions. We call this procedure self-denoised smoothing. Unlike previous denoised smoothing techniques in computer vision, which require training a separate model to enhance the robustness of LLMs, our method offers significantly better efficiency and flexibility. Our experimental results indicate that our method surpasses existing methods in both empirical and certified robustness in defending against adversarial attacks for both downstream tasks and human alignments (i.e., jailbreak attacks). Our code is publicly available at https://github.com/UCSB-NLP-Chang/SelfDenoise",2404.12274,http://arxiv.org/abs/2404.12274v1,2024-04-18 15:47:00+00:00,2024-04-18 15:47:00+00:00,cs.CL,"['cs.CL', 'cs.AI']",25
Generalizable Face Landmarking Guided by Conditional Face Warping,"['Jiayi Liang', 'Haotian Liu', 'Hongteng Xu', 'Dixin Luo']","As a significant step for human face modeling, editing, and generation, face landmarking aims at extracting facial keypoints from images. A generalizable face landmarker is required in practice because real-world facial images, e.g., the avatars in animations and games, are often stylized in various ways. However, achieving generalizable face landmarking is challenging due to the diversity of facial styles and the scarcity of labeled stylized faces. In this study, we propose a simple but effective paradigm to learn a generalizable face landmarker based on labeled real human faces and unlabeled stylized faces. Our method learns the face landmarker as the key module of a conditional face warper. Given a pair of real and stylized facial images, the conditional face warper predicts a warping field from the real face to the stylized one, in which the face landmarker predicts the ending points of the warping field and provides us with high-quality pseudo landmarks for the corresponding stylized facial images. Applying an alternating optimization strategy, we learn the face landmarker to minimize $i)$ the discrepancy between the stylized faces and the warped real ones and $ii)$ the prediction errors of both real and pseudo landmarks. Experiments on various datasets show that our method outperforms existing state-of-the-art domain adaptation methods in face landmarking tasks, leading to a face landmarker with better generalizability. Code is available at https://plustwo0.github.io/project-face-landmarker}{https://plustwo0.github.io/project-face-landmarker.",2404.12322,http://arxiv.org/abs/2404.12322v1,2024-04-18 16:53:08+00:00,2024-04-18 16:53:08+00:00,cs.CV,"['cs.CV', 'cs.AI']",26
V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning,"['Hang Hua', 'Yunlong Tang', 'Chenliang Xu', 'Jiebo Luo']","Video summarization aims to create short, accurate, and cohesive summaries of longer videos. Despite the existence of various video summarization datasets, a notable limitation is their limited amount of source videos, which hampers the effective fine-tuning of advanced large vision-language models (VLMs). Additionally, most existing datasets are created for video-to-video summarization, overlooking the contemporary need for multimodal video content summarization. Recent efforts have been made to expand from unimodal to multimodal video summarization, categorizing the task into three sub-tasks based on the summary's modality: video-to-video (V2V), video-to-text (V2T), and a combination of video and text summarization (V2VT). However, the textual summaries in previous multimodal datasets are inadequate. To address these issues, we introduce Instruct-V2Xum, a cross-modal video summarization dataset featuring 30,000 diverse videos sourced from YouTube, with lengths ranging from 40 to 940 seconds and an average summarization ratio of 16.39\%. Each video summary in Instruct-V2Xum is paired with a textual summary that references specific frame indexes, facilitating the generation of aligned video and textual summaries. In addition, we propose a new video summarization framework named V2Xum-LLM. V2Xum-LLM, specifically V2Xum-LLaMA in this study, is the first framework that unifies different video summarization tasks into one large language model's (LLM) text decoder and achieves task-controllable video summarization with temporal prompts and task instructions. Experiments show that V2Xum-LLaMA outperforms strong baseline models on multiple video summarization tasks. Furthermore, we propose an enhanced evaluation metric for V2V and V2VT summarization tasks.",2404.12353,http://arxiv.org/abs/2404.12353v1,2024-04-18 17:32:46+00:00,2024-04-18 17:32:46+00:00,cs.CV,"['cs.CV', 'cs.AI']",0
BLINK: Multimodal Large Language Models Can See but Not Perceive,"['Xingyu Fu', 'Yushi Hu', 'Bangzheng Li', 'Yu Feng', 'Haoyu Wang', 'Xudong Lin', 'Dan Roth', 'Noah A. Smith', 'Wei-Chiu Ma', 'Ranjay Krishna']","We introduce Blink, a new benchmark for multimodal language models (LLMs) that focuses on core visual perception abilities not found in other evaluations. Most of the Blink tasks can be solved by humans ""within a blink"" (e.g., relative depth estimation, visual correspondence, forensics detection, and multi-view reasoning). However, we find these perception-demanding tasks cast significant challenges for current multimodal LLMs because they resist mediation through natural language. Blink reformats 14 classic computer vision tasks into 3,807 multiple-choice questions, paired with single or multiple images and visual prompting. While humans get 95.70% accuracy on average, Blink is surprisingly challenging for existing multimodal LLMs: even the best-performing GPT-4V and Gemini achieve accuracies of 51.26% and 45.72%, only 13.17% and 7.63% higher than random guessing, indicating that such perception abilities have not ""emerged"" yet in recent multimodal LLMs. Our analysis also highlights that specialist CV models could solve these problems much better, suggesting potential pathways for future improvements. We believe Blink will stimulate the community to help multimodal LLMs catch up with human-level visual perception.",2404.1239,http://arxiv.org/abs/2404.12390v1,2024-04-18 17:59:54+00:00,2024-04-18 17:59:54+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.CL']",31
EEG_GLT-Net: Optimising EEG Graphs for Real-time Motor Imagery Signals Classification,"['Htoo Wai Aung', 'Jiao Jiao Li', 'Yang An', 'Steven W. Su']","Brain-Computer Interfaces connect the brain to external control devices, necessitating the accurate translation of brain signals such as from electroencephalography (EEG) into executable commands. Graph Neural Networks (GCN) have been increasingly applied for classifying EEG Motor Imagery signals, primarily because they incorporates the spatial relationships among EEG channels, resulting in improved accuracy over traditional convolutional methods. Recent advances by GCNs-Net in real-time EEG MI signal classification utilised Pearson Coefficient Correlation (PCC) for constructing adjacency matrices, yielding significant results on the PhysioNet dataset. Our paper introduces the EEG Graph Lottery Ticket (EEG_GLT) algorithm, an innovative technique for constructing adjacency matrices for EEG channels. It does not require pre-existing knowledge of inter-channel relationships, and it can be tailored to suit both individual subjects and GCN model architectures. Our findings demonstrated that the PCC method outperformed the Geodesic approach by 9.65% in mean accuracy, while our EEG_GLT matrix consistently exceeded the performance of the PCC method by a mean accuracy of 13.39%. Also, we found that the construction of the adjacency matrix significantly influenced accuracy, to a greater extent than GCN model configurations. A basic GCN configuration utilising our EEG_GLT matrix exceeded the performance of even the most complex GCN setup with a PCC matrix in average accuracy. Our EEG_GLT method also reduced MACs by up to 97% compared to the PCC method, while maintaining or enhancing accuracy. In conclusion, the EEG_GLT algorithm marks a breakthrough in the development of optimal adjacency matrices, effectively boosting both computational accuracy and efficiency, making it well-suited for real-time classification of EEG MI signals that demand intensive computational resources.",2404.11075,http://arxiv.org/abs/2404.11075v1,2024-04-17 05:16:12+00:00,2024-04-17 05:16:12+00:00,cs.LG,"['cs.LG', 'cs.AI', 'eess.SP']",0
Image Generative Semantic Communication with Multi-Modal Similarity Estimation for Resource-Limited Networks,"['Eri Hosonuma', 'Taku Yamazaki', 'Takumi Miyoshi', 'Akihito Taya', 'Yuuki Nishiyama', 'Kaoru Sezaki']","To reduce network traffic and support environments with limited resources, a method for transmitting images with low amounts of transmission data is required. Machine learning-based image compression methods, which compress the data size of images while maintaining their features, have been proposed. However, in certain situations, reconstructing a part of semantic information of images at the receiver end may be sufficient. To realize this concept, semantic-information-based communication, called semantic communication, has been proposed, along with an image transmission method using semantic communication. This method transmits only the semantic information of an image, and the receiver reconstructs the image using an image-generation model. This method utilizes one type of semantic information, but reconstructing images similar to the original image using only it is challenging. This study proposes a multi-modal image transmission method that leverages diverse semantic information for efficient semantic communication. The proposed method extracts multi-modal semantic information from an image and transmits only it. Subsequently, the receiver generates multiple images using an image-generation model and selects an output based on semantic similarity. The receiver must select the output based only on the received features; however, evaluating semantic similarity using conventional metrics is challenging. Therefore, this study explored new metrics to evaluate the similarity between semantic features of images and proposes two scoring procedures. The results indicate that the proposed procedures can compare semantic similarities, such as position and composition, between semantic features of the original and generated images. Thus, the proposed method can facilitate the transmission and utilization of photographs through mobile networks for various service applications.",2404.1128,http://arxiv.org/abs/2404.11280v1,2024-04-17 11:42:39+00:00,2024-04-17 11:42:39+00:00,cs.NI,"['cs.NI', 'cs.AI']",2
NTIRE 2024 Challenge on Short-form UGC Video Quality Assessment: Methods and Results,"['Xin Li', 'Kun Yuan', 'Yajing Pei', 'Yiting Lu', 'Ming Sun', 'Chao Zhou', 'Zhibo Chen', 'Radu Timofte', 'Wei Sun', 'Haoning Wu', 'Zicheng Zhang', 'Jun Jia', 'Zhichao Zhang', 'Linhan Cao', 'Qiubo Chen', 'Xiongkuo Min', 'Weisi Lin', 'Guangtao Zhai', 'Jianhui Sun', 'Tianyi Wang', 'Lei Li', 'Han Kong', 'Wenxuan Wang', 'Bing Li', 'Cheng Luo', 'Haiqiang Wang', 'Xiangguang Chen', 'Wenhui Meng', 'Xiang Pan', 'Huiying Shi', 'Han Zhu', 'Xiaozhong Xu', 'Lei Sun', 'Zhenzhong Chen', 'Shan Liu', 'Fangyuan Kong', 'Haotian Fan', 'Yifang Xu', 'Haoran Xu', 'Mengduo Yang', 'Jie Zhou', 'Jiaze Li', 'Shijie Wen', 'Mai Xu', 'Da Li', 'Shunyu Yao', 'Jiazhi Du', 'Wangmeng Zuo', 'Zhibo Li', 'Shuai He', 'Anlong Ming', 'Huiyuan Fu', 'Huadong Ma', 'Yong Wu', 'Fie Xue', 'Guozhi Zhao', 'Lina Du', 'Jie Guo', 'Yu Zhang', 'Huimin Zheng', 'Junhao Chen', 'Yue Liu', 'Dulan Zhou', 'Kele Xu', 'Qisheng Xu', 'Tao Sun', 'Zhixiang Ding', 'Yuhang Hu']","This paper reviews the NTIRE 2024 Challenge on Shortform UGC Video Quality Assessment (S-UGC VQA), where various excellent solutions are submitted and evaluated on the collected dataset KVQ from popular short-form video platform, i.e., Kuaishou/Kwai Platform. The KVQ database is divided into three parts, including 2926 videos for training, 420 videos for validation, and 854 videos for testing. The purpose is to build new benchmarks and advance the development of S-UGC VQA. The competition had 200 participants and 13 teams submitted valid solutions for the final testing phase. The proposed solutions achieved state-of-the-art performances for S-UGC VQA. The project can be found at https://github.com/lixinustc/KVQChallenge-CVPR-NTIRE2024.",2404.11313,http://arxiv.org/abs/2404.11313v1,2024-04-17 12:26:13+00:00,2024-04-17 12:26:13+00:00,eess.IV,"['eess.IV', 'cs.AI']",94
SoccerNet Game State Reconstruction: End-to-End Athlete Tracking and Identification on a Minimap,"['Vladimir Somers', 'Victor Joos', 'Anthony Cioppa', 'Silvio Giancola', 'Seyed Abolfazl Ghasemzadeh', 'Floriane Magera', 'Baptiste Standaert', 'Amir Mohammad Mansourian', 'Xin Zhou', 'Shohreh Kasaei', 'Bernard Ghanem', 'Alexandre Alahi', 'Marc Van Droogenbroeck', 'Christophe De Vleeschouwer']","Tracking and identifying athletes on the pitch holds a central role in collecting essential insights from the game, such as estimating the total distance covered by players or understanding team tactics. This tracking and identification process is crucial for reconstructing the game state, defined by the athletes' positions and identities on a 2D top-view of the pitch, (i.e. a minimap). However, reconstructing the game state from videos captured by a single camera is challenging. It requires understanding the position of the athletes and the viewpoint of the camera to localize and identify players within the field. In this work, we formalize the task of Game State Reconstruction and introduce SoccerNet-GSR, a novel Game State Reconstruction dataset focusing on football videos. SoccerNet-GSR is composed of 200 video sequences of 30 seconds, annotated with 9.37 million line points for pitch localization and camera calibration, as well as over 2.36 million athlete positions on the pitch with their respective role, team, and jersey number. Furthermore, we introduce GS-HOTA, a novel metric to evaluate game state reconstruction methods. Finally, we propose and release an end-to-end baseline for game state reconstruction, bootstrapping the research on this task. Our experiments show that GSR is a challenging novel task, which opens the field for future research. Our dataset and codebase are publicly available at https://github.com/SoccerNet/sn-gamestate.",2404.11335,http://arxiv.org/abs/2404.11335v1,2024-04-17 12:53:45+00:00,2024-04-17 12:53:45+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",0
When are Foundation Models Effective? Understanding the Suitability for Pixel-Level Classification Using Multispectral Imagery,"['Yiqun Xie', 'Zhihao Wang', 'Weiye Chen', 'Zhili Li', 'Xiaowei Jia', 'Yanhua Li', 'Ruichen Wang', 'Kangyang Chai', 'Ruohan Li', 'Sergii Skakun']","Foundation models, i.e., very large deep learning models, have demonstrated impressive performances in various language and vision tasks that are otherwise difficult to reach using smaller-size models. The major success of GPT-type of language models is particularly exciting and raises expectations on the potential of foundation models in other domains including satellite remote sensing. In this context, great efforts have been made to build foundation models to test their capabilities in broader applications, and examples include Prithvi by NASA-IBM, Segment-Anything-Model, ViT, etc. This leads to an important question: Are foundation models always a suitable choice for different remote sensing tasks, and when or when not? This work aims to enhance the understanding of the status and suitability of foundation models for pixel-level classification using multispectral imagery at moderate resolution, through comparisons with traditional machine learning (ML) and regular-size deep learning models. Interestingly, the results reveal that in many scenarios traditional ML models still have similar or better performance compared to foundation models, especially for tasks where texture is less useful for classification. On the other hand, deep learning models did show more promising results for tasks where labels partially depend on texture (e.g., burn scar), while the difference in performance between foundation models and deep learning models is not obvious. The results conform with our analysis: The suitability of foundation models depend on the alignment between the self-supervised learning tasks and the real downstream tasks, and the typical masked autoencoder paradigm is not necessarily suitable for many remote sensing problems.",2404.11797,http://arxiv.org/abs/2404.11797v1,2024-04-17 23:30:48+00:00,2024-04-17 23:30:48+00:00,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']",16
Introducing v0.5 of the AI Safety Benchmark from MLCommons,"['Bertie Vidgen', 'Adarsh Agrawal', 'Ahmed M. Ahmed', 'Victor Akinwande', 'Namir Al-Nuaimi', 'Najla Alfaraj', 'Elie Alhajjar', 'Lora Aroyo', 'Trupti Bavalatti', 'Borhane Blili-Hamelin', 'Kurt Bollacker', 'Rishi Bomassani', 'Marisa Ferrara Boston', 'Siméon Campos', 'Kal Chakra', 'Canyu Chen', 'Cody Coleman', 'Zacharie Delpierre Coudert', 'Leon Derczynski', 'Debojyoti Dutta', 'Ian Eisenberg', 'James Ezick', 'Heather Frase', 'Brian Fuller', 'Ram Gandikota', 'Agasthya Gangavarapu', 'Ananya Gangavarapu', 'James Gealy', 'Rajat Ghosh', 'James Goel', 'Usman Gohar', 'Sujata Goswami', 'Scott A. Hale', 'Wiebke Hutiri', 'Joseph Marvin Imperial', 'Surgan Jandial', 'Nick Judd', 'Felix Juefei-Xu', 'Foutse Khomh', 'Bhavya Kailkhura', 'Hannah Rose Kirk', 'Kevin Klyman', 'Chris Knotz', 'Michael Kuchnik', 'Shachi H. Kumar', 'Chris Lengerich', 'Bo Li', 'Zeyi Liao', 'Eileen Peters Long', 'Victor Lu', 'Yifan Mai', 'Priyanka Mary Mammen', 'Kelvin Manyeki', 'Sean McGregor', 'Virendra Mehta', 'Shafee Mohammed', 'Emanuel Moss', 'Lama Nachman', 'Dinesh Jinenhally Naganna', 'Amin Nikanjam', 'Besmira Nushi', 'Luis Oala', 'Iftach Orr', 'Alicia Parrish', 'Cigdem Patlak', 'William Pietri', 'Forough Poursabzi-Sangdeh', 'Eleonora Presani', 'Fabrizio Puletti', 'Paul Röttger', 'Saurav Sahay', 'Tim Santos', 'Nino Scherrer', 'Alice Schoenauer Sebag', 'Patrick Schramowski', 'Abolfazl Shahbazi', 'Vin Sharma', 'Xudong Shen', 'Vamsi Sistla', 'Leonard Tang', 'Davide Testuggine', 'Vithursan Thangarasa', 'Elizabeth Anne Watkins', 'Rebecca Weiss', 'Chris Welty', 'Tyler Wilbers', 'Adina Williams', 'Carole-Jean Wu', 'Poonam Yadav', 'Xianjun Yang', 'Yi Zeng', 'Wenhui Zhang', 'Fedor Zhdanov', 'Jiacheng Zhu', 'Percy Liang', 'Peter Mattson', 'Joaquin Vanschoren']","This paper introduces v0.5 of the AI Safety Benchmark, which has been created by the MLCommons AI Safety Working Group. The AI Safety Benchmark has been designed to assess the safety risks of AI systems that use chat-tuned language models. We introduce a principled approach to specifying and constructing the benchmark, which for v0.5 covers only a single use case (an adult chatting to a general-purpose assistant in English), and a limited set of personas (i.e., typical users, malicious users, and vulnerable users). We created a new taxonomy of 13 hazard categories, of which 7 have tests in the v0.5 benchmark. We plan to release version 1.0 of the AI Safety Benchmark by the end of 2024. The v1.0 benchmark will provide meaningful insights into the safety of AI systems. However, the v0.5 benchmark should not be used to assess the safety of AI systems. We have sought to fully document the limitations, flaws, and challenges of v0.5. This release of v0.5 of the AI Safety Benchmark includes (1) a principled approach to specifying and constructing the benchmark, which comprises use cases, types of systems under test (SUTs), language and context, personas, tests, and test items; (2) a taxonomy of 13 hazard categories with definitions and subcategories; (3) tests for seven of the hazard categories, each comprising a unique set of test items, i.e., prompts. There are 43,090 test items in total, which we created with templates; (4) a grading system for AI systems against the benchmark; (5) an openly available platform, and downloadable tool, called ModelBench that can be used to evaluate the safety of AI systems on the benchmark; (6) an example evaluation report which benchmarks the performance of over a dozen openly available chat-tuned language models; (7) a test specification for the benchmark.",2404.12241,http://arxiv.org/abs/2404.12241v1,2024-04-18 15:01:00+00:00,2024-04-18 15:01:00+00:00,cs.CL,"['cs.CL', 'cs.AI']",33
